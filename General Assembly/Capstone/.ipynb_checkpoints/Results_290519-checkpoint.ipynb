{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, SCORERS\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>MVP</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>TmWin</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>...</th>\n",
       "      <th>ORB/G</th>\n",
       "      <th>DRB/G</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>STL/G</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>22.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.79</td>\n",
       "      <td>6.35</td>\n",
       "      <td>292.787250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.599</td>\n",
       "      <td>...</td>\n",
       "      <td>2.66</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.16</td>\n",
       "      <td>10.78</td>\n",
       "      <td>429.586585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.581</td>\n",
       "      <td>...</td>\n",
       "      <td>2.99</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.49</td>\n",
       "      <td>11.43</td>\n",
       "      <td>500.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.594</td>\n",
       "      <td>...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.87</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13.27</td>\n",
       "      <td>506.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.548</td>\n",
       "      <td>...</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.49</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.94</td>\n",
       "      <td>608.001188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Player  MVP  Year   Age  TmWin     G    GS      MP   PER    TS%  \\\n",
       "0  A.C. Green    0  1986  22.0   62.0  82.0   1.0  1542.0  11.8  0.564   \n",
       "1  A.C. Green    0  1987  23.0   65.0  79.0  72.0  2240.0  15.7  0.599   \n",
       "2  A.C. Green    0  1988  24.0   62.0  82.0  64.0  2636.0  14.5  0.581   \n",
       "3  A.C. Green    0  1989  25.0   57.0  82.0  82.0  2510.0  17.8  0.594   \n",
       "4  A.C. Green    0  1990  26.0   63.0  82.0  82.0  2709.0  14.7  0.548   \n",
       "\n",
       "      ...      ORB/G  DRB/G  TRB/G  AST/G  STL/G  BLK/G  TOV/G  PF/G    PPG  \\\n",
       "0     ...       1.95   2.70   4.65   0.66   0.60   0.60   1.21  2.79   6.35   \n",
       "1     ...       2.66   5.13   7.78   1.06   0.89   1.01   1.29  2.16  10.78   \n",
       "2     ...       2.99   5.67   8.66   1.13   1.06   0.55   1.46  2.49  11.43   \n",
       "3     ...       3.15   5.87   9.01   1.26   1.15   0.67   1.45  2.10  13.27   \n",
       "4     ...       3.20   5.49   8.68   1.10   0.80   0.61   1.41  2.52  12.94   \n",
       "\n",
       "       Impact  \n",
       "0  292.787250  \n",
       "1  429.586585  \n",
       "2  500.510500  \n",
       "3  506.706250  \n",
       "4  608.001188  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the dataframe, then removing the useless column\n",
    "stats = pd.read_csv('stats_1.6.csv')\n",
    "stats.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17148, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the predictors for Logistic Regression\n",
    "# Naming the predictors and target variables X1, y1\n",
    "X1 = stats[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "y1 = stats['MVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the predictors using StandardScaler()\n",
    "ss = StandardScaler()\n",
    "ss.fit_transform(X1)\n",
    "\n",
    "# Creating a training and testing set\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.96756126 0.97036173 0.96824656 0.96357693 0.96661219]\n",
      "Mean Cross-Validation Score: 0.9672717326185231\n",
      "[[3233  122]\n",
      " [  15   60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      3355\n",
      "           1       0.33      0.80      0.47        75\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3430\n",
      "   macro avg       0.66      0.88      0.72      3430\n",
      "weighted avg       0.98      0.96      0.97      3430\n",
      "\n",
      "AUC Score 0.9636164927968207\n"
     ]
    }
   ],
   "source": [
    "# Oversampling the data with SMOTE\n",
    "sm_rfc = SMOTE(sampling_strategy=0.6, random_state=7, k_neighbors=9)\n",
    "smote_rfc_X1, smote_rfc_y1 = sm_rfc.fit_sample(X1_train, y1_train)\n",
    "\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators=17, criterion='entropy', max_features=7, n_jobs=-1, random_state=0, max_depth=13)\n",
    "\n",
    "# Fitting the model\n",
    "rfct1 = rfc1.fit(smote_rfc_X1, smote_rfc_y1)\n",
    "\n",
    "\n",
    "# Checking cross-validation values\n",
    "print('Cross-Validation Scores:', cross_val_score(rfc1, smote_rfc_X1, smote_rfc_y1, cv=5))\n",
    "print('Mean Cross-Validation Score:', np.mean(cross_val_score(rfc1, smote_rfc_X1, smote_rfc_y1, cv=5)))\n",
    "\n",
    "# Constructing the confusion matrix\n",
    "predictions_rfc1 = rfc1.predict(X1_test)\n",
    "predictions_proba_rfc1 = rfc1.predict_proba(X1_test)\n",
    "print(confusion_matrix(y1_test, predictions_rfc1))\n",
    "print(classification_report(y1_test, predictions_rfc1))\n",
    "print('AUC Score', roc_auc_score(y1_test, predictions_proba_rfc1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1a. Testing for NBA's 2019 MVPs using Basketball-reference.com's list as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2019 = stats[stats['Year'] == 2019]\n",
    "test_2019_X = testing_2019[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2019_y = testing_2019[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G      Impact  \\\n",
       "44   5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36  477.745006   \n",
       "55   0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   86.264634   \n",
       "89   0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   79.580606   \n",
       "194  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74  315.673985   \n",
       "230  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53  342.484546   \n",
       "\n",
       "      PER  \n",
       "44   15.1  \n",
       "55   11.9  \n",
       "89    8.8  \n",
       "194  20.2  \n",
       "230  13.2  "
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2019_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[509  11]\n",
      " [  0  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       520\n",
      "           1       0.48      1.00      0.65        10\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       530\n",
      "   macro avg       0.74      0.99      0.82       530\n",
      "weighted avg       0.99      0.98      0.98       530\n",
      "\n",
      "AUC Score 0.9992307692307693\n"
     ]
    }
   ],
   "source": [
    "predictions_rfc1_2019 = rfc1.predict(test_2019_X)\n",
    "predictions_proba_rfc1_2019 = rfc1.predict_proba(test_2019_X)\n",
    "print(confusion_matrix(test_2019_y, predictions_rfc1_2019))\n",
    "print(classification_report(test_2019_y, predictions_rfc1_2019))\n",
    "print('AUC Score', roc_auc_score(test_2019_y, predictions_proba_rfc1_2019[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_rfc_2019 = pd.DataFrame(predictions_proba_rfc1_2019)\n",
    "probability_rfc_2019 = probability_rfc_2019.loc[:,1:]\n",
    "probability_rfc_2019.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_rfc_2019 = pd.DataFrame(predictions_rfc1_2019)\n",
    "predictions_rfc_2019.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2019_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_rfc_2019 = test_2019_X.copy(deep=True)\n",
    "predictors_rfc_2019.reset_index(inplace=True)\n",
    "predictors_rfc_2019.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0    44.0  5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36   \n",
       "1    55.0  0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   \n",
       "2    89.0  0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   \n",
       "3   194.0  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74   \n",
       "4   230.0  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0  477.745006  15.1         0            0.0                   0.096648  \n",
       "1   86.264634  11.9         0            0.0                   0.000000  \n",
       "2   79.580606   8.8         0            0.0                   0.000000  \n",
       "3  315.673985  20.2         0            0.0                   0.000000  \n",
       "4  342.484546  13.2         0            0.0                   0.000000  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2019 = pd.concat([predictors_rfc_2019, real_mvp, predictions_rfc_2019, probability_rfc_2019], axis=1)\n",
    "MVP_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9402.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.631</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.99</td>\n",
       "      <td>6.37</td>\n",
       "      <td>885.110945</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>15101.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.641</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>27.26</td>\n",
       "      <td>5.35</td>\n",
       "      <td>708.083890</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3452.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.588</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>25.84</td>\n",
       "      <td>4.64</td>\n",
       "      <td>895.758171</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12714.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.583</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>28.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>803.387306</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9039.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.606</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>26.60</td>\n",
       "      <td>7.32</td>\n",
       "      <td>546.508537</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>9877.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.576</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.32</td>\n",
       "      <td>21.32</td>\n",
       "      <td>9.19</td>\n",
       "      <td>713.988329</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>7150.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.616</td>\n",
       "      <td>7.51</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.13</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1219.545755</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6065.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.644</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.53</td>\n",
       "      <td>27.69</td>\n",
       "      <td>12.47</td>\n",
       "      <td>835.939756</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>12329.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.589</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.05</td>\n",
       "      <td>10.81</td>\n",
       "      <td>753.032195</td>\n",
       "      <td>26.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9856.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.592</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23.82</td>\n",
       "      <td>5.00</td>\n",
       "      <td>546.619500</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8247.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.593</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.91</td>\n",
       "      <td>27.52</td>\n",
       "      <td>13.61</td>\n",
       "      <td>594.819220</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9160.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.558</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>25.63</td>\n",
       "      <td>4.40</td>\n",
       "      <td>732.749063</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.811711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4138.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.542</td>\n",
       "      <td>6.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>21.23</td>\n",
       "      <td>6.00</td>\n",
       "      <td>704.223220</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>12348.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.11</td>\n",
       "      <td>20.81</td>\n",
       "      <td>12.00</td>\n",
       "      <td>599.951220</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2885.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.560</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>15.62</td>\n",
       "      <td>4.57</td>\n",
       "      <td>326.319627</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.692176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1249.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.582</td>\n",
       "      <td>7.72</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>16.92</td>\n",
       "      <td>8.82</td>\n",
       "      <td>610.798857</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.680721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1789.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>25.60</td>\n",
       "      <td>5.01</td>\n",
       "      <td>573.301333</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>12597.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.628</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.93</td>\n",
       "      <td>6.86</td>\n",
       "      <td>624.777886</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.523111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3350.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.533</td>\n",
       "      <td>6.95</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>21.14</td>\n",
       "      <td>3.89</td>\n",
       "      <td>674.965098</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14232.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.501</td>\n",
       "      <td>10.74</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.05</td>\n",
       "      <td>738.546898</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "304   9402.0  11.5   2.88  1.99  0.631   5.86   4.3   1.08  25.99   6.37   \n",
       "454  15101.0   9.7   2.78  2.41  0.641   5.23   4.9   0.36  27.26   5.35   \n",
       "87    3452.0  12.1   2.65  1.85  0.588   6.89   5.4   0.43  25.84   4.64   \n",
       "407  12714.0  11.9   2.66  2.78  0.583   4.13   5.3   0.44  28.04   8.16   \n",
       "295   9039.0   9.5   2.02  1.45  0.606   3.32   3.6   0.40  26.60   7.32   \n",
       "323   9877.0   9.3   1.78  2.21  0.576   2.40   2.5   1.32  21.32   9.19   \n",
       "225   7150.0  15.2   4.96  3.13  0.616   7.51   9.9   0.74  36.13   6.64   \n",
       "179   6065.0  14.4   3.72  3.22  0.644   5.89   7.6   1.53  27.69  12.47   \n",
       "388  12329.0  11.8   3.10  2.85  0.589   7.25   7.3   0.69  20.05  10.81   \n",
       "322   9856.0   9.1   2.57  2.49  0.592   6.93   4.7   0.51  23.82   5.00   \n",
       "258   8247.0   8.7   3.53  3.30  0.593   3.66   3.3   1.91  27.52  13.61   \n",
       "299   9160.0   7.4   2.57  1.60  0.558   5.90   3.9   0.41  25.63   4.40   \n",
       "108   4138.0   6.3   2.58  2.30  0.542   6.17   2.0   0.47  21.23   6.00   \n",
       "390  12348.0  10.1   1.99  1.96  0.573   3.84   5.3   1.11  20.81  12.00   \n",
       "72    2885.0   6.6   2.62  2.52  0.560   8.16   2.4   0.31  15.62   4.57   \n",
       "35    1249.0   8.2   3.47  2.65  0.582   7.72   4.1   0.77  16.92   8.82   \n",
       "45    1789.0   7.6   2.73  2.76  0.581   5.46   3.7   0.71  25.60   5.01   \n",
       "400  12597.0   9.3   1.93  3.01  0.628   3.10   3.5   0.65  16.93   6.86   \n",
       "81    3350.0   5.0   3.12  1.74  0.533   6.95   3.3   0.25  21.14   3.89   \n",
       "433  14232.0   6.8   4.45  3.36  0.501  10.74   5.6   0.45  22.95  11.05   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "304   885.110945  24.2         0            1.0                   0.994624  \n",
       "454   708.083890  24.4         0            1.0                   0.994271  \n",
       "87    895.758171  23.7         0            1.0                   0.993744  \n",
       "407   803.387306  23.3         0            1.0                   0.985174  \n",
       "295   546.508537  25.8         0            1.0                   0.983634  \n",
       "323   713.988329  22.9         0            1.0                   0.982640  \n",
       "225  1219.545755  30.6         0            1.0                   0.981747  \n",
       "179   835.939756  30.9         0            1.0                   0.964024  \n",
       "388   753.032195  26.3         0            1.0                   0.955770  \n",
       "322   546.619500  24.3         0            1.0                   0.946983  \n",
       "258   594.819220  26.1         0            1.0                   0.905187  \n",
       "299   732.749063  21.7         1            1.0                   0.811711  \n",
       "108   704.223220  19.6         0            1.0                   0.733538  \n",
       "390   599.951220  25.5         0            1.0                   0.703626  \n",
       "72    326.319627  19.7         0            1.0                   0.692176  \n",
       "35    610.798857  20.0         0            1.0                   0.680721  \n",
       "45    573.301333  20.8         0            1.0                   0.555337  \n",
       "400   624.777886  18.7         0            1.0                   0.523111  \n",
       "81    674.965098  19.4         0            1.0                   0.517297  \n",
       "433   738.546898  21.1         0            1.0                   0.515135  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2019[MVP_2019['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False)\n",
    "\n",
    "# Players: 1249, 1789, 2885, 3350, 3452, 4138, 6065, 7150, 8247, 9039, 9160, 9402, 9856, 9877, 12329, 12348, 12597\n",
    "# 12714, 14232, 15101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 MVPs as predicted by Random Forest with SMOTE\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. Kevin Durant (0.995)\n",
    "2. Stephen Curry (0.994)\n",
    "3. Damian Lillard (0.993)\n",
    "4. Paul George (0.986)\n",
    "5. Kawhi Leonard (0.984)\n",
    "6. LaMarcus Aldridge (0.983)\n",
    "7. James Harden (0.982)\n",
    "8. Giannis Antetokounmpo (0.964)\n",
    "9. Nikola Vucevic (0.956)\n",
    "10. Kyrie Irving (0.947)\n",
    "11. Joel Embid (0.905)\n",
    "\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "12. Kemba Walker (0.812)\n",
    "13. DeMar Derozan (0.734)\n",
    "14. Nikola Vucevic (0.703)\n",
    "15. Chris Paul (0.692)\n",
    "16. Ben Simmons (0.680)\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "17. Bradley Beal\n",
    "18. Pascal Siakam\n",
    "19. D'Angelo Russell\n",
    "20. Russell Westbrook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1b. Testing for 2018 MVPs using actual winners as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2018 = stats[stats['Year'] == 2018]\n",
    "test_2018_X = testing_2018[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2018_y = testing_2018[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[514  10]\n",
      " [  0  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       524\n",
      "           1       0.57      1.00      0.72        13\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       537\n",
      "   macro avg       0.78      0.99      0.86       537\n",
      "weighted avg       0.99      0.98      0.98       537\n",
      "\n",
      "AUC Score 0.9995596007046389\n"
     ]
    }
   ],
   "source": [
    "predictions_rfc1_2018 = rfc1.predict(test_2018_X)\n",
    "predictions_proba_rfc1_2018 = rfc1.predict_proba(test_2018_X)\n",
    "print(confusion_matrix(test_2018_y, predictions_rfc1_2018))\n",
    "print(classification_report(test_2018_y, predictions_rfc1_2018))\n",
    "print('AUC Score', roc_auc_score(test_2018_y, predictions_proba_rfc1_2018[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_rfc_2018 = pd.DataFrame(predictions_proba_rfc1_2018)\n",
    "probability_rfc_2018 = probability_rfc_2018.loc[:,1:]\n",
    "probability_rfc_2018.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_rfc_2018 = pd.DataFrame(predictions_rfc1_2018)\n",
    "predictions_rfc_2018.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2018_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_rfc_2018 = test_2018_X.copy(deep=True)\n",
    "predictors_rfc_2018.reset_index(inplace=True)\n",
    "predictors_rfc_2018.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>14.371683</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>17.62</td>\n",
       "      <td>7.88</td>\n",
       "      <td>173.706390</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.981921</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.48</td>\n",
       "      <td>59.870854</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      39  0.1   0.34  0.88  0.508   0.63  -0.1   0.00   2.34   0.53   \n",
       "1      43  2.9   1.84  1.91  0.530   2.34   1.0   0.78  17.62   7.88   \n",
       "2      54 -0.1   0.33  3.00  0.392   1.22  -0.1   0.22   6.67   2.67   \n",
       "3      56  0.0   1.00  4.00  0.405   1.00  -0.1   0.00   8.00   3.00   \n",
       "4      88 -0.1   0.71  0.94  0.439   0.54  -0.5   0.21   3.04   1.48   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0   14.371683   9.8         0              0                        0.0  \n",
       "1  173.706390  16.5         0              0                        0.0  \n",
       "2    1.981921   5.1         0              0                        0.0  \n",
       "3    0.079186   2.4         0              0                        0.0  \n",
       "4   59.870854   5.1         0              0                        0.0  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2018 = pd.concat([predictors_rfc_2018, real_mvp, predictions_rfc_2018, probability_rfc_2018], axis=1)\n",
    "MVP_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>10170</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.621</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>27.45</td>\n",
       "      <td>8.65</td>\n",
       "      <td>996.058333</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3451</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.594</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.37</td>\n",
       "      <td>26.88</td>\n",
       "      <td>4.45</td>\n",
       "      <td>742.500137</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16542</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.577</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>23.13</td>\n",
       "      <td>5.20</td>\n",
       "      <td>702.578049</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9401</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.640</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>26.35</td>\n",
       "      <td>6.82</td>\n",
       "      <td>708.236585</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>7149</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.619</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>30.43</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1094.985640</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>821</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.57</td>\n",
       "      <td>28.13</td>\n",
       "      <td>11.09</td>\n",
       "      <td>748.262195</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4137</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.555</td>\n",
       "      <td>5.21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.94</td>\n",
       "      <td>962.294797</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6064</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.598</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.41</td>\n",
       "      <td>26.85</td>\n",
       "      <td>10.04</td>\n",
       "      <td>720.929268</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>9876</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.570</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>23.13</td>\n",
       "      <td>8.47</td>\n",
       "      <td>653.879440</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>14231</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.524</td>\n",
       "      <td>10.25</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.35</td>\n",
       "      <td>10.05</td>\n",
       "      <td>969.438049</td>\n",
       "      <td>24.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>15100</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.675</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>26.39</td>\n",
       "      <td>5.12</td>\n",
       "      <td>379.978247</td>\n",
       "      <td>28.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>8052</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.590</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>22.15</td>\n",
       "      <td>5.32</td>\n",
       "      <td>379.622009</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2884</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.604</td>\n",
       "      <td>7.88</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>18.64</td>\n",
       "      <td>5.40</td>\n",
       "      <td>433.430272</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1248</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.557</td>\n",
       "      <td>8.16</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>15.79</td>\n",
       "      <td>8.14</td>\n",
       "      <td>651.956817</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9823</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.598</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>16.24</td>\n",
       "      <td>5.56</td>\n",
       "      <td>636.832149</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>8246</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.76</td>\n",
       "      <td>22.94</td>\n",
       "      <td>10.95</td>\n",
       "      <td>531.524341</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>12713</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.570</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>21.95</td>\n",
       "      <td>5.66</td>\n",
       "      <td>715.804549</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>12328</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.603</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>18.47</td>\n",
       "      <td>10.71</td>\n",
       "      <td>518.206479</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>9159</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5.55</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>22.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>548.534634</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>9855</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.610</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>24.43</td>\n",
       "      <td>3.78</td>\n",
       "      <td>501.883384</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>4907</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.556</td>\n",
       "      <td>7.26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>11.04</td>\n",
       "      <td>7.64</td>\n",
       "      <td>405.756565</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.537433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1788</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.564</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>22.65</td>\n",
       "      <td>4.43</td>\n",
       "      <td>736.063250</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>9029</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.26</td>\n",
       "      <td>12.34</td>\n",
       "      <td>654.300708</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "324   10170  14.0   4.23  1.66  0.621   9.11   8.9   0.87  27.45   8.65   \n",
       "86     3451  12.6   2.82  1.60  0.594   6.59   5.9   0.37  26.88   4.45   \n",
       "513   16542   8.2   2.92  2.33  0.577   4.31   4.5   0.76  23.13   5.20   \n",
       "299    9401  10.4   3.04  1.96  0.640   5.38   4.5   1.75  26.35   6.82   \n",
       "217    7149  15.4   4.38  2.35  0.619   8.75   8.3   0.69  30.43   5.40   \n",
       "29      821  13.7   2.16  2.12  0.612   2.32   4.9   2.57  28.13  11.09   \n",
       "111    4137   9.6   2.19  1.89  0.555   5.21   2.6   0.28  23.00   3.94   \n",
       "173    6064  11.9   2.97  3.08  0.598   4.81   5.4   1.41  26.85  10.04   \n",
       "317    9876  10.9   1.48  2.15  0.570   2.03   3.3   1.20  23.13   8.47   \n",
       "444   14231  10.1   4.76  2.50  0.524  10.25   7.5   0.25  25.35  10.05   \n",
       "464   15100   9.1   3.00  2.24  0.675   6.08   4.4   0.16  26.39   5.12   \n",
       "243    8052   8.9   1.83  1.32  0.590   4.88   3.8   0.41  22.15   5.32   \n",
       "73     2884  10.2   2.21  2.43  0.604   7.88   4.3   0.24  18.64   5.40   \n",
       "39     1248   9.2   3.43  2.60  0.557   8.16   4.6   0.86  15.79   8.14   \n",
       "313    9823  10.2   2.35  2.46  0.598   6.88   5.0   0.24  16.24   5.56   \n",
       "251    8246   6.2   3.71  3.32  0.573   3.16   2.2   1.76  22.94  10.95   \n",
       "416   12713   8.9   2.68  2.95  0.570   3.33   3.3   0.49  21.95   5.66   \n",
       "396   12328  10.7   2.80  2.83  0.603   6.11   5.6   0.81  18.47  10.71   \n",
       "294    9159   8.6   2.24  1.23  0.572   5.55   3.6   0.30  22.13   3.10   \n",
       "316    9855   8.9   2.33  2.03  0.610   5.10   4.0   0.28  24.43   3.78   \n",
       "139    4907   6.1   2.89  2.64  0.556   7.26   3.0   1.30  11.04   7.64   \n",
       "47     1788   6.9   2.61  1.95  0.564   4.55   2.7   0.44  22.65   4.43   \n",
       "289    9029  14.0   1.94  3.48  0.646   2.43   5.5   1.40  21.26  12.34   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "324   996.058333  28.6         1              1                   0.994551  \n",
       "86    742.500137  25.2         1              1                   0.994059  \n",
       "513   702.578049  23.1         1              1                   0.992636  \n",
       "299   708.236585  26.0         1              1                   0.992606  \n",
       "217  1094.985640  29.8         1              1                   0.989958  \n",
       "29    748.262195  28.9         1              1                   0.988426  \n",
       "111   962.294797  21.0         1              1                   0.981508  \n",
       "173   720.929268  27.3         1              1                   0.980331  \n",
       "317   653.879440  25.0         1              1                   0.968208  \n",
       "444   969.438049  24.7         1              1                   0.965856  \n",
       "464   379.978247  28.2         1              1                   0.964858  \n",
       "243   379.622009  23.7         1              1                   0.922513  \n",
       "73    433.430272  24.4         0              1                   0.873615  \n",
       "39    651.956817  20.0         0              1                   0.850931  \n",
       "313   636.832149  19.5         0              1                   0.620406  \n",
       "251   531.524341  22.9         1              1                   0.618901  \n",
       "416   715.804549  18.7         0              1                   0.608554  \n",
       "396   518.206479  24.4         0              1                   0.601988  \n",
       "294   548.534634  20.6         0              1                   0.597130  \n",
       "316   501.883384  25.0         0              1                   0.576364  \n",
       "139   405.756565  16.1         0              1                   0.537433  \n",
       "47    736.063250  18.4         0              1                   0.504279  \n",
       "289   654.300708  24.9         0              1                   0.502779  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2018[MVP_2018['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 MVP List\n",
    "Actual Rankings (In order):\n",
    "1. James Harden\n",
    "2. LeBron James\n",
    "3. Anthony Davis\n",
    "4. Damian Lillard\n",
    "5. Russell Westbrook\n",
    "6. Giannis Antetokounmpo\n",
    "7. Kevin Durant\n",
    "8. DeMar DeRozan\n",
    "9. LaMarcus Aldridge\n",
    "10. Jimmy Butler\n",
    "11. Stephen Curry\n",
    "12. Joel Embiid\n",
    "13. Victor Oladipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 MVPs as predicted by Random Forest with SMOTE\n",
    "\n",
    "# Elite candidates (P >= 0.9)\n",
    "1. LeBron James (0.995)\n",
    "2. Damian Lillard (0.994)\n",
    "3. Victor Oladipo (0.99263)\n",
    "4. Kevin Durant (0.99260)\n",
    "5. James Harden (0.990)\n",
    "6. Anthony Davis (0.988)\n",
    "7. DeMar Derozan (0.982)\n",
    "8. Giannis Antetokounmpo (0.980)\n",
    "9. LaMarcus Aldridge (0.968)\n",
    "10. Rusell Westbrook (0.966)\n",
    "11. Stephen Curry (0.965)\n",
    "12. Jimmy Butler (0.923)\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "13. Chris Paul (0.874)\n",
    "14. Ben Simmons (0.850)\n",
    "15. Kyle Lowry (0.620)\n",
    "16. Joel Embiid (0.618)\n",
    "17. Paul George (0.609)\n",
    "18. Nikola Jokic (0.602)\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "19. Kemba Walker (0.598)\n",
    "20. Kyrie Irving (0.577) [Surprising given that he sat out almost the whole season]\n",
    "21. Draymond Green (0.537)\n",
    "22. Bradley Beal (0.504)\n",
    "23. Karl-Anthony Towns (0.502)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the data with SMOTE\n",
    "sm_log = SMOTE(sampling_strategy=0.6, random_state=7, k_neighbors=9)\n",
    "smote_log_X1, smote_log_y1 = sm_log.fit_sample(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.92783746 0.92875496 0.93317757 0.92663551 0.9228972 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Score: 0.9278605406597171\n",
      "[[3119  246]\n",
      " [   8   57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      3365\n",
      "           1       0.19      0.88      0.31        65\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3430\n",
      "   macro avg       0.59      0.90      0.64      3430\n",
      "weighted avg       0.98      0.93      0.95      3430\n",
      "\n",
      "AUC Score 0.9629214767401989\n"
     ]
    }
   ],
   "source": [
    "# Specifying the optimal hyperparameters\n",
    "log1 = LogisticRegression(penalty='l2', C=0.2)\n",
    "\n",
    "# Fitting the model\n",
    "logt1 = log1.fit(smote_log_X1, smote_log_y1)\n",
    "\n",
    "\n",
    "# Checking cross-validation values\n",
    "print('Cross-Validation Scores:', cross_val_score(logt1, smote_log_X1, smote_log_y1, cv=5))\n",
    "print('Mean Cross-Validation Score:', np.mean(cross_val_score(logt1, smote_log_X1, smote_log_y1, cv=5)))\n",
    "\n",
    "# Constructing the confusion matrix\n",
    "predictions_logt1 = logt1.predict(X1_test)\n",
    "predictions_proba_logt1 = logt1.predict_proba(X1_test)\n",
    "print(confusion_matrix(y1_test, predictions_logt1))\n",
    "print(classification_report(y1_test, predictions_logt1))\n",
    "print('AUC Score', roc_auc_score(y1_test, predictions_proba_logt1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2a. Testing for NBA's 2019 MVPs using Basketball-reference.com's list as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2019 = stats[stats['Year'] == 2019]\n",
    "test_2019_X = testing_2019[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2019_y = testing_2019[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G      Impact  \\\n",
       "44   5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36  477.745006   \n",
       "55   0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   86.264634   \n",
       "89   0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   79.580606   \n",
       "194  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74  315.673985   \n",
       "230  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53  342.484546   \n",
       "\n",
       "      PER  \n",
       "44   15.1  \n",
       "55   11.9  \n",
       "89    8.8  \n",
       "194  20.2  \n",
       "230  13.2  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2019_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[492  28]\n",
      " [  0  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       520\n",
      "           1       0.26      1.00      0.42        10\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       530\n",
      "   macro avg       0.63      0.97      0.69       530\n",
      "weighted avg       0.99      0.95      0.96       530\n",
      "\n",
      "AUC Score 0.9973076923076922\n"
     ]
    }
   ],
   "source": [
    "predictions_log1_2019 = logt1.predict(test_2019_X)\n",
    "predictions_proba_log1_2019 = logt1.predict_proba(test_2019_X)\n",
    "print(confusion_matrix(test_2019_y, predictions_log1_2019))\n",
    "print(classification_report(test_2019_y, predictions_log1_2019))\n",
    "print('AUC Score', roc_auc_score(test_2019_y, predictions_proba_log1_2019[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_log_2019 = pd.DataFrame(predictions_proba_log1_2019)\n",
    "probability_log_2019 = probability_log_2019.loc[:,1:]\n",
    "probability_log_2019.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_log_2019 = pd.DataFrame(predictions_log1_2019)\n",
    "predictions_log_2019.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2019_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_log_2019 = test_2019_X.copy(deep=True)\n",
    "predictors_log_2019.reset_index(inplace=True)\n",
    "predictors_log_2019.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      44  5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36   \n",
       "1      55  0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   \n",
       "2      89  0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   \n",
       "3     194  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74   \n",
       "4     230  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0  477.745006  15.1         0              0                   0.334005  \n",
       "1   86.264634  11.9         0              0                   0.003992  \n",
       "2   79.580606   8.8         0              0                   0.002118  \n",
       "3  315.673985  20.2         0              0                   0.455162  \n",
       "4  342.484546  13.2         0              0                   0.068130  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2019_log = pd.concat([predictors_log_2019, real_mvp, predictions_log_2019, probability_log_2019], axis=1)\n",
    "MVP_2019_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>7150</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.616</td>\n",
       "      <td>7.51</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.13</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1219.545755</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6065</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.644</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.53</td>\n",
       "      <td>27.69</td>\n",
       "      <td>12.47</td>\n",
       "      <td>835.939756</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9402</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.631</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.99</td>\n",
       "      <td>6.37</td>\n",
       "      <td>885.110945</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>12329</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.589</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.05</td>\n",
       "      <td>10.81</td>\n",
       "      <td>753.032195</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3452</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.588</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>25.84</td>\n",
       "      <td>4.64</td>\n",
       "      <td>895.758171</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14232</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.501</td>\n",
       "      <td>10.74</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.05</td>\n",
       "      <td>738.546898</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>10171</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.588</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>27.36</td>\n",
       "      <td>8.45</td>\n",
       "      <td>316.465249</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8247</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.593</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.91</td>\n",
       "      <td>27.52</td>\n",
       "      <td>13.61</td>\n",
       "      <td>594.819220</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12714</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.583</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>28.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>803.387306</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>822</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.597</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.41</td>\n",
       "      <td>25.93</td>\n",
       "      <td>12.00</td>\n",
       "      <td>256.236280</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>12348</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.11</td>\n",
       "      <td>20.81</td>\n",
       "      <td>12.00</td>\n",
       "      <td>599.951220</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>9030</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.622</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.62</td>\n",
       "      <td>24.42</td>\n",
       "      <td>12.39</td>\n",
       "      <td>517.992851</td>\n",
       "      <td>26.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>14198</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.682</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.31</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.85</td>\n",
       "      <td>471.991692</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1249</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.582</td>\n",
       "      <td>7.72</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>16.92</td>\n",
       "      <td>8.82</td>\n",
       "      <td>610.798857</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9039</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.606</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>26.60</td>\n",
       "      <td>7.32</td>\n",
       "      <td>546.508537</td>\n",
       "      <td>25.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>15101</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.641</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>27.26</td>\n",
       "      <td>5.35</td>\n",
       "      <td>708.083890</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1509</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.36</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>24.55</td>\n",
       "      <td>7.53</td>\n",
       "      <td>618.628125</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9160</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.558</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>25.63</td>\n",
       "      <td>4.40</td>\n",
       "      <td>732.749063</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9856</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.592</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23.82</td>\n",
       "      <td>5.00</td>\n",
       "      <td>546.619500</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>558</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>17.34</td>\n",
       "      <td>15.59</td>\n",
       "      <td>498.821635</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>9877</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.576</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.32</td>\n",
       "      <td>21.32</td>\n",
       "      <td>9.19</td>\n",
       "      <td>713.988329</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>10496</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.545</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>21.19</td>\n",
       "      <td>7.82</td>\n",
       "      <td>426.780549</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1789</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>25.60</td>\n",
       "      <td>5.01</td>\n",
       "      <td>573.301333</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>8849</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.555</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.81</td>\n",
       "      <td>21.19</td>\n",
       "      <td>4.99</td>\n",
       "      <td>342.720729</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3122</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.52</td>\n",
       "      <td>16.63</td>\n",
       "      <td>12.66</td>\n",
       "      <td>369.280543</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3350</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.533</td>\n",
       "      <td>6.95</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>21.14</td>\n",
       "      <td>3.89</td>\n",
       "      <td>674.965098</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4138</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.542</td>\n",
       "      <td>6.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>21.23</td>\n",
       "      <td>6.00</td>\n",
       "      <td>704.223220</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>16152</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.539</td>\n",
       "      <td>8.06</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.19</td>\n",
       "      <td>19.12</td>\n",
       "      <td>3.72</td>\n",
       "      <td>629.039003</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>11699</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.569</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>21.11</td>\n",
       "      <td>3.41</td>\n",
       "      <td>375.237668</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.715285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5413</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.577</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.37</td>\n",
       "      <td>15.91</td>\n",
       "      <td>4.64</td>\n",
       "      <td>618.635122</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.635002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>9824</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.562</td>\n",
       "      <td>8.68</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4.80</td>\n",
       "      <td>415.454766</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>10416</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.554</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>19.97</td>\n",
       "      <td>2.96</td>\n",
       "      <td>590.608537</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4535</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.13</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.584</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>26.56</td>\n",
       "      <td>4.14</td>\n",
       "      <td>227.881984</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2885</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.560</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>15.62</td>\n",
       "      <td>4.57</td>\n",
       "      <td>326.319627</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>8958</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.570</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.43</td>\n",
       "      <td>15.63</td>\n",
       "      <td>10.39</td>\n",
       "      <td>472.712817</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>4099</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.544</td>\n",
       "      <td>7.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>17.27</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.632477</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8529</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.527</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>20.72</td>\n",
       "      <td>3.63</td>\n",
       "      <td>82.719220</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.554479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>4793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.537</td>\n",
       "      <td>4.18</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>23.75</td>\n",
       "      <td>4.10</td>\n",
       "      <td>803.030183</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "225    7150  15.2   4.96  3.13  0.616   7.51   9.9   0.74  36.13   6.64   \n",
       "179    6065  14.4   3.72  3.22  0.644   5.89   7.6   1.53  27.69  12.47   \n",
       "304    9402  11.5   2.88  1.99  0.631   5.86   4.3   1.08  25.99   6.37   \n",
       "388   12329  11.8   3.10  2.85  0.589   7.25   7.3   0.69  20.05  10.81   \n",
       "87     3452  12.1   2.65  1.85  0.588   6.89   5.4   0.43  25.84   4.64   \n",
       "433   14232   6.8   4.45  3.36  0.501  10.74   5.6   0.45  22.95  11.05   \n",
       "330   10171   7.2   3.58  1.71  0.588   8.25   4.9   0.60  27.36   8.45   \n",
       "258    8247   8.7   3.53  3.30  0.593   3.66   3.3   1.91  27.52  13.61   \n",
       "407   12714  11.9   2.66  2.78  0.583   4.13   5.3   0.44  28.04   8.16   \n",
       "26      822   9.5   2.00  2.36  0.597   3.89   4.9   2.41  25.93  12.00   \n",
       "390   12348  10.1   1.99  1.96  0.573   3.84   5.3   1.11  20.81  12.00   \n",
       "294    9030  10.4   3.12  3.79  0.622   3.36   5.7   1.62  24.42  12.39   \n",
       "432   14198  14.4   1.60  2.85  0.682   1.99   5.9   2.31  15.85  12.85   \n",
       "35     1249   8.2   3.47  2.65  0.582   7.72   4.1   0.77  16.92   8.82   \n",
       "295    9039   9.5   2.02  1.45  0.606   3.32   3.6   0.40  26.60   7.32   \n",
       "454   15101   9.7   2.78  2.41  0.641   5.23   4.9   0.36  27.26   5.35   \n",
       "38     1509   8.0   3.37  2.65  0.581   5.36   4.4   0.37  24.55   7.53   \n",
       "299    9160   7.4   2.57  1.60  0.558   5.90   3.9   0.41  25.63   4.40   \n",
       "322    9856   9.1   2.57  2.49  0.592   6.93   4.7   0.51  23.82   5.00   \n",
       "17      558  10.0   2.22  3.44  0.555   1.42   3.3   1.75  17.34  15.59   \n",
       "323    9877   9.3   1.78  2.21  0.576   2.40   2.5   1.32  21.32   9.19   \n",
       "336   10496   4.9   3.43  1.90  0.545   5.96   3.6   0.35  21.19   7.82   \n",
       "45     1789   7.6   2.73  2.76  0.581   5.46   3.7   0.71  25.60   5.01   \n",
       "282    8849   5.4   3.13  2.21  0.555   7.73   2.9   0.81  21.19   4.99   \n",
       "74     3122  10.8   1.40  2.51  0.658   1.43   2.8   1.52  16.63  12.66   \n",
       "81     3350   5.0   3.12  1.74  0.533   6.95   3.3   0.25  21.14   3.89   \n",
       "108    4138   6.3   2.58  2.30  0.542   6.17   2.0   0.47  21.23   6.00   \n",
       "483   16152   3.3   3.80  1.73  0.539   8.06   0.6   0.19  19.12   3.72   \n",
       "368   11699   8.0   1.86  1.76  0.569   6.41   3.2   0.31  21.11   3.41   \n",
       "158    5413   8.2   2.12  2.00  0.577   5.51   3.2   0.37  15.91   4.64   \n",
       "320    9824   6.6   2.80  2.55  0.562   8.68   2.8   0.48  14.25   4.80   \n",
       "334   10416   5.1   2.41  1.07  0.554   5.36   1.2   0.15  19.97   2.96   \n",
       "123    4535   3.5   4.13  3.13  0.584   6.77   1.6   0.20  26.56   4.14   \n",
       "72     2885   6.6   2.62  2.52  0.560   8.16   2.4   0.31  15.62   4.57   \n",
       "291    8958   7.8   2.33  3.47  0.570   3.24   3.5   1.43  15.63  10.39   \n",
       "104    4099   5.6   2.80  2.52  0.544   7.28   2.0   0.56  17.27   3.75   \n",
       "263    8529   1.2   3.78  2.22  0.527   8.72   0.5   0.91  20.72   3.63   \n",
       "134    4793   5.0   2.83  2.70  0.537   4.18   1.7   0.40  23.75   4.10   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "225  1219.545755  30.6         1              1                   0.999643  \n",
       "179   835.939756  30.9         1              1                   0.998346  \n",
       "304   885.110945  24.2         1              1                   0.984991  \n",
       "388   753.032195  26.3         1              1                   0.984024  \n",
       "87    895.758171  23.7         1              1                   0.984008  \n",
       "433   738.546898  21.1         1              1                   0.983903  \n",
       "330   316.465249  25.6         0              1                   0.980628  \n",
       "258   594.819220  26.1         1              1                   0.979722  \n",
       "407   803.387306  23.3         1              1                   0.969254  \n",
       "26    256.236280  30.3         0              1                   0.968562  \n",
       "390   599.951220  25.5         0              1                   0.950619  \n",
       "294   517.992851  26.3         0              1                   0.947226  \n",
       "432   471.991692  24.6         0              1                   0.942982  \n",
       "35    610.798857  20.0         0              1                   0.925710  \n",
       "295   546.508537  25.8         1              1                   0.920647  \n",
       "454   708.083890  24.4         1              1                   0.919109  \n",
       "38    618.628125  21.0         0              1                   0.903971  \n",
       "299   732.749063  21.7         0              1                   0.895410  \n",
       "322   546.619500  24.3         0              1                   0.894917  \n",
       "17    498.821635  23.4         0              1                   0.876191  \n",
       "323   713.988329  22.9         0              1                   0.852368  \n",
       "336   426.780549  19.6         0              1                   0.817550  \n",
       "45    573.301333  20.8         0              1                   0.800466  \n",
       "282   342.720729  19.4         0              1                   0.790262  \n",
       "74    369.280543  23.8         0              1                   0.771787  \n",
       "81    674.965098  19.4         0              1                   0.766909  \n",
       "108   704.223220  19.6         0              1                   0.761031  \n",
       "483   629.039003  17.0         0              1                   0.738714  \n",
       "368   375.237668  21.4         0              1                   0.715285  \n",
       "158   618.635122  19.3         0              1                   0.635002  \n",
       "320   415.454766  16.5         0              1                   0.630925  \n",
       "334   590.608537  21.2         0              1                   0.627715  \n",
       "123   227.881984  20.2         0              1                   0.620008  \n",
       "72    326.319627  19.7         0              1                   0.602599  \n",
       "291   472.712817  23.4         0              1                   0.592960  \n",
       "104   500.632477  18.1         0              1                   0.561933  \n",
       "263    82.719220  18.0         0              1                   0.554479  \n",
       "134   803.030183  17.2         0              1                   0.505917  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2019_log[MVP_2019_log['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False).head(38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 MVPs as predicted by Logistic Regression with SMOTE\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. James Harden (0.999)\n",
    "2. Giannis Antetokounmpo (0.998)\n",
    "3. Kevin Durant (0.985)\n",
    "4. Nikola Jokic (0.984)\n",
    "5. Damian Lillard (0.984)\n",
    "6. Russell Westbrook (0.983)\n",
    "7. LeBron James (0.980)\n",
    "8. Joel Embiid (0.979)\n",
    "9. Paul George (0.969)\n",
    "10. Anthony Davis (0.968)\n",
    "11. Nikola Vucevic (0.950)\n",
    "12. Karl-Anthony Towns (0.947)\n",
    "13. Rudy Gobert (0.943)\n",
    "14. Ben Simmons (0.926)\n",
    "15. Kawhi Leonard (0.920)\n",
    "16. Stephen Curry (0.919)\n",
    "17. Blake Griffin (0.094)\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "18. Kemba Walker (0.895)\n",
    "19. Kyrie Irving (0.894)\n",
    "20. Andre Drummond (0.876)\n",
    "21. LaMarcus Aldridge (0.852)\n",
    "22. Luka Doncic (0.817)\n",
    "23. Bradley Beal (0.800)\n",
    "24. Jrue Holiday (0.790)\n",
    "25. Clint Capela (0.771)\n",
    "26. D'Angelo Russell (0.766)\n",
    "27. DeMar DeRozen (0.761)\n",
    "28. Trae Young (0.739)\n",
    "29. Mike Conley (0.715)\n",
    "30. Eric Bledsoe (0.635)\n",
    "31. Kyle Lowry (0.630)\n",
    "32. Lou Williams (0.628)\n",
    "33. Devin Booker (0.620)\n",
    "34. Chris Paul (0.602)\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "35. Jusuf Nurkic (0.593)\n",
    "36. De'Aaron Fox (0.561)\n",
    "37. John Wall (0.554) [What the hell though, guy breaks his leg in his own bathroom and missed almost the whole season]\n",
    "38. Donovan Mitchell (0.506)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2b. Testing for 2018 MVPs using actual winners as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2018 = stats[stats['Year'] == 2018]\n",
    "test_2018_X = testing_2018[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2018_y = testing_2018[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[506  18]\n",
      " [  0  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       524\n",
      "           1       0.42      1.00      0.59        13\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       537\n",
      "   macro avg       0.71      0.98      0.79       537\n",
      "weighted avg       0.99      0.97      0.97       537\n",
      "\n",
      "AUC Score 0.9951556077510275\n"
     ]
    }
   ],
   "source": [
    "predictions_log1_2018 = logt1.predict(test_2018_X)\n",
    "predictions_proba_log1_2018 = logt1.predict_proba(test_2018_X)\n",
    "print(confusion_matrix(test_2018_y, predictions_log1_2018))\n",
    "print(classification_report(test_2018_y, predictions_log1_2018))\n",
    "print('AUC Score', roc_auc_score(test_2018_y, predictions_proba_log1_2018[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_log_2018 = pd.DataFrame(predictions_proba_log1_2018)\n",
    "probability_log_2018 = probability_log_2018.loc[:,1:]\n",
    "probability_log_2018.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_log_2018 = pd.DataFrame(predictions_log1_2018)\n",
    "predictions_log_2018.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2018_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_log_2018 = test_2018_X.copy(deep=True)\n",
    "predictors_log_2018.reset_index(inplace=True)\n",
    "predictors_log_2018.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>14.371683</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>17.62</td>\n",
       "      <td>7.88</td>\n",
       "      <td>173.706390</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.981921</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.48</td>\n",
       "      <td>59.870854</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      39  0.1   0.34  0.88  0.508   0.63  -0.1   0.00   2.34   0.53   \n",
       "1      43  2.9   1.84  1.91  0.530   2.34   1.0   0.78  17.62   7.88   \n",
       "2      54 -0.1   0.33  3.00  0.392   1.22  -0.1   0.22   6.67   2.67   \n",
       "3      56  0.0   1.00  4.00  0.405   1.00  -0.1   0.00   8.00   3.00   \n",
       "4      88 -0.1   0.71  0.94  0.439   0.54  -0.5   0.21   3.04   1.48   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0   14.371683   9.8         0              0                   0.001206  \n",
       "1  173.706390  16.5         0              0                   0.167410  \n",
       "2    1.981921   5.1         0              0                   0.000835  \n",
       "3    0.079186   2.4         0              0                   0.000613  \n",
       "4   59.870854   5.1         0              0                   0.002213  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2018_log = pd.concat([predictors_log_2018, real_mvp, predictions_log_2018, probability_log_2018], axis=1)\n",
    "MVP_2018_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>10170</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.621</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>27.45</td>\n",
       "      <td>8.65</td>\n",
       "      <td>996.058333</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>7149</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.619</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>30.43</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1094.985640</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>14231</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.524</td>\n",
       "      <td>10.25</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.35</td>\n",
       "      <td>10.05</td>\n",
       "      <td>969.438049</td>\n",
       "      <td>24.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>821</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.57</td>\n",
       "      <td>28.13</td>\n",
       "      <td>11.09</td>\n",
       "      <td>748.262195</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3451</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.594</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.37</td>\n",
       "      <td>26.88</td>\n",
       "      <td>4.45</td>\n",
       "      <td>742.500137</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6064</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.598</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.41</td>\n",
       "      <td>26.85</td>\n",
       "      <td>10.04</td>\n",
       "      <td>720.929268</td>\n",
       "      <td>27.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9401</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.640</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>26.35</td>\n",
       "      <td>6.82</td>\n",
       "      <td>708.236585</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1248</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.557</td>\n",
       "      <td>8.16</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.86</td>\n",
       "      <td>15.79</td>\n",
       "      <td>8.14</td>\n",
       "      <td>651.956817</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>9029</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.40</td>\n",
       "      <td>21.26</td>\n",
       "      <td>12.34</td>\n",
       "      <td>654.300708</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>12328</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.603</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>18.47</td>\n",
       "      <td>10.71</td>\n",
       "      <td>518.206479</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4147</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.35</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.58</td>\n",
       "      <td>25.21</td>\n",
       "      <td>12.85</td>\n",
       "      <td>324.352976</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.940294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>557</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.555</td>\n",
       "      <td>3.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.63</td>\n",
       "      <td>15.01</td>\n",
       "      <td>15.99</td>\n",
       "      <td>430.099848</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>15100</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.675</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>26.39</td>\n",
       "      <td>5.12</td>\n",
       "      <td>379.978247</td>\n",
       "      <td>28.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.908775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>9876</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.570</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>23.13</td>\n",
       "      <td>8.47</td>\n",
       "      <td>653.879440</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4137</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.555</td>\n",
       "      <td>5.21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.28</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.94</td>\n",
       "      <td>962.294797</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>8246</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.76</td>\n",
       "      <td>22.94</td>\n",
       "      <td>10.95</td>\n",
       "      <td>531.524341</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2884</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.604</td>\n",
       "      <td>7.88</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>18.64</td>\n",
       "      <td>5.40</td>\n",
       "      <td>433.430272</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16542</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.577</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>23.13</td>\n",
       "      <td>5.20</td>\n",
       "      <td>702.578049</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>9159</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5.55</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>22.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>548.534634</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>8052</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.590</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>22.15</td>\n",
       "      <td>5.32</td>\n",
       "      <td>379.622009</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>9855</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.610</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>24.43</td>\n",
       "      <td>3.78</td>\n",
       "      <td>501.883384</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>10415</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.574</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>22.56</td>\n",
       "      <td>2.51</td>\n",
       "      <td>650.383637</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9823</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.598</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>16.24</td>\n",
       "      <td>5.56</td>\n",
       "      <td>636.832149</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>8528</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.515</td>\n",
       "      <td>9.59</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.10</td>\n",
       "      <td>19.44</td>\n",
       "      <td>3.66</td>\n",
       "      <td>183.784687</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1788</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.564</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>22.65</td>\n",
       "      <td>4.43</td>\n",
       "      <td>736.063250</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>12713</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.570</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>21.95</td>\n",
       "      <td>5.66</td>\n",
       "      <td>715.804549</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>8848</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.570</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>18.98</td>\n",
       "      <td>4.51</td>\n",
       "      <td>667.891427</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3121</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>13.86</td>\n",
       "      <td>10.84</td>\n",
       "      <td>482.217165</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>4907</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.556</td>\n",
       "      <td>7.26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>11.04</td>\n",
       "      <td>7.64</td>\n",
       "      <td>405.756565</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.623883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5007</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.62</td>\n",
       "      <td>16.63</td>\n",
       "      <td>12.49</td>\n",
       "      <td>441.582860</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.575</td>\n",
       "      <td>4.71</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.88</td>\n",
       "      <td>7.36</td>\n",
       "      <td>421.522683</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "324   10170  14.0   4.23  1.66  0.621   9.11   8.9   0.87  27.45   8.65   \n",
       "217    7149  15.4   4.38  2.35  0.619   8.75   8.3   0.69  30.43   5.40   \n",
       "444   14231  10.1   4.76  2.50  0.524  10.25   7.5   0.25  25.35  10.05   \n",
       "29      821  13.7   2.16  2.12  0.612   2.32   4.9   2.57  28.13  11.09   \n",
       "86     3451  12.6   2.82  1.60  0.594   6.59   5.9   0.37  26.88   4.45   \n",
       "173    6064  11.9   2.97  3.08  0.598   4.81   5.4   1.41  26.85  10.04   \n",
       "299    9401  10.4   3.04  1.96  0.640   5.38   4.5   1.75  26.35   6.82   \n",
       "39     1248   9.2   3.43  2.60  0.557   8.16   4.6   0.86  15.79   8.14   \n",
       "289    9029  14.0   1.94  3.48  0.646   2.43   5.5   1.40  21.26  12.34   \n",
       "396   12328  10.7   2.80  2.83  0.603   6.11   5.6   0.81  18.47  10.71   \n",
       "112    4147   4.7   5.04  3.81  0.583   5.35   3.3   1.58  25.21  12.85   \n",
       "19      557  10.3   2.56  3.21  0.555   3.04   5.0   1.63  15.01  15.99   \n",
       "464   15100   9.1   3.00  2.24  0.675   6.08   4.4   0.16  26.39   5.12   \n",
       "317    9876  10.9   1.48  2.15  0.570   2.03   3.3   1.20  23.13   8.47   \n",
       "111    4137   9.6   2.19  1.89  0.555   5.21   2.6   0.28  23.00   3.94   \n",
       "251    8246   6.2   3.71  3.32  0.573   3.16   2.2   1.76  22.94  10.95   \n",
       "73     2884  10.2   2.21  2.43  0.604   7.88   4.3   0.24  18.64   5.40   \n",
       "513   16542   8.2   2.92  2.33  0.577   4.31   4.5   0.76  23.13   5.20   \n",
       "294    9159   8.6   2.24  1.23  0.572   5.55   3.6   0.30  22.13   3.10   \n",
       "243    8052   8.9   1.83  1.32  0.590   4.88   3.8   0.41  22.15   5.32   \n",
       "316    9855   8.9   2.33  2.03  0.610   5.10   4.0   0.28  24.43   3.78   \n",
       "328   10415   6.7   2.96  1.34  0.574   5.28   2.0   0.24  22.56   2.51   \n",
       "313    9823  10.2   2.35  2.46  0.598   6.88   5.0   0.24  16.24   5.56   \n",
       "256    8528   2.7   3.85  1.95  0.515   9.59   1.2   1.10  19.44   3.66   \n",
       "47     1788   6.9   2.61  1.95  0.564   4.55   2.7   0.44  22.65   4.43   \n",
       "416   12713   8.9   2.68  2.95  0.570   3.33   3.3   0.49  21.95   5.66   \n",
       "278    8848   7.1   2.63  2.48  0.570   6.00   3.0   0.79  18.98   4.51   \n",
       "74     3121  10.2   1.39  2.50  0.650   0.92   2.6   1.85  13.86  10.84   \n",
       "139    4907   6.1   2.89  2.64  0.556   7.26   3.0   1.30  11.04   7.64   \n",
       "142    5007   6.8   2.57  3.07  0.577   1.30   1.1   1.62  16.63  12.49   \n",
       "6       193   7.8   1.83  1.92  0.575   4.71   3.5   1.08  12.88   7.36   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "324   996.058333  28.6         1              1                   0.999538  \n",
       "217  1094.985640  29.8         1              1                   0.999495  \n",
       "444   969.438049  24.7         1              1                   0.998079  \n",
       "29    748.262195  28.9         1              1                   0.995179  \n",
       "86    742.500137  25.2         1              1                   0.989263  \n",
       "173   720.929268  27.3         1              1                   0.986206  \n",
       "299   708.236585  26.0         1              1                   0.983938  \n",
       "39    651.956817  20.0         0              1                   0.949986  \n",
       "289   654.300708  24.9         0              1                   0.947540  \n",
       "396   518.206479  24.4         0              1                   0.947365  \n",
       "112   324.352976  22.6         0              1                   0.940294  \n",
       "19    430.099848  22.9         0              1                   0.925584  \n",
       "464   379.978247  28.2         1              1                   0.908775  \n",
       "317   653.879440  25.0         1              1                   0.895151  \n",
       "111   962.294797  21.0         1              1                   0.892580  \n",
       "251   531.524341  22.9         1              1                   0.875500  \n",
       "73    433.430272  24.4         0              1                   0.866767  \n",
       "513   702.578049  23.1         1              1                   0.855840  \n",
       "294   548.534634  20.6         0              1                   0.850897  \n",
       "243   379.622009  23.7         1              1                   0.838420  \n",
       "316   501.883384  25.0         0              1                   0.820730  \n",
       "328   650.383637  20.2         0              1                   0.811075  \n",
       "313   636.832149  19.5         0              1                   0.809892  \n",
       "256   183.784687  19.1         0              1                   0.792371  \n",
       "47    736.063250  18.4         0              1                   0.738196  \n",
       "416   715.804549  18.7         0              1                   0.717084  \n",
       "278   667.891427  17.8         0              1                   0.682858  \n",
       "74    482.217165  24.5         0              1                   0.644734  \n",
       "139   405.756565  16.1         0              1                   0.623883  \n",
       "142   441.582860  20.5         0              1                   0.618747  \n",
       "6     421.522683  17.6         0              1                   0.573743  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2018_log[MVP_2018_log['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 MVPs as predicted by Logistic Regression with SMOTE\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. LeBron James (0.999)\n",
    "2. James Harden (0.999)\n",
    "3. Rusell Westbrook (0.998)\n",
    "4. Anthony Davis (0.995)\n",
    "5. Damian Lillard (0.989)\n",
    "6. Giannis Antetokounmpo (0.986)\n",
    "7. Kevin Durant (0.984)\n",
    "8. Ben Simmons (0.949)\n",
    "9. Karl-Anthony Towns (0.947)\n",
    "10. Nikola Jokic (0.940)\n",
    "11. DeMarcus Cousins (0.925)\n",
    "12. Stephen Curry (0.908)\n",
    "\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "13. LaMarcus Aldrige (0.895)\n",
    "14. DeMar DeRozan (0.892)\n",
    "15. Joel Embiid (0.875)\n",
    "16. Chris Paul (0.866)\n",
    "17. Victor Oladipo (0.856)\n",
    "18. Kemba Walker (0.850)\n",
    "19. Jimmy Butler (0.838)\n",
    "18. Kyrie Irving (0.820)\n",
    "19. Lou Williams (0.811)\n",
    "20. Kyle Lowry (0.809)\n",
    "21. John Wall (0.790)\n",
    "22. Bradley Beal (0.738)\n",
    "23. Paul George (0.717)\n",
    "24. Jrue Holiday (0.683)\n",
    "25. Clint Capela (0.644)\n",
    "26. Draymond Green (0.623)\n",
    "27. Dwight Howard (0.618) [What the hell lol]\n",
    "\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "28. Al Horford (0.573)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Balanced Bagging Classifer with Logistic Regression Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.89180328 0.89540816 0.9274517  0.89281808 0.88844331]\n",
      "Mean Cross-Validation Score: 0.8991849059627676\n",
      "[[3000  365]\n",
      " [  13   52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      3365\n",
      "           1       0.12      0.80      0.22        65\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      3430\n",
      "   macro avg       0.56      0.85      0.58      3430\n",
      "weighted avg       0.98      0.89      0.93      3430\n",
      "\n",
      "AUC Score 0.9301863070065151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "bbc1 = BalancedBaggingClassifier(base_estimator=LogisticRegression(penalty='l2', C=0.2), bootstrap=False,\n",
    "                                 max_features=9, max_samples=900, n_estimators=11, replacement=True,\n",
    "                                 random_state=0, sampling_strategy=0.51)\n",
    "\n",
    "# Fitting the model\n",
    "bbc1 = bbc1.fit(X1_train, y1_train)\n",
    "\n",
    "\n",
    "# Checking cross-validation values\n",
    "print('Cross-Validation Scores:', cross_val_score(bbc1, X1_train, y1_train, cv=5))\n",
    "print('Mean Cross-Validation Score:', np.mean(cross_val_score(bbc1, X1_train, y1_train, cv=5)))\n",
    "\n",
    "# Constructing the confusion matrix\n",
    "predictions_bbc1 = bbc1.predict(X1_test)\n",
    "predictions_proba_bbc1 = bbc1.predict_proba(X1_test)\n",
    "print(confusion_matrix(y1_test, predictions_bbc1))\n",
    "print(classification_report(y1_test, predictions_bbc1))\n",
    "print('AUC Score', roc_auc_score(y1_test, predictions_proba_bbc1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3a. Testing for NBA's 2019 MVPs using Basketball-reference.com's list as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2019 = stats[stats['Year'] == 2019]\n",
    "test_2019_X = testing_2019[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2019_y = testing_2019[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[478  42]\n",
      " [  0  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       520\n",
      "           1       0.19      1.00      0.32        10\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       530\n",
      "   macro avg       0.60      0.96      0.64       530\n",
      "weighted avg       0.98      0.92      0.95       530\n",
      "\n",
      "AUC Score 0.9876923076923076\n"
     ]
    }
   ],
   "source": [
    "predictions_bbc1_2019 = bbc1.predict(test_2019_X)\n",
    "predictions_proba_bbc1_2019 = bbc1.predict_proba(test_2019_X)\n",
    "print(confusion_matrix(test_2019_y, predictions_bbc1_2019))\n",
    "print(classification_report(test_2019_y, predictions_bbc1_2019))\n",
    "print('AUC Score', roc_auc_score(test_2019_y, predictions_proba_bbc1_2019[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_bbc_2019 = pd.DataFrame(predictions_proba_bbc1_2019)\n",
    "probability_bbc_2019 = probability_bbc_2019.loc[:,1:]\n",
    "probability_bbc_2019.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_bbc_2019 = pd.DataFrame(predictions_bbc1_2019)\n",
    "predictions_bbc_2019.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2019_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_bbc_2019 = test_2019_X.copy(deep=True)\n",
    "predictors_bbc_2019.reset_index(inplace=True)\n",
    "predictors_bbc_2019.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      44  5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36   \n",
       "1      55  0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   \n",
       "2      89  0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   \n",
       "3     194  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74   \n",
       "4     230  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0  477.745006  15.1         0              1                   0.564416  \n",
       "1   86.264634  11.9         0              0                   0.060062  \n",
       "2   79.580606   8.8         0              0                   0.078163  \n",
       "3  315.673985  20.2         0              0                   0.400248  \n",
       "4  342.484546  13.2         0              0                   0.415323  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2019_bbc = pd.concat([predictors_bbc_2019, real_mvp, predictions_bbc_2019, probability_bbc_2019], axis=1)\n",
    "MVP_2019_bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>7150</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>7.510</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.13</td>\n",
       "      <td>6.640</td>\n",
       "      <td>1219.545755</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3452</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>6.890</td>\n",
       "      <td>5.40</td>\n",
       "      <td>0.43</td>\n",
       "      <td>25.84</td>\n",
       "      <td>4.640</td>\n",
       "      <td>895.758171</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>4798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>-38.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6065</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>5.890</td>\n",
       "      <td>7.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>27.69</td>\n",
       "      <td>12.470</td>\n",
       "      <td>835.939756</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12714</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>4.130</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.44</td>\n",
       "      <td>28.04</td>\n",
       "      <td>8.160</td>\n",
       "      <td>803.387306</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9402</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>5.860</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.99</td>\n",
       "      <td>6.370</td>\n",
       "      <td>885.110945</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>7531</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.1155</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.299832</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>12329</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>7.250</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.05</td>\n",
       "      <td>10.810</td>\n",
       "      <td>753.032195</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>15481</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.063557</td>\n",
       "      <td>-15.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>15101</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>5.230</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.36</td>\n",
       "      <td>27.26</td>\n",
       "      <td>5.350</td>\n",
       "      <td>708.083890</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>577</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.108857</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9160</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>5.900</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.41</td>\n",
       "      <td>25.63</td>\n",
       "      <td>4.400</td>\n",
       "      <td>732.749063</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14232</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>10.740</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.050</td>\n",
       "      <td>738.546898</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.827271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1509</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.360</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>24.55</td>\n",
       "      <td>7.530</td>\n",
       "      <td>618.628125</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>17072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1789</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.460</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>25.60</td>\n",
       "      <td>5.010</td>\n",
       "      <td>573.301333</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9856</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>6.930</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23.82</td>\n",
       "      <td>5.000</td>\n",
       "      <td>546.619500</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1249</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>7.720</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>16.92</td>\n",
       "      <td>8.820</td>\n",
       "      <td>610.798857</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>12348</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>3.840</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.11</td>\n",
       "      <td>20.81</td>\n",
       "      <td>12.000</td>\n",
       "      <td>599.951220</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>12597</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.93</td>\n",
       "      <td>6.860</td>\n",
       "      <td>624.777886</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G     TS%   AST/G  VORP  BLK/G    PPG   TRB/G  \\\n",
       "225    7150  15.2   4.96  3.13  0.6160   7.510  9.90   0.74  36.13   6.640   \n",
       "87     3452  12.1   2.65  1.85  0.5880   6.890  5.40   0.43  25.84   4.640   \n",
       "136    4798   0.0   0.00  0.00  0.0000   0.000  0.00   0.00   0.00   0.000   \n",
       "179    6065  14.4   3.72  3.22  0.6440   5.890  7.60   1.53  27.69  12.470   \n",
       "407   12714  11.9   2.66  2.78  0.5830   4.130  5.30   0.44  28.04   8.160   \n",
       "304    9402  11.5   2.88  1.99  0.6310   5.860  4.30   1.08  25.99   6.370   \n",
       "236    7531  -0.1   0.43  0.57  0.1155   0.715 -0.05   0.00   0.43   0.855   \n",
       "388   12329  11.8   3.10  2.85  0.5890   7.250  7.30   0.69  20.05  10.810   \n",
       "465   15481  -0.1   0.50  0.50  0.2250   0.000 -0.10   0.00   1.00   2.000   \n",
       "454   15101   9.7   2.78  2.41  0.6410   5.230  4.90   0.36  27.26   5.350   \n",
       "19      577  -0.1   0.25  0.00  0.0000   0.000 -0.10   0.00   0.00   0.500   \n",
       "299    9160   7.4   2.57  1.60  0.5580   5.900  3.90   0.41  25.63   4.400   \n",
       "433   14232   6.8   4.45  3.36  0.5010  10.740  5.60   0.45  22.95  11.050   \n",
       "38     1509   8.0   3.37  2.65  0.5810   5.360  4.40   0.37  24.55   7.530   \n",
       "526   17072   0.0   1.00  0.00  0.0000   0.000  0.00   0.00   0.00   0.000   \n",
       "45     1789   7.6   2.73  2.76  0.5810   5.460  3.70   0.71  25.60   5.010   \n",
       "322    9856   9.1   2.57  2.49  0.5920   6.930  4.70   0.51  23.82   5.000   \n",
       "35     1249   8.2   3.47  2.65  0.5820   7.720  4.10   0.77  16.92   8.820   \n",
       "390   12348  10.1   1.99  1.96  0.5730   3.840  5.30   1.11  20.81  12.000   \n",
       "400   12597   9.3   1.93  3.01  0.6280   3.100  3.50   0.65  16.93   6.860   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "225  1219.545755  30.6         1              1                   0.987668  \n",
       "87    895.758171  23.7         1              1                   0.960631  \n",
       "136     0.030401 -38.1         0              1                   0.941156  \n",
       "179   835.939756  30.9         1              1                   0.930541  \n",
       "407   803.387306  23.3         1              1                   0.930245  \n",
       "304   885.110945  24.2         1              1                   0.922092  \n",
       "236     0.299832 -18.7         0              1                   0.894184  \n",
       "388   753.032195  26.3         1              1                   0.878897  \n",
       "465     0.063557 -15.8         0              1                   0.864574  \n",
       "454   708.083890  24.4         1              1                   0.856034  \n",
       "19      0.108857 -11.9         0              1                   0.838764  \n",
       "299   732.749063  21.7         0              1                   0.834170  \n",
       "433   738.546898  21.1         1              1                   0.827271  \n",
       "38    618.628125  21.0         0              1                   0.817541  \n",
       "526     0.009000 -10.0         0              1                   0.811534  \n",
       "45    573.301333  20.8         0              1                   0.766192  \n",
       "322   546.619500  24.3         0              1                   0.762062  \n",
       "35    610.798857  20.0         0              1                   0.748543  \n",
       "390   599.951220  25.5         0              1                   0.748525  \n",
       "400   624.777886  18.7         0              1                   0.732873  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2019_bbc[MVP_2019_bbc['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 MVPs as predicted by Balanced Bagging Classifier\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. James Harden (0.987)\n",
    "2. Damian Lillard (0.961)\n",
    "3. Donte Grantham (0.941) [Negative Statistics and stats inflated by low attempts]\n",
    "4. Giannis Antetokounmpo (0.931)\n",
    "5. Paul George (0.930)\n",
    "6. Kevin Durant (0.922)\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "7. Jawun Evans (0.894) [Negative Statistics and stats inflated by low attempts]\n",
    "8. Nikola Jokic (0.878)\n",
    "9. Terrance Jones (0.865) [Negative Statistics and stats inflated by low attempts]\n",
    "10. Stephen Curry (0.856)\n",
    "11. Andre Ingram (0.856) [Negative Statistics and stats inflated by low attempts]\n",
    "12. Kemba Walker (0.834)\n",
    "13. Russell Westbrook (0.827)\n",
    "14. Blake Griffin (0.817)\n",
    "15. Zach Lofton (0.811) [Negative Statistics and stats inflated by low attempts]\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "Model is not performing good enough for me to continue\n",
    "\n",
    "\n",
    "In summary, BBC approach does not produce good results. It is unable to differentiate between positive and negative player stats. The increase in number of false negatives likely attributed to the aforementioned weakness of BBC.\n",
    "\n",
    "Moving forward, I should probably try to remove these outliers in the dataset during the cleaning process and try BBC again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3b. Testing for 2018 MVPs using actual winners as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2018 = stats[stats['Year'] == 2018]\n",
    "test_2018_X = testing_2018[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2018_y = testing_2018[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[483  41]\n",
      " [  1  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       524\n",
      "           1       0.23      0.92      0.36        13\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       537\n",
      "   macro avg       0.61      0.92      0.66       537\n",
      "weighted avg       0.98      0.92      0.94       537\n",
      "\n",
      "AUC Score 0.9743100411039343\n"
     ]
    }
   ],
   "source": [
    "predictions_bbc1_2018 = bbc1.predict(test_2018_X)\n",
    "predictions_proba_bbc1_2018 = bbc1.predict_proba(test_2018_X)\n",
    "print(confusion_matrix(test_2018_y, predictions_bbc1_2018))\n",
    "print(classification_report(test_2018_y, predictions_bbc1_2018))\n",
    "print('AUC Score', roc_auc_score(test_2018_y, predictions_proba_bbc1_2018[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_bbc_2018 = pd.DataFrame(predictions_proba_bbc1_2018)\n",
    "probability_bbc_2018 = probability_bbc_2018.loc[:,1:]\n",
    "probability_bbc_2018.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_bbc_2018 = pd.DataFrame(predictions_bbc1_2018)\n",
    "predictions_bbc_2018.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2018_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_bbc_2018 = test_2018_X.copy(deep=True)\n",
    "predictors_bbc_2018.reset_index(inplace=True)\n",
    "predictors_bbc_2018.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>14.371683</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>17.62</td>\n",
       "      <td>7.88</td>\n",
       "      <td>173.706390</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.981921</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.48</td>\n",
       "      <td>59.870854</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      39  0.1   0.34  0.88  0.508   0.63  -0.1   0.00   2.34   0.53   \n",
       "1      43  2.9   1.84  1.91  0.530   2.34   1.0   0.78  17.62   7.88   \n",
       "2      54 -0.1   0.33  3.00  0.392   1.22  -0.1   0.22   6.67   2.67   \n",
       "3      56  0.0   1.00  4.00  0.405   1.00  -0.1   0.00   8.00   3.00   \n",
       "4      88 -0.1   0.71  0.94  0.439   0.54  -0.5   0.21   3.04   1.48   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0   14.371683   9.8         0              0                   0.057577  \n",
       "1  173.706390  16.5         0              0                   0.198948  \n",
       "2    1.981921   5.1         0              0                   0.116255  \n",
       "3    0.079186   2.4         0              0                   0.196672  \n",
       "4   59.870854   5.1         0              0                   0.130965  "
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2018_bbc = pd.concat([predictors_bbc_2018, real_mvp, predictions_bbc_2018, probability_bbc_2018], axis=1)\n",
    "MVP_2018_bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>10170</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.621</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.87</td>\n",
       "      <td>27.45</td>\n",
       "      <td>8.65</td>\n",
       "      <td>996.058333</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>7149</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.619</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>30.43</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1094.985640</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>14231</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.524</td>\n",
       "      <td>10.25</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>25.35</td>\n",
       "      <td>10.05</td>\n",
       "      <td>969.438049</td>\n",
       "      <td>24.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3451</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.594</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.37</td>\n",
       "      <td>26.88</td>\n",
       "      <td>4.45</td>\n",
       "      <td>742.500137</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>11951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>-41.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>-28.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>10485</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9823</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.598</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>16.24</td>\n",
       "      <td>5.56</td>\n",
       "      <td>636.832149</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>821</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.57</td>\n",
       "      <td>28.13</td>\n",
       "      <td>11.09</td>\n",
       "      <td>748.262195</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>8812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "324   10170  14.0   4.23  1.66  0.621   9.11   8.9   0.87  27.45   8.65   \n",
       "217    7149  15.4   4.38  2.35  0.619   8.75   8.3   0.69  30.43   5.40   \n",
       "444   14231  10.1   4.76  2.50  0.524  10.25   7.5   0.25  25.35  10.05   \n",
       "86     3451  12.6   2.82  1.60  0.594   6.59   5.9   0.37  26.88   4.45   \n",
       "379   11951   0.0   0.00  0.00  0.000   0.00   0.0   0.00   0.00   0.00   \n",
       "71     2703   0.0   0.00  0.00  0.000   0.00   0.0   0.00   0.00   0.00   \n",
       "331   10485  -0.1   0.00  0.00  0.000   0.00   0.0   0.00   0.00   0.00   \n",
       "313    9823  10.2   2.35  2.46  0.598   6.88   5.0   0.24  16.24   5.56   \n",
       "29      821  13.7   2.16  2.12  0.612   2.32   4.9   2.57  28.13  11.09   \n",
       "275    8812   0.0   0.00  0.00  0.000   0.00   0.0   1.00   0.00   0.00   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "324   996.058333  28.6         1              1                   0.989801  \n",
       "217  1094.985640  29.8         1              1                   0.988864  \n",
       "444   969.438049  24.7         1              1                   0.960055  \n",
       "86    742.500137  25.2         1              1                   0.956113  \n",
       "379     0.006440 -41.1         0              1                   0.941822  \n",
       "71      0.006469 -28.5         0              1                   0.935312  \n",
       "331     0.026317 -15.5         0              1                   0.886930  \n",
       "313   636.832149  19.5         0              1                   0.879561  \n",
       "29    748.262195  28.9         1              1                   0.865721  \n",
       "275     0.005561 -12.5         0              1                   0.855061  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2018_bbc[MVP_2018_bbc['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>8246</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.76</td>\n",
       "      <td>22.94</td>\n",
       "      <td>10.95</td>\n",
       "      <td>531.524341</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "251    8246  6.2   3.71  3.32  0.573   3.16   2.2   1.76  22.94  10.95   \n",
       "\n",
       "         Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "251  531.524341  22.9         1              0                   0.334877  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In addition, checking who got left out by the model\n",
    "# Joel Embiid got left out for some reason\n",
    "MVP_2018_bbc[(MVP_2018_bbc['Predicted MVP'] == 0) & (MVP_2018_bbc['Real MVP'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 MVPs as predicted by Logistic Regression with SMOTE\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. LeBron James (0.989)\n",
    "2. James Harden (0.988)\n",
    "3. Russell Westbrook (0.960)\n",
    "4. Damiam Lillard (0.956)\n",
    "5. Mindaugas Kuzminskas (0.942) [Negative Statistics and stats inflated by low attempts]\n",
    "6. Chris Boucher (0.935) [Negative Statistics and stats inflated by low attempts]\n",
    "\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "7. Luis Montero (0.887) [Negative Statistics and stats inflated by low attempts]\n",
    "8. Kyle Lowry (0.880)\n",
    "9. Anthony Davis (0.865)\n",
    "10. Josh McRoberts (0.855) [Negative Statistics and stats inflated by low attempts]\n",
    "\n",
    "\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "\n",
    "\n",
    "\n",
    "# Left out by model\n",
    "Joel Embiid\n",
    "\n",
    "\n",
    "Taking a deeper look at the stats of the mispredicted players, most of them either have highly negative stats or have alot of 0s in their stats record cause of lack of playing time/attempts. BBC seems to attach undue importance to negative numbers or zeroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Balanced Bagging Classifer with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9169\n",
      "AUC Score : 0.972050\n",
      "[[3076  279]\n",
      " [   6   69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      3355\n",
      "           1       0.20      0.92      0.33        75\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3430\n",
      "   macro avg       0.60      0.92      0.64      3430\n",
      "weighted avg       0.98      0.92      0.94      3430\n",
      "\n",
      "AUC Score 0.9720496770988575\n"
     ]
    }
   ],
   "source": [
    "bbc_xgb1 = BalancedBaggingClassifier(base_estimator=XGBClassifier(learning_rate=0.09, n_estimators=500, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.5, colsample_by_tree = 0.6,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0, reg_alpha=0.1), \n",
    "                                sampling_strategy='auto', replacement=True, random_state=0)\n",
    "\n",
    "\n",
    "bbc_xgb1.fit(X1_train, y1_train)\n",
    "\n",
    "predictions_bbc_xgb1 = bbc_xgb1.predict(X1_test)\n",
    "predict_proba_bbc_xgb1 = bbc_xgb1.predict_proba(X1_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y1_test, predictions_bbc_xgb1))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y1_test, predict_proba_bbc_xgb1[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y1_test, predictions_bbc_xgb1))\n",
    "print(classification_report(y1_test, predictions_bbc_xgb1))\n",
    "print('AUC Score', roc_auc_score(y1_test, predict_proba_bbc_xgb1[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4a. Testing for NBA's 2019 MVPs using Basketball-reference.com's list as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2019 = stats[stats['Year'] == 2019]\n",
    "test_2019_X = testing_2019[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2019_y = testing_2019[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[487  33]\n",
      " [  0  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       520\n",
      "           1       0.23      1.00      0.38        10\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       530\n",
      "   macro avg       0.62      0.97      0.67       530\n",
      "weighted avg       0.99      0.94      0.96       530\n",
      "\n",
      "AUC Score 0.9959615384615383\n"
     ]
    }
   ],
   "source": [
    "predictions_bbc_xgb_2019 = bbc_xgb1.predict(test_2019_X)\n",
    "predictions_proba_bbc_xgb_2019 = bbc_xgb1.predict_proba(test_2019_X)\n",
    "print(confusion_matrix(test_2019_y, predictions_bbc_xgb_2019))\n",
    "print(classification_report(test_2019_y, predictions_bbc_xgb_2019))\n",
    "print('AUC Score', roc_auc_score(test_2019_y, predictions_proba_bbc_xgb_2019[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_bbc_xgb_2019 = pd.DataFrame(predictions_proba_bbc_xgb_2019)\n",
    "probability_bbc_xgb_2019 = probability_bbc_xgb_2019.loc[:,1:]\n",
    "probability_bbc_xgb_2019.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_bbc_xgb_2019 = pd.DataFrame(predictions_bbc_xgb_2019)\n",
    "predictions_bbc_xgb_2019.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2019_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_bbc_xgb_2019 = test_2019_X.copy(deep=True)\n",
    "predictors_bbc_xgb_2019.reset_index(inplace=True)\n",
    "predictors_bbc_xgb_2019.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>15.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>477.745006</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.518</td>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.34</td>\n",
       "      <td>86.264634</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.90</td>\n",
       "      <td>79.580606</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.568</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.53</td>\n",
       "      <td>342.484546</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      44  5.1   2.08  2.21  0.538   3.71   2.0   0.72  15.97   7.36   \n",
       "1      55  0.9   0.80  1.42  0.518   1.74  -0.1   0.26   5.88   1.34   \n",
       "2      89  0.9   0.43  1.11  0.522   0.33  -0.5   0.20   3.95   1.90   \n",
       "3     194  7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74   \n",
       "4     230  5.8   0.89  1.77  0.568   1.28   1.7   0.41   9.38   7.53   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0  477.745006  15.1         0              0                   0.279497  \n",
       "1   86.264634  11.9         0              0                   0.006903  \n",
       "2   79.580606   8.8         0              0                   0.007339  \n",
       "3  315.673985  20.2         0              1                   0.573858  \n",
       "4  342.484546  13.2         0              0                   0.050289  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2019_bbc_xgb = pd.concat([predictors_bbc_xgb_2019, real_mvp, predictions_bbc_xgb_2019, probability_bbc_xgb_2019], axis=1)\n",
    "MVP_2019_bbc_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>14232</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.501</td>\n",
       "      <td>10.74</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.05</td>\n",
       "      <td>738.546898</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>9402</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.631</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.08</td>\n",
       "      <td>25.99</td>\n",
       "      <td>6.37</td>\n",
       "      <td>885.110945</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>6065</td>\n",
       "      <td>14.4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.644</td>\n",
       "      <td>5.89</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.53</td>\n",
       "      <td>27.69</td>\n",
       "      <td>12.47</td>\n",
       "      <td>835.939756</td>\n",
       "      <td>30.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>12329</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.589</td>\n",
       "      <td>7.25</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.05</td>\n",
       "      <td>10.81</td>\n",
       "      <td>753.032195</td>\n",
       "      <td>26.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>15101</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.641</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>27.26</td>\n",
       "      <td>5.35</td>\n",
       "      <td>708.083890</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>7150</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.96</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.616</td>\n",
       "      <td>7.51</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.13</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1219.545755</td>\n",
       "      <td>30.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3452</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.588</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>25.84</td>\n",
       "      <td>4.64</td>\n",
       "      <td>895.758171</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9160</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.558</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.41</td>\n",
       "      <td>25.63</td>\n",
       "      <td>4.40</td>\n",
       "      <td>732.749063</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>12348</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.11</td>\n",
       "      <td>20.81</td>\n",
       "      <td>12.00</td>\n",
       "      <td>599.951220</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8247</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.593</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.91</td>\n",
       "      <td>27.52</td>\n",
       "      <td>13.61</td>\n",
       "      <td>594.819220</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>9030</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.79</td>\n",
       "      <td>0.622</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.62</td>\n",
       "      <td>24.42</td>\n",
       "      <td>12.39</td>\n",
       "      <td>517.992851</td>\n",
       "      <td>26.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>9856</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.592</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.51</td>\n",
       "      <td>23.82</td>\n",
       "      <td>5.00</td>\n",
       "      <td>546.619500</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>10171</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.588</td>\n",
       "      <td>8.25</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>27.36</td>\n",
       "      <td>8.45</td>\n",
       "      <td>316.465249</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12714</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.583</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.44</td>\n",
       "      <td>28.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>803.387306</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>9877</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.576</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.32</td>\n",
       "      <td>21.32</td>\n",
       "      <td>9.19</td>\n",
       "      <td>713.988329</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>8849</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0.555</td>\n",
       "      <td>7.73</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.81</td>\n",
       "      <td>21.19</td>\n",
       "      <td>4.99</td>\n",
       "      <td>342.720729</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3350</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.533</td>\n",
       "      <td>6.95</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>21.14</td>\n",
       "      <td>3.89</td>\n",
       "      <td>674.965098</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>822</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.597</td>\n",
       "      <td>3.89</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.41</td>\n",
       "      <td>25.93</td>\n",
       "      <td>12.00</td>\n",
       "      <td>256.236280</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1789</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.71</td>\n",
       "      <td>25.60</td>\n",
       "      <td>5.01</td>\n",
       "      <td>573.301333</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4138</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.542</td>\n",
       "      <td>6.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>21.23</td>\n",
       "      <td>6.00</td>\n",
       "      <td>704.223220</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1509</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.581</td>\n",
       "      <td>5.36</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>24.55</td>\n",
       "      <td>7.53</td>\n",
       "      <td>618.628125</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.920332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1249</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.582</td>\n",
       "      <td>7.72</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>16.92</td>\n",
       "      <td>8.82</td>\n",
       "      <td>610.798857</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.917755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>558</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>17.34</td>\n",
       "      <td>15.59</td>\n",
       "      <td>498.821635</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>9039</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.606</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>26.60</td>\n",
       "      <td>7.32</td>\n",
       "      <td>546.508537</td>\n",
       "      <td>25.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5413</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.577</td>\n",
       "      <td>5.51</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.37</td>\n",
       "      <td>15.91</td>\n",
       "      <td>4.64</td>\n",
       "      <td>618.635122</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>11699</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.569</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>21.11</td>\n",
       "      <td>3.41</td>\n",
       "      <td>375.237668</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>8896</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.600</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.62</td>\n",
       "      <td>21.44</td>\n",
       "      <td>8.68</td>\n",
       "      <td>379.770037</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>10416</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.554</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>19.97</td>\n",
       "      <td>2.96</td>\n",
       "      <td>590.608537</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.843136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>10496</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.545</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>21.19</td>\n",
       "      <td>7.82</td>\n",
       "      <td>426.780549</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>12597</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.628</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.93</td>\n",
       "      <td>6.86</td>\n",
       "      <td>624.777886</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>9622</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.558</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.09</td>\n",
       "      <td>18.27</td>\n",
       "      <td>5.99</td>\n",
       "      <td>705.023034</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.775981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2885</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.560</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>15.62</td>\n",
       "      <td>4.57</td>\n",
       "      <td>326.319627</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>8958</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.570</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.43</td>\n",
       "      <td>15.63</td>\n",
       "      <td>10.39</td>\n",
       "      <td>472.712817</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.732998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>12034</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.34</td>\n",
       "      <td>16.60</td>\n",
       "      <td>6.52</td>\n",
       "      <td>507.130000</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3122</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.658</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.52</td>\n",
       "      <td>16.63</td>\n",
       "      <td>12.66</td>\n",
       "      <td>369.280543</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8529</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.527</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>20.72</td>\n",
       "      <td>3.63</td>\n",
       "      <td>82.719220</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3608</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.633</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.34</td>\n",
       "      <td>19.79</td>\n",
       "      <td>6.13</td>\n",
       "      <td>406.376293</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>4099</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.544</td>\n",
       "      <td>7.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>17.27</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.632477</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>14198</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.682</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.31</td>\n",
       "      <td>15.85</td>\n",
       "      <td>12.85</td>\n",
       "      <td>471.991692</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>8325</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.64</td>\n",
       "      <td>19.48</td>\n",
       "      <td>9.75</td>\n",
       "      <td>288.871870</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.622262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>16543</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.519</td>\n",
       "      <td>5.17</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.31</td>\n",
       "      <td>18.75</td>\n",
       "      <td>5.61</td>\n",
       "      <td>140.493512</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.605</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.26</td>\n",
       "      <td>13.60</td>\n",
       "      <td>6.74</td>\n",
       "      <td>315.673985</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>7053</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.538</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>18.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>626.950495</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player    WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "433   14232   6.8   4.45  3.36  0.501  10.74   5.6   0.45  22.95  11.05   \n",
       "304    9402  11.5   2.88  1.99  0.631   5.86   4.3   1.08  25.99   6.37   \n",
       "179    6065  14.4   3.72  3.22  0.644   5.89   7.6   1.53  27.69  12.47   \n",
       "388   12329  11.8   3.10  2.85  0.589   7.25   7.3   0.69  20.05  10.81   \n",
       "454   15101   9.7   2.78  2.41  0.641   5.23   4.9   0.36  27.26   5.35   \n",
       "225    7150  15.2   4.96  3.13  0.616   7.51   9.9   0.74  36.13   6.64   \n",
       "87     3452  12.1   2.65  1.85  0.588   6.89   5.4   0.43  25.84   4.64   \n",
       "299    9160   7.4   2.57  1.60  0.558   5.90   3.9   0.41  25.63   4.40   \n",
       "390   12348  10.1   1.99  1.96  0.573   3.84   5.3   1.11  20.81  12.00   \n",
       "258    8247   8.7   3.53  3.30  0.593   3.66   3.3   1.91  27.52  13.61   \n",
       "294    9030  10.4   3.12  3.79  0.622   3.36   5.7   1.62  24.42  12.39   \n",
       "322    9856   9.1   2.57  2.49  0.592   6.93   4.7   0.51  23.82   5.00   \n",
       "330   10171   7.2   3.58  1.71  0.588   8.25   4.9   0.60  27.36   8.45   \n",
       "407   12714  11.9   2.66  2.78  0.583   4.13   5.3   0.44  28.04   8.16   \n",
       "323    9877   9.3   1.78  2.21  0.576   2.40   2.5   1.32  21.32   9.19   \n",
       "282    8849   5.4   3.13  2.21  0.555   7.73   2.9   0.81  21.19   4.99   \n",
       "81     3350   5.0   3.12  1.74  0.533   6.95   3.3   0.25  21.14   3.89   \n",
       "26      822   9.5   2.00  2.36  0.597   3.89   4.9   2.41  25.93  12.00   \n",
       "45     1789   7.6   2.73  2.76  0.581   5.46   3.7   0.71  25.60   5.01   \n",
       "108    4138   6.3   2.58  2.30  0.542   6.17   2.0   0.47  21.23   6.00   \n",
       "38     1509   8.0   3.37  2.65  0.581   5.36   4.4   0.37  24.55   7.53   \n",
       "35     1249   8.2   3.47  2.65  0.582   7.72   4.1   0.77  16.92   8.82   \n",
       "17      558  10.0   2.22  3.44  0.555   1.42   3.3   1.75  17.34  15.59   \n",
       "295    9039   9.5   2.02  1.45  0.606   3.32   3.6   0.40  26.60   7.32   \n",
       "158    5413   8.2   2.12  2.00  0.577   5.51   3.2   0.37  15.91   4.64   \n",
       "368   11699   8.0   1.86  1.76  0.569   6.41   3.2   0.31  21.11   3.41   \n",
       "285    8896   6.1   2.85  3.37  0.600   3.14   1.9   0.62  21.44   8.68   \n",
       "334   10416   5.1   2.41  1.07  0.554   5.36   1.2   0.15  19.97   2.96   \n",
       "336   10496   4.9   3.43  1.90  0.545   5.96   3.6   0.35  21.19   7.82   \n",
       "400   12597   9.3   1.93  3.01  0.628   3.10   3.5   0.65  16.93   6.86   \n",
       "310    9622   6.1   2.26  2.23  0.558   4.30   1.7   0.09  18.27   5.99   \n",
       "72     2885   6.6   2.62  2.52  0.560   8.16   2.4   0.31  15.62   4.57   \n",
       "291    8958   7.8   2.33  3.47  0.570   3.24   3.5   1.43  15.63  10.39   \n",
       "378   12034   8.7   1.61  3.11  0.636   1.98   3.4   1.34  16.60   6.52   \n",
       "74     3122  10.8   1.40  2.51  0.658   1.43   2.8   1.52  16.63  12.66   \n",
       "263    8529   1.2   3.78  2.22  0.527   8.72   0.5   0.91  20.72   3.63   \n",
       "92     3608   8.2   1.46  1.90  0.633   2.62   2.6   0.34  19.79   6.13   \n",
       "104    4099   5.6   2.80  2.52  0.544   7.28   2.0   0.56  17.27   3.75   \n",
       "432   14198  14.4   1.60  2.85  0.682   1.99   5.9   2.31  15.85  12.85   \n",
       "259    8325   6.0   1.97  3.26  0.627   1.98   1.6   0.64  19.48   9.75   \n",
       "506   16543   2.3   2.28  2.00  0.519   5.17   1.3   0.31  18.75   5.61   \n",
       "3       194   7.5   1.50  1.85  0.605   4.16   3.4   1.26  13.60   6.74   \n",
       "223    7053   5.1   2.11  2.04  0.538   4.84   1.3   0.36  18.23   4.23   \n",
       "\n",
       "          Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "433   738.546898  21.1         1              1                   0.990738  \n",
       "304   885.110945  24.2         1              1                   0.989396  \n",
       "179   835.939756  30.9         1              1                   0.986852  \n",
       "388   753.032195  26.3         1              1                   0.982280  \n",
       "454   708.083890  24.4         1              1                   0.981205  \n",
       "225  1219.545755  30.6         1              1                   0.978103  \n",
       "87    895.758171  23.7         1              1                   0.974000  \n",
       "299   732.749063  21.7         0              1                   0.966839  \n",
       "390   599.951220  25.5         0              1                   0.963551  \n",
       "258   594.819220  26.1         1              1                   0.954142  \n",
       "294   517.992851  26.3         0              1                   0.953132  \n",
       "322   546.619500  24.3         0              1                   0.952603  \n",
       "330   316.465249  25.6         0              1                   0.950106  \n",
       "407   803.387306  23.3         1              1                   0.944171  \n",
       "323   713.988329  22.9         0              1                   0.942660  \n",
       "282   342.720729  19.4         0              1                   0.939550  \n",
       "81    674.965098  19.4         0              1                   0.933465  \n",
       "26    256.236280  30.3         0              1                   0.932250  \n",
       "45    573.301333  20.8         0              1                   0.924287  \n",
       "108   704.223220  19.6         0              1                   0.920425  \n",
       "38    618.628125  21.0         0              1                   0.920332  \n",
       "35    610.798857  20.0         0              1                   0.917755  \n",
       "17    498.821635  23.4         0              1                   0.910009  \n",
       "295   546.508537  25.8         1              1                   0.901413  \n",
       "158   618.635122  19.3         0              1                   0.899282  \n",
       "368   375.237668  21.4         0              1                   0.857451  \n",
       "285   379.770037  21.0         0              1                   0.855834  \n",
       "334   590.608537  21.2         0              1                   0.843136  \n",
       "336   426.780549  19.6         0              1                   0.838941  \n",
       "400   624.777886  18.7         0              1                   0.783458  \n",
       "310   705.023034  16.5         0              1                   0.775981  \n",
       "72    326.319627  19.7         0              1                   0.740592  \n",
       "291   472.712817  23.4         0              1                   0.732998  \n",
       "378   507.130000  23.4         0              1                   0.704892  \n",
       "74    369.280543  23.8         0              1                   0.703944  \n",
       "263    82.719220  18.0         0              1                   0.682018  \n",
       "92    406.376293  21.0         0              1                   0.654856  \n",
       "104   500.632477  18.1         0              1                   0.642795  \n",
       "432   471.991692  24.6         0              1                   0.636394  \n",
       "259   288.871870  21.8         0              1                   0.622262  \n",
       "506   140.493512  17.6         0              1                   0.576945  \n",
       "3     315.673985  20.2         0              1                   0.573858  \n",
       "223   626.950495  16.0         0              1                   0.535664  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2019_bbc_xgb[MVP_2019_bbc_xgb['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False).head(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 MVPs as predicted by Balanced Bagging Classifier with XGBoost\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. Russell Westbrook (0.990)\n",
    "2. Kevin Durant (0.989)\n",
    "3. Giannis Antetokounmpo (0.986)\n",
    "4. Nikola Jokic (0.982)\n",
    "5. Stephen Curry (0.981)\n",
    "6. James Harden (0.978)\n",
    "7. Damian Lillard (0.974)\n",
    "8. Kemba Walker (0.966)\n",
    "9. Nikola Vucevic (0.963)\n",
    "10. Joel Embiid (0.954)\n",
    "11. Karl-Anthony Towns (0.953)\n",
    "12. Kyrie Irving (0.952)\n",
    "13. LeBron James (0.950)\n",
    "14. Paul George (0.944)\n",
    "15. LaMarcus Aldridge (0.942)\n",
    "16. Jrue Holiday (0.939)\n",
    "17. D'Angelo Russell (0.933)\n",
    "18. Anthony Davis (0.932)\n",
    "19. Bradley Beal (0.924)\n",
    "20. DeMar DeRozan (0.920)\n",
    "21. Blake Griffin (0.920)\n",
    "22. Ben Simmons (0.917)\n",
    "23. Andre Drummond (0.910)\n",
    "24. Kawhi Leonard (0.901)\n",
    "\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "25. Eric Bledsoe (0.899)\n",
    "26. Mike Conley (0.857)\n",
    "27. Julius Randle (0.855)\n",
    "28. Lou Williams (0.843)\n",
    "29. Luka Doncic (0.839)\n",
    "30. Pascal Siakam (0.783)\n",
    "31. Khris Middleton (0.776)\n",
    "32. Chris Paul (0.740)\n",
    "33. Jusuf Nurkic (0.733)\n",
    "34. Motrezl Harrell (0.704)\n",
    "35. Clint Capela (0.703)\n",
    "36. John Wall (0.682)\n",
    "37. Danilo Gallinari (0.654)\n",
    "38. De'Aaron Fox (0.642)\n",
    "39. Rudy Gobert (0.636)\n",
    "40. John Collins (0.622)\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "41. Victor Oladipo (0.577)\n",
    "42. Al Horford (0.573)\n",
    "43. Jamal Murray (0.535)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4b. Testing for 2018 MVPs using actual winners as a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_2018 = stats[stats['Year'] == 2018]\n",
    "test_2018_X = testing_2018[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "test_2018_y = testing_2018[['MVP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[501  23]\n",
      " [  0  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       524\n",
      "           1       0.36      1.00      0.53        13\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       537\n",
      "   macro avg       0.68      0.98      0.75       537\n",
      "weighted avg       0.98      0.96      0.97       537\n",
      "\n",
      "AUC Score 0.9975044039929536\n"
     ]
    }
   ],
   "source": [
    "predictions_bbc_xgb_2018 = bbc_xgb1.predict(test_2018_X)\n",
    "predictions_proba_bbc_xgb_2018 = bbc_xgb1.predict_proba(test_2018_X)\n",
    "print(confusion_matrix(test_2018_y, predictions_bbc_xgb_2018))\n",
    "print(classification_report(test_2018_y, predictions_bbc_xgb_2018))\n",
    "print('AUC Score', roc_auc_score(test_2018_y, predictions_proba_bbc_xgb_2018[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_bbc_xgb_2018 = pd.DataFrame(predictions_proba_bbc_xgb_2018)\n",
    "probability_bbc_xgb_2018 = probability_bbc_xgb_2018.loc[:,1:]\n",
    "probability_bbc_xgb_2018.columns = ['Predicted MVP Probability']\n",
    "\n",
    "predictions_bbc_xgb_2018 = pd.DataFrame(predictions_bbc_xgb_2018)\n",
    "predictions_bbc_xgb_2018.columns = ['Predicted MVP']\n",
    "\n",
    "real_mvp = pd.DataFrame(test_2018_y)\n",
    "real_mvp.columns = ['Real MVP']\n",
    "real_mvp.reset_index(inplace=True)\n",
    "real_mvp = real_mvp[['Real MVP']]\n",
    "\n",
    "predictors_bbc_xgb_2018 = test_2018_X.copy(deep=True)\n",
    "predictors_bbc_xgb_2018.reset_index(inplace=True)\n",
    "predictors_bbc_xgb_2018.columns = ['Player', 'WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>14.371683</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>17.62</td>\n",
       "      <td>7.88</td>\n",
       "      <td>173.706390</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.981921</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.48</td>\n",
       "      <td>59.870854</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player   WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G    PPG  TRB/G  \\\n",
       "0      39  0.1   0.34  0.88  0.508   0.63  -0.1   0.00   2.34   0.53   \n",
       "1      43  2.9   1.84  1.91  0.530   2.34   1.0   0.78  17.62   7.88   \n",
       "2      54 -0.1   0.33  3.00  0.392   1.22  -0.1   0.22   6.67   2.67   \n",
       "3      56  0.0   1.00  4.00  0.405   1.00  -0.1   0.00   8.00   3.00   \n",
       "4      88 -0.1   0.71  0.94  0.439   0.54  -0.5   0.21   3.04   1.48   \n",
       "\n",
       "       Impact   PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "0   14.371683   9.8         0              0                   0.007753  \n",
       "1  173.706390  16.5         0              0                   0.164629  \n",
       "2    1.981921   5.1         0              0                   0.005795  \n",
       "3    0.079186   2.4         0              0                   0.006538  \n",
       "4   59.870854   5.1         0              0                   0.007451  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP_2018_bbc_xgb = pd.concat([predictors_bbc_xgb_2018, real_mvp, predictions_bbc_xgb_2018, probability_bbc_xgb_2018], axis=1)\n",
    "MVP_2018_bbc_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WS</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>TS%</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>VORP</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>Impact</th>\n",
       "      <th>PER</th>\n",
       "      <th>Real MVP</th>\n",
       "      <th>Predicted MVP</th>\n",
       "      <th>Predicted MVP Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>14231</td>\n",
       "      <td>10.10</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.524</td>\n",
       "      <td>10.25</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.250</td>\n",
       "      <td>25.350</td>\n",
       "      <td>10.05</td>\n",
       "      <td>969.438049</td>\n",
       "      <td>24.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>10170</td>\n",
       "      <td>14.00</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.621</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.870</td>\n",
       "      <td>27.450</td>\n",
       "      <td>8.65</td>\n",
       "      <td>996.058333</td>\n",
       "      <td>28.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9401</td>\n",
       "      <td>10.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.640</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.750</td>\n",
       "      <td>26.350</td>\n",
       "      <td>6.82</td>\n",
       "      <td>708.236585</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>7149</td>\n",
       "      <td>15.40</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.619</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.690</td>\n",
       "      <td>30.430</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1094.985640</td>\n",
       "      <td>29.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6064</td>\n",
       "      <td>11.90</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.598</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.410</td>\n",
       "      <td>26.850</td>\n",
       "      <td>10.04</td>\n",
       "      <td>720.929268</td>\n",
       "      <td>27.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3451</td>\n",
       "      <td>12.60</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.594</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.370</td>\n",
       "      <td>26.880</td>\n",
       "      <td>4.45</td>\n",
       "      <td>742.500137</td>\n",
       "      <td>25.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>16542</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.577</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.760</td>\n",
       "      <td>23.130</td>\n",
       "      <td>5.20</td>\n",
       "      <td>702.578049</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>821</td>\n",
       "      <td>13.70</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.570</td>\n",
       "      <td>28.130</td>\n",
       "      <td>11.09</td>\n",
       "      <td>748.262195</td>\n",
       "      <td>28.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>15100</td>\n",
       "      <td>9.10</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.675</td>\n",
       "      <td>6.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.160</td>\n",
       "      <td>26.390</td>\n",
       "      <td>5.12</td>\n",
       "      <td>379.978247</td>\n",
       "      <td>28.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>12328</td>\n",
       "      <td>10.70</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.603</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.810</td>\n",
       "      <td>18.470</td>\n",
       "      <td>10.71</td>\n",
       "      <td>518.206479</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>4137</td>\n",
       "      <td>9.60</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.555</td>\n",
       "      <td>5.21</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.280</td>\n",
       "      <td>23.000</td>\n",
       "      <td>3.94</td>\n",
       "      <td>962.294797</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>9159</td>\n",
       "      <td>8.60</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.572</td>\n",
       "      <td>5.55</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.300</td>\n",
       "      <td>22.130</td>\n",
       "      <td>3.10</td>\n",
       "      <td>548.534634</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>9029</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2.43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.400</td>\n",
       "      <td>21.260</td>\n",
       "      <td>12.34</td>\n",
       "      <td>654.300708</td>\n",
       "      <td>24.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>10415</td>\n",
       "      <td>6.70</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.574</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>22.560</td>\n",
       "      <td>2.51</td>\n",
       "      <td>650.383637</td>\n",
       "      <td>20.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>8246</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.573</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.760</td>\n",
       "      <td>22.940</td>\n",
       "      <td>10.95</td>\n",
       "      <td>531.524341</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>9876</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.570</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.200</td>\n",
       "      <td>23.130</td>\n",
       "      <td>8.47</td>\n",
       "      <td>653.879440</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2884</td>\n",
       "      <td>10.20</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.604</td>\n",
       "      <td>7.88</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.240</td>\n",
       "      <td>18.640</td>\n",
       "      <td>5.40</td>\n",
       "      <td>433.430272</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1788</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.564</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.440</td>\n",
       "      <td>22.650</td>\n",
       "      <td>4.43</td>\n",
       "      <td>736.063250</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1248</td>\n",
       "      <td>9.20</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.557</td>\n",
       "      <td>8.16</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.860</td>\n",
       "      <td>15.790</td>\n",
       "      <td>8.14</td>\n",
       "      <td>651.956817</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>9823</td>\n",
       "      <td>10.20</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.598</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>16.240</td>\n",
       "      <td>5.56</td>\n",
       "      <td>636.832149</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>8052</td>\n",
       "      <td>8.90</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.590</td>\n",
       "      <td>4.88</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.410</td>\n",
       "      <td>22.150</td>\n",
       "      <td>5.32</td>\n",
       "      <td>379.622009</td>\n",
       "      <td>23.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>9855</td>\n",
       "      <td>8.90</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.610</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>24.430</td>\n",
       "      <td>3.78</td>\n",
       "      <td>501.883384</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>12713</td>\n",
       "      <td>8.90</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.570</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.490</td>\n",
       "      <td>21.950</td>\n",
       "      <td>5.66</td>\n",
       "      <td>715.804549</td>\n",
       "      <td>18.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>8848</td>\n",
       "      <td>7.10</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.570</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>18.980</td>\n",
       "      <td>4.51</td>\n",
       "      <td>667.891427</td>\n",
       "      <td>17.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>557</td>\n",
       "      <td>10.30</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.555</td>\n",
       "      <td>3.04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.630</td>\n",
       "      <td>15.010</td>\n",
       "      <td>15.99</td>\n",
       "      <td>430.099848</td>\n",
       "      <td>22.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4147</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.35</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.580</td>\n",
       "      <td>25.210</td>\n",
       "      <td>12.85</td>\n",
       "      <td>324.352976</td>\n",
       "      <td>22.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.787867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>9621</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.577</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.260</td>\n",
       "      <td>20.150</td>\n",
       "      <td>5.23</td>\n",
       "      <td>672.441000</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>16390</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.561</td>\n",
       "      <td>5.17</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.330</td>\n",
       "      <td>19.420</td>\n",
       "      <td>5.10</td>\n",
       "      <td>132.649358</td>\n",
       "      <td>21.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>8528</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.515</td>\n",
       "      <td>9.59</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.100</td>\n",
       "      <td>19.440</td>\n",
       "      <td>3.66</td>\n",
       "      <td>183.784687</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5007</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.620</td>\n",
       "      <td>16.630</td>\n",
       "      <td>12.49</td>\n",
       "      <td>441.582860</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>8957</td>\n",
       "      <td>4.70</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.410</td>\n",
       "      <td>14.330</td>\n",
       "      <td>8.96</td>\n",
       "      <td>542.128829</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2222</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.536</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.430</td>\n",
       "      <td>21.380</td>\n",
       "      <td>3.96</td>\n",
       "      <td>781.089318</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>16885</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.562</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.650</td>\n",
       "      <td>5.05</td>\n",
       "      <td>525.749392</td>\n",
       "      <td>16.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1508</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.542</td>\n",
       "      <td>5.81</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.315</td>\n",
       "      <td>21.225</td>\n",
       "      <td>7.29</td>\n",
       "      <td>84.796901</td>\n",
       "      <td>19.45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>15310</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.630</td>\n",
       "      <td>1.16</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.030</td>\n",
       "      <td>13.890</td>\n",
       "      <td>9.01</td>\n",
       "      <td>384.939073</td>\n",
       "      <td>20.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>8895</td>\n",
       "      <td>6.60</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.606</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.550</td>\n",
       "      <td>16.130</td>\n",
       "      <td>7.98</td>\n",
       "      <td>404.009375</td>\n",
       "      <td>19.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Player     WS  TOV/G  PF/G    TS%  AST/G  VORP  BLK/G     PPG  TRB/G  \\\n",
       "444   14231  10.10   4.76  2.50  0.524  10.25   7.5  0.250  25.350  10.05   \n",
       "324   10170  14.00   4.23  1.66  0.621   9.11   8.9  0.870  27.450   8.65   \n",
       "299    9401  10.40   3.04  1.96  0.640   5.38   4.5  1.750  26.350   6.82   \n",
       "217    7149  15.40   4.38  2.35  0.619   8.75   8.3  0.690  30.430   5.40   \n",
       "173    6064  11.90   2.97  3.08  0.598   4.81   5.4  1.410  26.850  10.04   \n",
       "86     3451  12.60   2.82  1.60  0.594   6.59   5.9  0.370  26.880   4.45   \n",
       "513   16542   8.20   2.92  2.33  0.577   4.31   4.5  0.760  23.130   5.20   \n",
       "29      821  13.70   2.16  2.12  0.612   2.32   4.9  2.570  28.130  11.09   \n",
       "464   15100   9.10   3.00  2.24  0.675   6.08   4.4  0.160  26.390   5.12   \n",
       "396   12328  10.70   2.80  2.83  0.603   6.11   5.6  0.810  18.470  10.71   \n",
       "111    4137   9.60   2.19  1.89  0.555   5.21   2.6  0.280  23.000   3.94   \n",
       "294    9159   8.60   2.24  1.23  0.572   5.55   3.6  0.300  22.130   3.10   \n",
       "289    9029  14.00   1.94  3.48  0.646   2.43   5.5  1.400  21.260  12.34   \n",
       "328   10415   6.70   2.96  1.34  0.574   5.28   2.0  0.240  22.560   2.51   \n",
       "251    8246   6.20   3.71  3.32  0.573   3.16   2.2  1.760  22.940  10.95   \n",
       "317    9876  10.90   1.48  2.15  0.570   2.03   3.3  1.200  23.130   8.47   \n",
       "73     2884  10.20   2.21  2.43  0.604   7.88   4.3  0.240  18.640   5.40   \n",
       "47     1788   6.90   2.61  1.95  0.564   4.55   2.7  0.440  22.650   4.43   \n",
       "39     1248   9.20   3.43  2.60  0.557   8.16   4.6  0.860  15.790   8.14   \n",
       "313    9823  10.20   2.35  2.46  0.598   6.88   5.0  0.240  16.240   5.56   \n",
       "243    8052   8.90   1.83  1.32  0.590   4.88   3.8  0.410  22.150   5.32   \n",
       "316    9855   8.90   2.33  2.03  0.610   5.10   4.0  0.280  24.430   3.78   \n",
       "416   12713   8.90   2.68  2.95  0.570   3.33   3.3  0.490  21.950   5.66   \n",
       "278    8848   7.10   2.63  2.48  0.570   6.00   3.0  0.790  18.980   4.51   \n",
       "19      557  10.30   2.56  3.21  0.555   3.04   5.0  1.630  15.010  15.99   \n",
       "112    4147   4.70   5.04  3.81  0.583   5.35   3.3  1.580  25.210  12.85   \n",
       "303    9621   6.90   2.33  3.29  0.577   4.00   1.8  0.260  20.150   5.23   \n",
       "507   16390   4.20   2.25  1.85  0.561   5.17   2.3  0.330  19.420   5.10   \n",
       "256    8528   2.70   3.85  1.95  0.515   9.59   1.2  1.100  19.440   3.66   \n",
       "142    5007   6.80   2.57  3.07  0.577   1.30   1.1  1.620  16.630  12.49   \n",
       "287    8957   4.70   2.32  3.13  0.528   1.81   1.2  1.410  14.330   8.96   \n",
       "60     2222   6.60   1.86  2.07  0.536   3.36   1.8  0.430  21.380   3.96   \n",
       "523   16885   6.20   1.84  2.07  0.562   4.09   2.0  0.640  15.650   5.05   \n",
       "41     1508   2.45   2.82  2.40  0.542   5.81   1.2  0.315  21.225   7.29   \n",
       "466   15310   9.70   1.68  2.83  0.630   1.16   3.3  1.030  13.890   9.01   \n",
       "280    8895   6.60   2.60  3.34  0.606   2.56   1.6  0.550  16.130   7.98   \n",
       "\n",
       "          Impact    PER  Real MVP  Predicted MVP  Predicted MVP Probability  \n",
       "444   969.438049  24.70         1              1                   0.992021  \n",
       "324   996.058333  28.60         1              1                   0.991230  \n",
       "299   708.236585  26.00         1              1                   0.989810  \n",
       "217  1094.985640  29.80         1              1                   0.988605  \n",
       "173   720.929268  27.30         1              1                   0.986134  \n",
       "86    742.500137  25.20         1              1                   0.980997  \n",
       "513   702.578049  23.10         1              1                   0.976609  \n",
       "29    748.262195  28.90         1              1                   0.971383  \n",
       "464   379.978247  28.20         1              1                   0.970744  \n",
       "396   518.206479  24.40         0              1                   0.968242  \n",
       "111   962.294797  21.00         1              1                   0.962791  \n",
       "294   548.534634  20.60         0              1                   0.955044  \n",
       "289   654.300708  24.90         0              1                   0.953871  \n",
       "328   650.383637  20.20         0              1                   0.947642  \n",
       "251   531.524341  22.90         1              1                   0.939723  \n",
       "317   653.879440  25.00         1              1                   0.936890  \n",
       "73    433.430272  24.40         0              1                   0.932178  \n",
       "47    736.063250  18.40         0              1                   0.930232  \n",
       "39    651.956817  20.00         0              1                   0.925872  \n",
       "313   636.832149  19.50         0              1                   0.919063  \n",
       "243   379.622009  23.70         1              1                   0.909376  \n",
       "316   501.883384  25.00         0              1                   0.903811  \n",
       "416   715.804549  18.70         0              1                   0.836704  \n",
       "278   667.891427  17.80         0              1                   0.833348  \n",
       "19    430.099848  22.90         0              1                   0.791444  \n",
       "112   324.352976  22.60         0              1                   0.787867  \n",
       "303   672.441000  17.40         0              1                   0.744074  \n",
       "507   132.649358  21.10         0              1                   0.734136  \n",
       "256   183.784687  19.10         0              1                   0.729028  \n",
       "142   441.582860  20.50         0              1                   0.665896  \n",
       "287   542.128829  19.20         0              1                   0.561969  \n",
       "60    781.089318  17.00         0              1                   0.550641  \n",
       "523   525.749392  16.20         0              1                   0.540344  \n",
       "41     84.796901  19.45         0              1                   0.529371  \n",
       "466   384.939073  20.60         0              1                   0.528214  \n",
       "280   404.009375  19.90         0              1                   0.513171  "
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for who was predicted as MVP by the model\n",
    "MVP_2018_bbc_xgb[MVP_2018_bbc_xgb['Predicted MVP'] == 1].sort_values(by=['Predicted MVP Probability'], ascending=False).head(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 MVPs as predicted by Logistic Regression with SMOTE\n",
    "\n",
    "\n",
    "# Elite Candidates where P => 0.9 \n",
    "1. Russell Westbrook (0.992)\n",
    "2. LeBron James (0.991)\n",
    "3. Kevin Durant (0.989)\n",
    "4. James Harden (0.988)\n",
    "5. Giannis Antetokounmpo (0.986)\n",
    "6. Damian Lillard (0.980)\n",
    "7. Victor Oladipo (0.976)\n",
    "8. Anthony Davis (0.971)\n",
    "9. Stephen Curry (0.970)\n",
    "10. Nikola Jokic (0.968)\n",
    "11. DeMar DeRozan (0.962)\n",
    "12. Kemba Walker (0.955)\n",
    "13. Karl-Anthony Towns (0.953)\n",
    "14. Lou Williams (0.947)\n",
    "15. Joel Embiid (0.939)\n",
    "16. LaMarcus Aldridge (0.936)\n",
    "17. Chris Paul (0.932)\n",
    "18. Bradley Beal (0.930)\n",
    "19. Ben Simmons (0.925)\n",
    "20. Kyle Lowry (0.919)\n",
    "21. Jimmy Butler (0.909)\n",
    "22. Kyrie Irving (0.904)\n",
    "\n",
    "\n",
    "# Mid-tier Candidates  (0.6 <= P <= 0.89)\n",
    "23. Paul George (0.836)\n",
    "24. Jrue Holiday (0.833)\n",
    "25. Andre Drummond (0.791)\n",
    "26. DeMarcus Cousins (0.787)\n",
    "27. Khris Middleton (0.744)\n",
    "28. Tyreke Evans (0.734)\n",
    "29. John Wall (0.729)\n",
    "30. Dwight Howard (0.665)\n",
    "\n",
    "\n",
    "# Pleb-tier Candidates (0.6 < P)\n",
    "31. Jusuf Nurkic (0.562)\n",
    "32. CJ McCollum (0.550)\n",
    "33. Will Barton (0.540)\n",
    "34. Blake Griffin (0.529)\n",
    "35. Steven Adams (0.528)\n",
    "36. Julius Randle (0.513)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
