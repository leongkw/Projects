{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('tagging.xlsx')\n",
    "# df = data[['label', 'questions']]\n",
    "# df.head()\n",
    "\n",
    "# Writing csv to txt file\n",
    "# df.to_csv('abc.txt', index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the stopwords dictionary\n",
    "stopwords = [\n",
    "             'i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "             'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "             \"you'd\", 'your', 'yours', 'yourself', 'yourselves', \n",
    "             'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', \n",
    "             'hers', 'herself', 'it', \"it's\", 'its', 'itself', \n",
    "             'they', 'them', 'their', 'theirs', 'themselves', 'what', \n",
    "             'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', \n",
    "             'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', \n",
    "             'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "             'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', \n",
    "             'or', 'because', 'as', 'until', 'while', 'of', 'at', \n",
    "             'by', 'for', 'with', 'about', 'against', 'between', \n",
    "             'into', 'through', 'during', 'before', 'after', 'above', \n",
    "             'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', \n",
    "             'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "             'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "             'both', 'each', 'few', 'more', 'most', 'other', 'some', \n",
    "             'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "             'than', 'too', 'very', 's', 't', 'can', 'will', 'just', \n",
    "             'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', \n",
    "             'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \n",
    "             \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \n",
    "             \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", \n",
    "             'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", \n",
    "             'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren',\n",
    "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'fuck', 'fucker',\n",
    "             'lah', 'la', 'leh', 'lor', 'nah', 'ya', 'yah', 'shit', 'ass', 'asshole',\n",
    "             'le', 'already', 'liao', 'liaoz', 'u', 'cheebye', 'lanjiao',\n",
    "             'nabei', 'kaopei', 'knnb', 'cb', 'cheebye', 'fucked', 'fucks',\n",
    "             'bitch', 'bitches', 'scumbag', 'fuckface', 'wtf', 'ffs', 'siao',\n",
    "             'walao', 'waliao', 'ttyl', 'orhhhh', 'sai'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up nltk's lemmatizer\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = open(\"fasttext_input.txt\", \"r\", encoding='utf-8')\n",
    "# Converting to lower case\n",
    "# f = f.read().lower()\n",
    "# print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('fasttext_input.txt', \n",
    "                                  epoch=100,\n",
    "                                  lr=0.1,\n",
    "                                  wordNgrams=2,\n",
    "                                  loss='softmax',\n",
    "                                  ws=10\n",
    "                                 )\n",
    "\n",
    "# Model v1.0\n",
    "# By right need a test set for this, then tune with test set\n",
    "# But that's for the future\n",
    "\n",
    "# model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__aprogress'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('what is my name', k=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qasmall = pd.read_excel('tagging.xlsx')\n",
    "qabig = pd.read_excel('q&adatabaseexpanded.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i have settled my payment with my consultant.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i have made my payment with my consultant.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>when do i have to make payment?</td>\n",
       "      <td>You have to make the payment before your 1st F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>how do i make payment?</td>\n",
       "      <td>Payment can be made via Giro/ TT/ Cheque/ Payn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>is there any late payment fee?</td>\n",
       "      <td>No. There is no late payment fee. However, you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                         prompt  \\\n",
       "0  __label__adminpayment  i have settled my payment with my consultant.   \n",
       "1  __label__adminpayment     i have made my payment with my consultant.   \n",
       "2  __label__adminpayment                when do i have to make payment?   \n",
       "3  __label__adminpayment                         how do i make payment?   \n",
       "4  __label__adminpayment                 is there any late payment fee?   \n",
       "\n",
       "                                            response  \n",
       "0  Thank you. We will inform our Finance and your...  \n",
       "1  Thank you. We will inform our Finance and your...  \n",
       "2  You have to make the payment before your 1st F...  \n",
       "3  Payment can be made via Giro/ TT/ Cheque/ Payn...  \n",
       "4  No. There is no late payment fee. However, you...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasmall['prompt'] = qasmall['prompt'].map(lambda x: x.lower())\n",
    "qasmall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i have settled my payment with my consultant.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i have made my payment with my consultant.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i paid my course fees already.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>i have paid my course fees.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__adminpayment</td>\n",
       "      <td>my course fees have been paid.</td>\n",
       "      <td>Thank you. We will inform our Finance and your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                         prompt  \\\n",
       "0  __label__adminpayment  i have settled my payment with my consultant.   \n",
       "1  __label__adminpayment     i have made my payment with my consultant.   \n",
       "2  __label__adminpayment                 i paid my course fees already.   \n",
       "3  __label__adminpayment                    i have paid my course fees.   \n",
       "4  __label__adminpayment                 my course fees have been paid.   \n",
       "\n",
       "                                            response  \n",
       "0  Thank you. We will inform our Finance and your...  \n",
       "1  Thank you. We will inform our Finance and your...  \n",
       "2  Thank you. We will inform our Finance and your...  \n",
       "3  Thank you. We will inform our Finance and your...  \n",
       "4  Thank you. We will inform our Finance and your...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qabig['prompt'] = qabig['prompt'].map(lambda x: x.lower())\n",
    "qabig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_output(user_input):\n",
    "    return model.predict(user_input, k=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, please ask me a question!\n",
      "Hello\n",
      "Question:  hello\n",
      "Bot:  I'm sorry, I do not understand you.\n",
      "-------------------------------------------------------------\n",
      "Matched Label:  __label__admingeneral\n",
      "Matched Label Score:  [0.93318278]\n",
      "Matched Question:  yes i need assistance.\n",
      "2nd Best Match:  i need you to guide me.\n",
      "3rd Best Match:  i need some assistance.\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print('Hello, please ask me a question!')\n",
    "while(flag == True):\n",
    "    user_input = input()\n",
    "    user_input = user_input.lower()\n",
    "    bot_response = ''\n",
    "    \n",
    "    # Fasttext model to classify user question into different categories\n",
    "    matched_label = fasttext_output(user_input)\n",
    "    # Mask/filter for dataframe\n",
    "    mask = qabig.label == matched_label\n",
    "    \n",
    "    # Temporary string to the prompts from the matched label\n",
    "    prompts_corpus = ''\n",
    "    for i in qabig[mask]['prompt'].values:\n",
    "        prompts_corpus += i\n",
    "    prompts_corpus = prompts_corpus.replace('.', '. ').replace('?', '? ').replace('!', '! ')\n",
    "    \n",
    "    # Tokenizing the prompts corpus into sentence tokens\n",
    "    # Adding the user's input into the list of sentence tokens\n",
    "    prompts_sent_token = nltk.sent_tokenize(prompts_corpus)\n",
    "    prompts_sent_token.append(user_input)\n",
    "\n",
    "    # Initializing the Tfidf Vecotizer\n",
    "    # Using LemNormalize function to tokenize it\n",
    "    # Stopwords taken from the manually defined list\n",
    "    # ngrams set to 1 and 2\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, \n",
    "                               stop_words=stopwords, \n",
    "                               ngram_range=(1,2))\n",
    "    \n",
    "    # Fitting the tfidf model with the sentence tokens\n",
    "    tfidf = TfidfVec.fit_transform(prompts_sent_token) \n",
    "    cosine_vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    index = cosine_vals.argsort()[0][-2]\n",
    "    flat = cosine_vals.flatten()\n",
    "    flat.sort()\n",
    "    matched_cosine = flat[-2]\n",
    "    \n",
    "    if matched_cosine == 0:\n",
    "        bot_response = bot_response + \"I'm sorry, I do not understand you.\"\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            # bot_response = bot_response + qabig[(qabig['prompt'] == prompts_sent_token[index])]['resp'][qabig[qabig['prompt'] == prompts_sent_token[index]]['resp'].index[0]]\n",
    "            # bot_response = bot_response + qabig[(qabig['prompt'].str.contains(prompts_sent_token[index]))]['resp'][qabig[qabig['prompt'] == prompts_sent_token[index]]['resp'].index[0]]\n",
    "            bot_response = bot_response + qabig[qabig['prompt'] == prompts_sent_token[index]]['response'].values[0]\n",
    "        except:\n",
    "            bot_response = bot_response + qabig[(qabig['prompt'].str.contains(prompts_sent_token[index]))]\n",
    "    prompts_sent_token.remove(user_input)\n",
    "    \n",
    "    print('Question: ', user_input)\n",
    "    print('Bot: ', bot_response)\n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Matched Label: ', matched_label)\n",
    "    print('Matched Label Score: ', model.predict(user_input, k=1)[1])\n",
    "    print('Matched Question: ', prompts_sent_token[index])\n",
    "    print('2nd Best Match: ', prompts_sent_token[index-1])\n",
    "    print('3rd Best Match: ', prompts_sent_token[index-2])\n",
    "#    print('Cosine Similarity Values: ', flat)\n",
    "    print('*************************************************************')\n",
    "#    print(tfidf)\n",
    "#    print(tfidf[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
