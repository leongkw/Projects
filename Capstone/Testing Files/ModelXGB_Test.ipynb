{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try simple logistic regression with no super sampling shit to see how it goes first\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, SCORERS\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "\n",
    "\n",
    "stats = pd.read_csv('stats_1.5.csv')\n",
    "stats.drop(labels='Unnamed: 0', axis=1, inplace=True)\n",
    "stats['MVP'] = stats['MVP'].apply(lambda x : int(x))\n",
    "stats['Impact_1'] = (stats['TmWin'] * stats['G']) / 82 \n",
    "stats['Impact'] = stats['Impact_1'] * ((stats['MP'] / 48) * (stats['USG%']/100))\n",
    "stats.drop(labels='Impact_1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted'])"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring metrics\n",
    "SCORERS.keys()\n",
    "\n",
    "# Or can use make_score to make own scoring metric see how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>MVP</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>TmWin</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>...</th>\n",
       "      <th>ORB/G</th>\n",
       "      <th>DRB/G</th>\n",
       "      <th>TRB/G</th>\n",
       "      <th>AST/G</th>\n",
       "      <th>STL/G</th>\n",
       "      <th>BLK/G</th>\n",
       "      <th>TOV/G</th>\n",
       "      <th>PF/G</th>\n",
       "      <th>PPG</th>\n",
       "      <th>Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>22.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.564</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.70</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.79</td>\n",
       "      <td>6.35</td>\n",
       "      <td>292.787250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.599</td>\n",
       "      <td>...</td>\n",
       "      <td>2.66</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.16</td>\n",
       "      <td>10.78</td>\n",
       "      <td>429.586585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>24.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.581</td>\n",
       "      <td>...</td>\n",
       "      <td>2.99</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2.49</td>\n",
       "      <td>11.43</td>\n",
       "      <td>500.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.594</td>\n",
       "      <td>...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.87</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13.27</td>\n",
       "      <td>506.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.C. Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.548</td>\n",
       "      <td>...</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.49</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.94</td>\n",
       "      <td>608.001188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Player  MVP  Year   Age  TmWin     G    GS      MP   PER    TS%  \\\n",
       "0  A.C. Green    0  1986  22.0   62.0  82.0   1.0  1542.0  11.8  0.564   \n",
       "1  A.C. Green    0  1987  23.0   65.0  79.0  72.0  2240.0  15.7  0.599   \n",
       "2  A.C. Green    0  1988  24.0   62.0  82.0  64.0  2636.0  14.5  0.581   \n",
       "3  A.C. Green    0  1989  25.0   57.0  82.0  82.0  2510.0  17.8  0.594   \n",
       "4  A.C. Green    0  1990  26.0   63.0  82.0  82.0  2709.0  14.7  0.548   \n",
       "\n",
       "      ...      ORB/G  DRB/G  TRB/G  AST/G  STL/G  BLK/G  TOV/G  PF/G    PPG  \\\n",
       "0     ...       1.95   2.70   4.65   0.66   0.60   0.60   1.21  2.79   6.35   \n",
       "1     ...       2.66   5.13   7.78   1.06   0.89   1.01   1.29  2.16  10.78   \n",
       "2     ...       2.99   5.67   8.66   1.13   1.06   0.55   1.46  2.49  11.43   \n",
       "3     ...       3.15   5.87   9.01   1.26   1.15   0.67   1.45  2.10  13.27   \n",
       "4     ...       3.20   5.49   8.68   1.10   0.80   0.61   1.41  2.52  12.94   \n",
       "\n",
       "       Impact  \n",
       "0  292.787250  \n",
       "1  429.586585  \n",
       "2  500.510500  \n",
       "3  506.706250  \n",
       "4  608.001188  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats[['WS', 'TOV/G', 'PF/G', 'TS%', 'AST/G', 'VORP', 'BLK/G', 'PPG', 'TRB/G', 'Impact', 'PER']]\n",
    "y = stats['MVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.9690962099125364\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for y in y_test:\n",
    "    if y == 1 or y ==0:\n",
    "        sum = sum + 1\n",
    "\n",
    "sum\n",
    "# Total of 106 MVPs candidates in the test set\n",
    "# Total 3430 players in test set\n",
    "print('Baseline Accuracy', (3430 - 106) / 3430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9755\n",
      "AUC Score : 0.970160\n",
      "[[3299   25]\n",
      " [  59   47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3324\n",
      "           1       0.65      0.44      0.53       106\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3430\n",
      "   macro avg       0.82      0.72      0.76      3430\n",
      "weighted avg       0.97      0.98      0.97      3430\n",
      "\n",
      "AUC Score 0.9701598437890243\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9755102040816327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0             0.5            0.0            0.5           0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ad22ab048>"
      ]
     },
     "execution_count": 976,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test run 1\n",
    "xgb_class = XGBClassifier(learning_rate=0.5, scale_post_weight=1, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "                    nthread=4, objective='binary:logistic', n_estimators=500, seed=27)\n",
    "\n",
    "xgb_class.fit(X_train, y_train)\n",
    "\n",
    "predictions = xgb_class.predict(X_test)\n",
    "predict_proba = xgb_class.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictions))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_proba[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_proba[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3299 + 47) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':1, 'gamma':0, 'subsample':0, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':500, 'seed':27}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_class.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_child_weight': 1}\n",
      "0.9669177350575712\n",
      "{'mean_fit_time': array([2.04353037, 2.16919694, 2.48694692, 3.31632729, 3.10808473,\n",
      "       3.02231436, 3.58421135, 3.2455173 , 3.27862883, 4.00807643,\n",
      "       3.44558172, 3.26626196]),\n",
      " 'mean_score_time': array([0.01376357, 0.01396289, 0.02014656, 0.01894937, 0.01855063,\n",
      "       0.01914868, 0.01855021, 0.01755309, 0.01954765, 0.01835117,\n",
      "       0.01815114, 0.01815114]),\n",
      " 'mean_test_score': array([0.96614284, 0.96488194, 0.96482662, 0.96654008, 0.96591262,\n",
      "       0.9612511 , 0.96645815, 0.96270233, 0.96277536, 0.96691774,\n",
      "       0.96410311, 0.96321712]),\n",
      " 'mean_train_score': array([1.        , 1.        , 0.99999984, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]),\n",
      " 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
      "            {'max_depth': 3, 'min_child_weight': 3},\n",
      "            {'max_depth': 3, 'min_child_weight': 5},\n",
      "            {'max_depth': 5, 'min_child_weight': 1},\n",
      "            {'max_depth': 5, 'min_child_weight': 3},\n",
      "            {'max_depth': 5, 'min_child_weight': 5},\n",
      "            {'max_depth': 7, 'min_child_weight': 1},\n",
      "            {'max_depth': 7, 'min_child_weight': 3},\n",
      "            {'max_depth': 7, 'min_child_weight': 5},\n",
      "            {'max_depth': 9, 'min_child_weight': 1},\n",
      "            {'max_depth': 9, 'min_child_weight': 3},\n",
      "            {'max_depth': 9, 'min_child_weight': 5}],\n",
      " 'rank_test_score': array([ 4,  6,  7,  2,  5, 12,  3, 11, 10,  1,  8,  9]),\n",
      " 'split0_test_score': array([0.97403751, 0.97798063, 0.97390089, 0.9766766 , 0.97465847,\n",
      "       0.97488202, 0.97519871, 0.97395678, 0.96724416, 0.97830353,\n",
      "       0.97016269, 0.96857303]),\n",
      " 'split0_train_score': array([1.        , 1.        , 0.99999961, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]),\n",
      " 'split1_test_score': array([0.95507327, 0.96043219, 0.95743294, 0.9542536 , 0.95730874,\n",
      "       0.94989444, 0.95260805, 0.94822404, 0.95350845, 0.95236587,\n",
      "       0.95132265, 0.95940139]),\n",
      " 'split1_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      " 'split2_test_score': array([0.96472926, 0.95372578, 0.96954794, 0.967269  , 0.96689642,\n",
      "       0.95842027, 0.96945479, 0.95935171, 0.96440636, 0.9679148 ,\n",
      "       0.96866617, 0.96438152]),\n",
      " 'split2_train_score': array([1.        , 1.        , 0.99999961, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]),\n",
      " 'split3_test_score': array([0.97123245, 0.96909554, 0.96451733, 0.96930675, 0.96577215,\n",
      "       0.96665424, 0.97365511, 0.9704249 , 0.97125109, 0.96918872,\n",
      "       0.96894024, 0.96701454]),\n",
      " 'split3_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      " 'split4_test_score': array([0.96564169, 0.96317555, 0.958734  , 0.96519443, 0.96492732,\n",
      "       0.95640452, 0.96137408, 0.96155423, 0.95746677, 0.96681575,\n",
      "       0.96142378, 0.95671512]),\n",
      " 'split4_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      " 'std_fit_time': array([0.04261686, 0.30557365, 0.02944159, 0.05496148, 0.03196207,\n",
      "       0.04169099, 0.0905445 , 0.02976269, 0.03174923, 0.10499644,\n",
      "       0.06333616, 0.1091158 ]),\n",
      " 'std_score_time': array([0.00230877, 0.00302562, 0.00692126, 0.00109267, 0.0024101 ,\n",
      "       0.00369943, 0.001017  , 0.00048862, 0.00371028, 0.00079746,\n",
      "       0.00116265, 0.00146623]),\n",
      " 'std_test_score': array([0.00652709, 0.00820368, 0.00626922, 0.00726227, 0.00552223,\n",
      "       0.00866571, 0.00842433, 0.00903843, 0.00645794, 0.00833732,\n",
      "       0.00709164, 0.00450106]),\n",
      " 'std_train_score': array([0.00000000e+00, 0.00000000e+00, 1.90165964e-07, 0.00000000e+00,\n",
      "       0.00000000e+00, 4.96506831e-17, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 4.96506831e-17, 0.00000000e+00, 0.00000000e+00])}\n"
     ]
    }
   ],
   "source": [
    "# Trying to tune the shit, test_run 1\n",
    "param_t1 = {'max_depth':range(3,10,2), 'min_child_weight':range(1,6,2)}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265,\n",
    "                                                gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27),\n",
    "                        param_grid = param_t1, scoring='roc_auc', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)\n",
    "pp.pprint(gsearch1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9723\n",
      "AUC Score : 0.972164\n",
      "[[3297   27]\n",
      " [  68   38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3324\n",
      "           1       0.58      0.36      0.44       106\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3430\n",
      "   macro avg       0.78      0.68      0.72      3430\n",
      "weighted avg       0.97      0.97      0.97      3430\n",
      "\n",
      "AUC Score 0.972163567422746\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9723032069970845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.925136       0.010740       0.887036      0.019505\n",
      "1         0.957986       0.005345       0.924659      0.022637\n",
      "2         0.972698       0.007989       0.942086      0.022015\n",
      "3         0.983039       0.004846       0.947612      0.018029\n",
      "4         0.988511       0.002156       0.957994      0.011999\n",
      "5         0.991901       0.001441       0.961822      0.007035\n",
      "6         0.993906       0.001089       0.963282      0.007190\n",
      "7         0.995141       0.000404       0.964932      0.004605\n",
      "8         0.996081       0.000219       0.964462      0.003945\n",
      "9         0.996556       0.000389       0.964474      0.004375\n",
      "10        0.997008       0.000420       0.963880      0.004328\n",
      "11        0.997578       0.000303       0.963541      0.004570\n",
      "12        0.997968       0.000329       0.965213      0.004896\n",
      "13        0.998334       0.000263       0.965011      0.005120\n",
      "14        0.998600       0.000121       0.965822      0.003747\n",
      "15        0.998905       0.000131       0.966375      0.004604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ae0f3d5f8>"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune test 1\n",
    "# Test run 1\n",
    "xgb_classt1 = XGBClassifier(learning_rate=0.5, max_depth=9, scale_post_weight=1, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "                    nthread=4, objective='binary:logistic', n_estimators=265, seed=27, colsample_bytree=0.8)\n",
    "\n",
    "xgb_classt1.fit(X_train, y_train)\n",
    "\n",
    "predictionst1 = xgb_classt1.predict(X_test)\n",
    "predict_probat1 = xgb_classt1.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictionst1))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_probat1[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictionst1))\n",
    "print(classification_report(y_test, predictionst1))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_probat1[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3297 + 38) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':1, 'gamma':0, 'subsample':0.8, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':265, 'seed':27, 'colsample_bytree':0.8}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_classt1.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_child_weight': 3}\n",
      "0.39333333333333337\n",
      "{'mean_fit_time': array([2.2890728 , 1.75271072, 1.84606123, 2.51766458, 2.32497959,\n",
      "       2.22982945, 2.58468528, 2.43348932, 2.37803841, 2.75582738,\n",
      "       3.04924245, 3.12025266]),\n",
      " 'mean_score_time': array([0.01156917, 0.01017284, 0.01057186, 0.01256647, 0.01176858,\n",
      "       0.01136985, 0.01276593, 0.01136961, 0.01136923, 0.01316495,\n",
      "       0.01535859, 0.01495996]),\n",
      " 'mean_test_score': array([0.39333333, 0.38333333, 0.38333333, 0.38666667, 0.39333333,\n",
      "       0.36333333, 0.38666667, 0.38333333, 0.38333333, 0.35      ,\n",
      "       0.39      , 0.39      ]),\n",
      " 'mean_train_score': array([1.    , 1.    , 0.9925, 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
      "       1.    , 1.    , 1.    , 1.    ]),\n",
      " 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
      "            {'max_depth': 3, 'min_child_weight': 3},\n",
      "            {'max_depth': 3, 'min_child_weight': 5},\n",
      "            {'max_depth': 5, 'min_child_weight': 1},\n",
      "            {'max_depth': 5, 'min_child_weight': 3},\n",
      "            {'max_depth': 5, 'min_child_weight': 5},\n",
      "            {'max_depth': 7, 'min_child_weight': 1},\n",
      "            {'max_depth': 7, 'min_child_weight': 3},\n",
      "            {'max_depth': 7, 'min_child_weight': 5},\n",
      "            {'max_depth': 9, 'min_child_weight': 1},\n",
      "            {'max_depth': 9, 'min_child_weight': 3},\n",
      "            {'max_depth': 9, 'min_child_weight': 5}],\n",
      " 'rank_test_score': array([ 2,  8, 10,  6,  1, 11,  5,  8,  7, 12,  3,  3]),\n",
      " 'split0_test_score': array([0.36666667, 0.33333333, 0.38333333, 0.36666667, 0.35      ,\n",
      "       0.4       , 0.35      , 0.4       , 0.41666667, 0.33333333,\n",
      "       0.38333333, 0.4       ]),\n",
      " 'split0_train_score': array([1.    , 1.    , 0.9875, 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
      "       1.    , 1.    , 1.    , 1.    ]),\n",
      " 'split1_test_score': array([0.33333333, 0.4       , 0.31666667, 0.35      , 0.38333333,\n",
      "       0.28333333, 0.36666667, 0.35      , 0.31666667, 0.35      ,\n",
      "       0.33333333, 0.33333333]),\n",
      " 'split1_train_score': array([1.    , 1.    , 0.9875, 1.    , 1.    , 1.    , 1.    , 1.    ,\n",
      "       1.    , 1.    , 1.    , 1.    ]),\n",
      " 'split2_test_score': array([0.36666667, 0.35      , 0.35      , 0.36666667, 0.43333333,\n",
      "       0.35      , 0.4       , 0.36666667, 0.3       , 0.31666667,\n",
      "       0.38333333, 0.36666667]),\n",
      " 'split2_train_score': array([1.        , 1.        , 0.99583333, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]),\n",
      " 'split3_test_score': array([0.45      , 0.45      , 0.43333333, 0.46666667, 0.45      ,\n",
      "       0.43333333, 0.46666667, 0.41666667, 0.48333333, 0.35      ,\n",
      "       0.45      , 0.46666667]),\n",
      " 'split3_train_score': array([1.        , 1.        , 0.99166667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        ]),\n",
      " 'split4_test_score': array([0.45      , 0.38333333, 0.43333333, 0.38333333, 0.35      ,\n",
      "       0.35      , 0.35      , 0.38333333, 0.4       , 0.4       ,\n",
      "       0.4       , 0.38333333]),\n",
      " 'split4_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      " 'std_fit_time': array([0.25221547, 0.02646704, 0.08445904, 0.06450377, 0.05672858,\n",
      "       0.04495169, 0.05452618, 0.06013143, 0.06237476, 0.0869715 ,\n",
      "       0.19375195, 0.10062605]),\n",
      " 'std_score_time': array([0.0028629 , 0.00146543, 0.00048844, 0.00079776, 0.00074616,\n",
      "       0.0004884 , 0.00074624, 0.00048831, 0.00048871, 0.00193426,\n",
      "       0.0004886 , 0.00089244]),\n",
      " 'std_test_score': array([0.04784233, 0.04082483, 0.04594683, 0.04136558, 0.04163332,\n",
      "       0.0509902 , 0.04396969, 0.02357023, 0.06749486, 0.02788867,\n",
      "       0.03741657, 0.04422166]),\n",
      " 'std_train_score': array([0.        , 0.        , 0.00485913, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ])}\n"
     ]
    }
   ],
   "source": [
    "# Trying to tune the shit, test_run 2\n",
    "param_t2 = {'max_depth':range(3,10,2), 'min_child_weight':range(1,6,2)}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265,\n",
    "                                                gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27),\n",
    "                        param_grid = param_t2, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)\n",
    "pp.pprint(gsearch2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9729\n",
      "AUC Score : 0.968565\n",
      "[[3297   27]\n",
      " [  66   40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3324\n",
      "           1       0.60      0.38      0.46       106\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3430\n",
      "   macro avg       0.79      0.68      0.72      3430\n",
      "weighted avg       0.97      0.97      0.97      3430\n",
      "\n",
      "AUC Score 0.968564811661331\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9728862973760933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.921692       0.008507       0.889240      0.016444\n",
      "1        0.955777       0.004893       0.918101      0.017553\n",
      "2        0.964694       0.005755       0.938616      0.016364\n",
      "3        0.974609       0.002823       0.951207      0.017232\n",
      "4        0.981924       0.002396       0.959413      0.011902\n",
      "5        0.985087       0.001522       0.963250      0.006819\n",
      "6        0.988002       0.001056       0.967597      0.003619\n",
      "7        0.989422       0.000729       0.969552      0.002673\n",
      "8        0.990157       0.000422       0.969904      0.002546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ae1a9c390>"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEhCAYAAABx6WukAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHZRJREFUeJzt3Xm4XFWd7vHvS8IkIIoJEAIhAlFQgYABR5DBVgYxONCCraANIt2oYDvF4TZcGm3aq/YFB/pBRVAQARFIyyAYEUUBCRgCCFzDmEAggTAJqAy//mOtwp1zz1CcqlWVs/J+nuc8p/au4bdO1am3Vq299t6KCMzMrF6r9LsBZmZWloPezKxyDnozs8o56M3MKuegNzOrnIPezKxyDnozs8o56G1UJN0p6UlJf2r8bNThY+4iaVG32thmzVMkHdvLmkORdLSk0/rdDquPg946sU9ErN34ubefjZE0vp/1OzGW224rPge9dZ2k10r6raSHJV0vaZfGdR+UdLOkxyTdLunDef1awEXARs1vCAN73AN7/fmbxWckzQcelzQ+3+8cSUsl3SHpY222e6qkyG1cKOkhSYdJ2kHS/Pz3fKNx+w9I+o2kr0t6RNItknZvXL+RpNmSlklaIOlDjeuOlvRjSadJehQ4DPgc8J78t18/3PPVfC4kfULSEkmLJX2wcf2akr4q6a7cviskrTnSa2T1cS/CukrSZOAC4P3AxcDuwDmStoyIpcAS4G3A7cDOwEWSromI6yTtCZwWERs3Hq+dsgcAewMPAM8C/w2cn9dvDPxc0q0R8bM2/4zXANNy+2bnv+PNwKrA7yWdHRGXN277Y2AC8E7gJ5JeGhHLgDOAm4CNgC2BSyXdHhFz8n1nAvsBBwKr58fYIiLe12jLkM9Xvn5DYF1gMvB3wI8lnRcRDwFfAV4JvB64L7f12TZeI6uMe/TWifNyj/BhSeflde8DLoyICyPi2Yi4FJgL7AUQERdExG2RXA5cAuzUYTtOiIiFEfEksAMwMSKOiYi/RsTtwLeB/Z/H4/1bRPw5Ii4BHgfOiIglEXEP8Gtgu8ZtlwD/NyKeiogzgVuBvSVtArwR+Ex+rHnAd0jh2nJlRJyXn6cnB2tIG8/XU8Axuf6FwJ+Al0taBfhH4IiIuCcinomI30bEXxjhNbL6uEdvndg3In4+YN2mwH6S9mmsWxW4DCD32o8CXkbqaLwAuKHDdiwcUH8jSQ831o0jBXS77m9cfnKQ5bUby/fE8kcGvIvUg98IWBYRjw24bsYQ7R5UG8/XgxHxdGP5idy+CcAawG2DPOywr5HVx0Fv3bYQ+EFEfGjgFZJWB84hDVWcHxFP5W8CrfGZwQ6l+jgp3Fo2HOQ2zfstBO6IiGmjafwoTJakRthPIQ333AusJ2mdRthPAe5p3Hfg37vcchvP13AeAP4MbA5cP+C6IV8jq5OHbqzbTgP2kfRWSeMkrZE3Gm4MrEYai14KPJ17q29p3Pd+4CWS1m2smwfsJWk9SRsCR45Q/3fAo3kD7Zq5Da+StEPX/sLlrQ98TNKqkvYDtiINiywEfgv8e34OtgEOBk4f5rHuB6bmYRcY+fkaUkQ8C5wMfC1vFB4n6XX5w2O418gq5KC3rsoBN5M0g2Qpqff4KWCV3LP9GHAW8BDwXlLvt3XfW0gbMG/P4/4bAT8g9UjvJI1PnzlC/WeAfYDpwB2knu13SBssS7iatOH2AeCLwLsj4sF83QHAVFLv/lzgqDwePpSz8+8HJV030vPVhk+ShnmuAZYB/0F6HYZ8jZ7HY9sYIp94xGx0JH0AOCQi3tjvtpgNx5/gZmaVc9CbmVXOQzdmZpVzj97MrHIOejOzyq0QO0xNmDAhpk6d2u9mmJmNKddee+0DETFxpNutEEE/depU5s6d2+9mmJmNKZLuaud2HroxM6ucg97MrHIOejOzyjnozcwq56A3M6ucg97MrHIOejOzyjnozcwqt0LsMDWSqbMuGPV97zxu7y62xMxs7HGP3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCo3JubR983R63Zw30e61w4zsw64R29mVjkHvZlZ5Rz0ZmaVc9CbmVXOQW9mVjkHvZlZ5Rz0ZmaVc9CbmVXOO0ytoLY+detR3/eGg27oYkvMbKxzj97MrHIOejOzyjnozcwq56A3M6ucg97MrHIOejOzynl6pS3n5i23GvV9t7rl5o5qf/OwX4z6vof/124d1Tar2Yg9ekmbSLpM0s2SbpJ0RF6/nqRLJf0x/35xXi9JJ0haIGm+pO1L/xFmZja0dnr0TwOfiIjrJK0DXCvpUuADwJyIOE7SLGAW8BlgT2Ba/nkNcGL+bbZC+up73jbq+37izJ92sSVmZYwY9BGxGFicLz8m6WZgMjAT2CXf7FTgl6Sgnwl8PyICuErSiyRNyo9jZtmiWb/u6P4bH7dTl1pitXteG2MlTQW2A64GNmiFd/69fr7ZZGBh426L8jozM+uDtoNe0trAOcCREfHocDcdZF0M8niHSporae7SpUvbbYaZmT1PbQW9pFVJIX96RPwkr75f0qR8/SRgSV6/CNikcfeNgXsHPmZEnBQRMyJixsSJE0fbfjMzG0E7s24EfBe4OSK+1rhqNnBQvnwQcH5j/YF59s1rgUc8Pm9m1j/tzLp5A/B+4AZJ8/K6zwHHAWdJOhi4G9gvX3chsBewAHgC+GBXW2xmZs9LO7NurmDwcXeA3Qe5fQCHd9guMzPrEh8Cwcyscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PK+ZyxZiuho48+ui/3tf5wj97MrHIOejOzyjnozcwq56A3M6ucg97MrHIOejOzyjnozcwq56A3M6ucg97MrHIOejOzyjnozcwq52PdmFnPzPnF5h3df/fdbutSS1Yu7tGbmVXOQW9mVjkHvZlZ5Rz0ZmaVc9CbmVXOQW9mVjkHvZlZ5Rz0ZmaVc9CbmVXOQW9mVjkHvZlZ5Rz0ZmaVc9CbmVVuxKCXdLKkJZJubKw7WtI9kubln70a131W0gJJt0p6a6mGm5lZe9rp0Z8C7DHI+v+MiOn550IASa8A9gdeme/zLUnjutVYMzN7/kYM+oj4FbCszcebCfwoIv4SEXcAC4AdO2ifmZl1qJMx+o9Imp+Hdl6c100GFjZusyivMzOzPhlt0J8IbA5MBxYDX83rNchtY7AHkHSopLmS5i5dunSUzTAzs5GMKugj4v6IeCYingW+zd+GZxYBmzRuujFw7xCPcVJEzIiIGRMnThxNM8zMrA2jCnpJkxqL7wBaM3JmA/tLWl3SS4FpwO86a6KZmXVixJODSzoD2AWYIGkRcBSwi6TppGGZO4EPA0TETZLOAv4APA0cHhHPlGm6mZm1Y8Sgj4gDBln93WFu/0Xgi500yszMusd7xpqZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVc5Bb2ZWOQe9mVnlHPRmZpVz0JuZVW7EPWPNzGqw4WXzRn3f+3ad3sWW9J579GZmlXPQm5lVzkM3ZmYFTZ11wajve+dxe3elDe7Rm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZla5EYNe0smSlki6sbFuPUmXSvpj/v3ivF6STpC0QNJ8SduXbLyZmY2snR79KcAeA9bNAuZExDRgTl4G2BOYln8OBU7sTjPNzGy0Rgz6iPgVsGzA6pnAqfnyqcC+jfXfj+Qq4EWSJnWrsWZm9vyNdox+g4hYDJB/r5/XTwYWNm63KK8zM7M+6fbGWA2yLga9oXSopLmS5i5durTLzTAzs5bRBv39rSGZ/HtJXr8I2KRxu42Bewd7gIg4KSJmRMSMiRMnjrIZZmY2ktEG/WzgoHz5IOD8xvoD8+yb1wKPtIZ4zMysP8aPdANJZwC7ABMkLQKOAo4DzpJ0MHA3sF+++YXAXsAC4AnggwXabGZmz8OIQR8RBwxx1e6D3DaAwzttlJmZdY/3jDUzq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCrnoDczq5yD3syscg56M7PKOejNzCo3vpM7S7oTeAx4Bng6ImZIWg84E5gK3An8fUQ81FkzzcxstLrRo981IqZHxIy8PAuYExHTgDl52czM+qTE0M1M4NR8+VRg3wI1zMysTZ0GfQCXSLpW0qF53QYRsRgg/16/wxpmZtaBjsbogTdExL2S1gculXRLu3fMHwyHAkyZMqXDZpiZ2VA66tFHxL359xLgXGBH4H5JkwDy7yVD3PekiJgRETMmTpzYSTPMzGwYow56SWtJWqd1GXgLcCMwGzgo3+wg4PxOG2lmZqPXydDNBsC5klqP88OIuFjSNcBZkg4G7gb267yZZmY2WqMO+oi4Hdh2kPUPArt30igzM+se7xlrZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVzkFvZlY5B72ZWeUc9GZmlXPQm5lVrljQS9pD0q2SFkiaVaqOmZkNr0jQSxoHfBPYE3gFcICkV5SoZWZmwyvVo98RWBARt0fEX4EfATML1TIzs2GUCvrJwMLG8qK8zszMekwR0f0HlfYD3hoRh+Tl9wM7RsRHG7c5FDg0L74cuHWU5SYAD3TQ3E70q7b/5pWj9spWt5+1x+rfvGlETBzpRuNH+eAjWQRs0ljeGLi3eYOIOAk4qdNCkuZGxIxOH2cs1fbfvHLUXtnq9rN27X9zqaGba4Bpkl4qaTVgf2B2oVpmZjaMIj36iHha0keAnwHjgJMj4qYStczMbHilhm6IiAuBC0s9fkPHwz9jsLb/5pWj9spWt5+1q/6bi2yMNTOzFYcPgWBmVjkHvbVN0hqSXtjvdpjZ8+OgX4FJminp8Mby1ZJuzz/v7nFbDiFtXL9A0pd6WbsfJK3ezjqz50vShF7XHFNB36/gk3SwpE81lu+R9KikxyT9U6m6wKdZflrq6sAOwC5AybpI2mfAqjdHxJsiYidg75K1VxBXtrmuY5JeKGlaY3k/SQfmnw1K1BymLZMlTck/xSZrjNCGl0v6dsHH31TSuo3lXSUdL+lf8nTwUnX3kbQUuEHSIkmvL1VroDEV9PQv+A4DTm4sL4mIFwITgQMK1l0tIpqHkrgiIh6MiLuBtQrWBdhW0vmSts3L8yWdLuk0oOhU2T5+sCJpQ0mvBtaUtJ2k7fPPLsALCpX9CvCGxvK/k/6vdwb+d6GaAEj6rKR/bay6EvgpcAnwqcHv1bXa20i6RNKNko6VtIGkc4A5wB8Klj6L/P6RNB04G7gb2Bb4VsG6XwR2iohJwLtIr3NP9OUTuwODBh/woKSSwbdKrtNyNkBE/FnSmgXrvri5EBEfaSyOuNtzJyLiWEkbAsdIAvhXYG3gBRExv2Rt0gfrHo3lJRExWdIapAA6sWDttwIfIO3N/VVAef2jwOcK1dwB+HBj+bHW4UIkXVGoZst+wE6N5QcjYrt8BNrLKRtG3ya9lleSXu/rgB8C/xARfy5Yd82IaO2p/z7Sfj5flbQKMK9g3acj4haAiLha0joFay1nrAV9v4Jv3eZCRHwJIP9jvKRg3aslfSgilvsaK+nDwO8K1m15HDgSmEaa63sN8H96ULdfH6xExKnAqZLeFRHnlKzVMD6Wn+f8/sblF5UuHhGPNxaPz+ueKf1cA6tHxCn58q2SPgnMiohnCtdV4/JuwGcBIuLZ3KkpZX1J/zLUckR8rVThsRb0/Qq+SyQdGxFfGLD+GFIPs5SPA+dJei+ptwPwatKQ1b4F6yLpWNLQwarAmRHxdklvJ22MPSUiflCwfL8+WJteLWlORDyca78Y+MQg/wPd8KykDSPiPoCIuDHXnAw8W6Be09qSVo2Ip3LtU3Lt1YHSM6zWkLQdfwvePwHbKKdtRFw35D078wtJZwH3kTqPvwCQNAn4a6GakL7BrDPMcjFjaocpSesD5wF/YZDgi4j7C9VdC/guMAO4Pq/eFpgLHBIRfypRt1F/N+CVefGmiPhFyXq55ryImJ7fdNdGxPZ5/Xjg8Ig4vmDtbwHLBoZq/vCZEBGHlardqPX7iNhuwLrrWs9Dl2u9DzgC+ATw+7x6e9LY/QklP1TzDKoNgY9ExBN53VrAN4D7IuKzBWv/EhgqgCIiditU9+OkYcgngR+2hnHyh876EfGzEnVHaNNaA75Zdffxx1LQt/Q6+CSNz8fv2axR9w8RcVvhunOB3wAXAb8sPG45sPZppDfhmsDCiPh4D2v39YM1t2E+sENE/CUvrwnMjYhXDn/PUdfbg7QN4JWk5/0m4LiIuKhEvUbdcaSNhIcAd+XVU0jP/xci4umS9ftB0leA1wNbkf6/fkt6n10ZEcsK154MTALmR8Rfc+f1SOADEbFRsbpjKejzxrjDgC2AG4Dv9uIfMQfuIuBi4OKIuLN0zVx3PPBG0oaqXYEHSXPZL4qI/9eD+lsDT7U2IPVKvz5YB7Th08Dbge+RgvcfgdkR8eUCtQ4ALhmwXaInJE2KiMX5g2yLvHpBRDzZg9qfbj2fkvaLiLMb130pIkpt/G7VWI3UmXg98Lr883BEFDntqaQjgc8DC0ijEMcDXwO+D3w5IhaXqAtjL+jPBJ4Cfk06H+2dEXFkj2pvmmvuQTpb1hWknvblrV5fD9owqdGGLYCrIuKfC9XagdSTvy8vH0iaEnYXcHTJnk+/PlgHaceewO6kMeRLSn2llzQLeAtpe8gc0v/V76IHb05JF5HGqX9Jer6v6FUvvjkUNnBYrNQw2YD665LC/Q3594uAGyLig4Xq/QF4Y0QskzSFFPg7R8RVJeotV3uMBf0NEbF1vjye9GYo+s8wRDtWJU1J24M0h39pRHR9JyKlncB+OtiQTd4w+bqI+E236+bHv460k9QySTuTzvv7UWA6sFVEFN0zd0X4YO21PN3uzaS/eUfgZlL4/qzU9qdcdw3S//GepNC7m799yN5dsO5z20EGbhMZbBtJF+ueRPqm+BhwNXAVqdP0UIl6jboDP8xujIhXlaz5XK0xFvQ9/9Rvh6TJEXFPgcc9l/TGuxg4g9SrLD31rFX7+ojYNl/+JunD7Oi8PC8ipveiHbleTz5YB9R8LfB10jjuaqTzKjweaUe5bteaMligSnoFKXzfEhFv7XbdYdrzUv72IbthROxYqE5fevSSLiadvu9G0vj8lcCNpb9BSVpC6jC17N9cjoiPFas9xoL+GdLc7tZ0rDWBJ/JylHgT5rrTSGNry0hjat8mBc9twMERMbdE3Vz7hcA7SP8U2wLnA2dExK9K1cx1bwSm57HyW4BDWzVL90SGCr7G9UU+WAfUmEt6zs8mjeMeCGwREZ8vUKtvHRZJB0Xad2Dg+lWBHwAHRkSRKYcD3s+t9zJ5eY2IWLVE3VxbpF796/PPq0jv7ysj4qhCNQ8a7vrBXoduGVPz6CNiXJ9Kf4+0weSFpK96R5LCdyfgm8BrShWOiEeB1k48LwHeDXxd0noRscnw9+7IWcDlkh4gTUP7NYCkLYBHCtaFNIW21dM7JyLe1byydMg36iyQNC5/i/qepN8WKlV0L50RHCFp9UjncE6NSbOeziVtoyk2r7yP72dy7/1GSQ+T/p8fAd5GGjIrEvTNIJe0dm5GsSmVTWMq6AfMuplP2nW5FxuO1m69ESQd1pgdcKmkXuwp2tph553Ae4D1gNJ7be4L/DNpKtglja+1q5DG6ktqBt9mhWsN5Yk8K2OepC8Diyl3fKHJkk4Y6sqSX+lJ2wQulrRGRJwgaSLpzHBzImJWwbp9ez9L+hipF/8G0uSO35CGb04mzeYrWfufSHvito618yfgPyKi5DF2xlbQk3q2rVk3e5G+eh3Rg7rNvRMfHea6rsob5/YlHThte9IB3Y4FLuvFjIzBZgP0Ylony+9E06+xxfeTPtQ+QtpDeRPSrKMSngSuLfTYw8ob298MXCRpI2AmcGJEDPnB00X9ej9PBX4MfLzklMaBJH2B9AGzS0TcntdtBhyfv6EfW6z2GBuj78usG0lPkKZCCdg8XyYvbxYRRXp6edjkZ6QNNhdH3k29FyQtIm2PGFQUPC7HCGO3xbbFDNKO1YAtSR82txYcq+7nGP0788V1SK/3HJbfQPiTgrVXiFl0vSLpVmDbgbPo8j4M10fEy0rVHms9+ueCLm8k7FXdrXpVaIApEfFE/or7ckkB3DbYdMsCxpF2E+/5+HE/x25bJO0N/Bdpg7uAl0r6cJTZU7Xk8VVG0jzvwOwB6wIoFvT07/3cN4O9dyPiSUlFj2k01nr0rZ4eLN/b62lPr9GeccD+EXF6occfT9o9/WDSjkqrkA6f+z3g8yV7+H3uZfZrW0yzDbcAb4uIBXl5c+CCiNiyQK2pwEMR8Uhe3pU0ZHcX8I2SG0RHaFfRI3iuaO/n0iTNAb4UEXMGrN8N+F8RsWux2mMp6PslT3E8nLTjzmzgUtLY7SeBeRExs1Dd/yR9pf54RDzWaMtXgCcjoth4ZskdVtqoPXAP6LtK/q1DtOFXEbFzY1mknbV2HuZuo611NfCOiLhX6UQYPycdB34b0iEoDul2zTbbdXdETOlH7Rrl/SJmk3b+u5b0jWkH0kbhmRFR7IQ+Dvo2SDofeIi0ZX530i7jqwFHRESxExVI+iPwsoEbXvM3iVsiYtrg9+xK7fWi8AGehqnd97FbSScCm5KmmQbpBB23kmZodHXsWtL8iNgmX/4K8GxEfFr5RBit63pN0sLCU3hXKpK+Qdrx8eWkDc8iHbzu9NLDsWNtjL5fNmsEz3eAB0jj548VrhuDza6JdFKIop/Q/Qr5bEUYu10DuB94U15eSprWug/dH7se7kQY/Ry4di+wu/5I+jY+CTiTtONjyTNaPcdB355m8Dwj6Y4ehDzAHyQdGBHfb65UOn55T48o2WPbSmpNYxXp/K2P0sOx2yh0YKshtE6EsZj//0QYRXt6km5g8EAX0NMTk9cu0jkcjlc6jtP+pJ3w1iD18n9Ucuqyh27akLeIt46B3rONRpI2Ic33bc2zbo3prUka0+3JHqIrI6XjvXyUNOf6uQ5RRLy9QC2RdoSbBJzVel2VDib3vYjYvNs1G7U3He76iLhruOutM0onOzkZ2KbkbDMHfRv6tWGyNfNF0u7AK8hjegO32lv3SbqedPKNG2jsFBcRlxeuOx14L/D3wB3ATyLi6yVrDtKGCaSThDscCsjHEdqD1KvfnXQS9jMi4rxSNT10055+/cO3zp05h7Qji/XOn3u0dyiSXkZ60x9AOrnMmaROWLHpdo3arwWOIx3Q699IBzKbAKyShw0vLt2GlYWkvyO9xnuTznH9I9LBAosf78Y9+jb0ay/Rfu6durJTOiH7NNLJ3587/n0UOGF1Hhr8NelIqK15+7dHRPHj/CgdpfNzpBOynwTsGRFXSdqS1MvsyxTbGkm6DPghcE6vJzu4R9+efu0l2re9U42tSce72Y2/Dd1EXu62d5F69JcpHSv9R/TuNR8fEZcASDqmdXyjiLhlZdhTtZd68Q1tKA769iyOiGNWorqWDkO9WS/2So2Ic4Fz8+GB9yUdRG2DPJf/3FYQF9Lc9X7geWL9db8Sq/S7AWNEv7o27lL1z/Wkc4j2TEQ8HhGnR8TbSIe6mAcUPVQweSqrpMeAbfLl1vLWhWtbj3iMvg392ku0n3unruwk/ZJ0CIJrWH6MvuvTK81Kc9CbDULSmwZbX3p6pVkJDnozs8p5Y6xZQx6bHuqQANUdOtdWDu7Rm5lVzrNuzMwq56A3M6ucg97MrHIOejOzyjnozcwq9z85wL29CFdFpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune test 2\n",
    "# Test run 2\n",
    "xgb_classt2 = XGBClassifier(learning_rate=0.5, max_depth=5, scale_post_weight=1, min_child_weight=3, gamma=0, subsample=0.8,\n",
    "                    nthread=4, objective='binary:logistic', n_estimators=265, seed=27, colsample_bytree=0.8)\n",
    "\n",
    "xgb_classt2.fit(X_train, y_train)\n",
    "\n",
    "predictionst2 = xgb_classt2.predict(X_test)\n",
    "predict_probat2 = xgb_classt2.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictionst2))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_probat2[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictionst2))\n",
    "print(classification_report(y_test, predictionst2))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_probat2[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3297 + 40) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':3, 'gamma':0, 'subsample':0.8, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':265, 'seed':27, 'colsample_bytree':0.8,\n",
    "          'max_depth':5}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_classt2.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_child_weight': 6}\n",
      "0.40666666666666673\n",
      "{'mean_fit_time': array([0.8207953 , 0.74420862, 0.7509901 , 0.74939504, 0.75557809,\n",
      "       0.78470054, 0.84214654, 0.86109567, 0.85531154, 0.86089644,\n",
      "       0.88104239, 1.28775482, 1.27698326, 1.30630517, 1.2921432 ,\n",
      "       1.29194331, 1.29473577, 1.29214258, 1.27419076, 1.25424414,\n",
      "       1.40304661, 1.71880159, 2.17218857, 2.09698949, 2.08881154,\n",
      "       2.15224166, 2.10157747, 2.09200273, 2.07903795, 2.12970219,\n",
      "       2.16002131, 2.20889034, 2.09758816, 2.95429583, 2.77677069,\n",
      "       3.05203495, 2.96107759, 2.78135805, 2.78754296, 2.7576221 ,\n",
      "       2.77058806, 2.82962971, 2.81207657, 2.78494945, 4.06951246,\n",
      "       3.56166978, 3.53534255, 3.46672511, 3.52756257, 3.50482316,\n",
      "       3.48866639, 3.54072728, 3.55708385, 3.83573842, 3.56147156,\n",
      "       5.79828849, 4.86458564, 4.12755742, 4.02383509, 4.07988439,\n",
      "       3.9627986 , 3.89857063, 3.86127005, 3.80262699, 4.07230625,\n",
      "       4.49457626, 7.0449523 , 4.46046677, 4.2346715 , 4.26738362,\n",
      "       4.07090898, 4.00847616, 4.19756999, 4.00867496, 3.88101683,\n",
      "       3.94305105, 3.82257376, 7.70339131, 4.53347068, 4.2771575 ,\n",
      "       4.13792987, 4.08766389, 4.02363572, 3.99092259, 4.01765165,\n",
      "       4.01705303, 4.12616148, 3.70987544, 8.8443388 , 4.48340583,\n",
      "       4.44052072, 4.3643239 , 4.11399322, 3.99930062, 3.86047196,\n",
      "       4.05934043, 3.90036473, 3.81359692, 3.70389071, 9.28137012,\n",
      "       4.46186333, 4.28034873, 4.15508409, 4.352356  , 4.25820751,\n",
      "       4.00568376, 3.90974035, 3.89857001, 3.84810519, 3.82137632,\n",
      "       9.93701534, 4.35215645, 4.2392591 , 4.21891131, 4.12795715,\n",
      "       4.07729168, 3.95940704, 3.91512575, 3.92729325, 4.13194637,\n",
      "       3.79564543]),\n",
      " 'mean_score_time': array([0.00578423, 0.00598435, 0.0059844 , 0.00538607, 0.00638294,\n",
      "       0.00658278, 0.00678205, 0.00678205, 0.00678186, 0.00678182,\n",
      "       0.00698171, 0.00857725, 0.0083776 , 0.00857773, 0.00797858,\n",
      "       0.00757976, 0.00837765, 0.00837774, 0.00817795, 0.00817814,\n",
      "       0.00917549, 0.01136971, 0.01216726, 0.01176901, 0.01196809,\n",
      "       0.01276541, 0.0121675 , 0.01276641, 0.01236734, 0.01296563,\n",
      "       0.01316485, 0.01196785, 0.01296539, 0.01456146, 0.01476064,\n",
      "       0.01535912, 0.01476102, 0.01515994, 0.0155582 , 0.01575809,\n",
      "       0.01595736, 0.01555872, 0.01595759, 0.01555829, 0.01954823,\n",
      "       0.01875014, 0.01815138, 0.01875019, 0.01835146, 0.01815143,\n",
      "       0.01795177, 0.01855073, 0.01894937, 0.01994696, 0.01954808,\n",
      "       0.03011961, 0.02194147, 0.02074432, 0.02074451, 0.02014651,\n",
      "       0.01994686, 0.01954737, 0.01894941, 0.01894965, 0.02054482,\n",
      "       0.02114406, 0.03470774, 0.02373667, 0.02872238, 0.0223402 ,\n",
      "       0.02074451, 0.02034574, 0.01995206, 0.01875   , 0.02174215,\n",
      "       0.02333746, 0.01795206, 0.03829732, 0.02353764, 0.0227397 ,\n",
      "       0.02074466, 0.02214112, 0.02114334, 0.02094417, 0.01855073,\n",
      "       0.02333798, 0.01974697, 0.02573085, 0.04208736, 0.02333775,\n",
      "       0.02692823, 0.02014613, 0.02074475, 0.01974726, 0.01894894,\n",
      "       0.01934805, 0.0197474 , 0.01914964, 0.01954751, 0.0400928 ,\n",
      "       0.02194138, 0.0223402 , 0.02034574, 0.02333784, 0.02154279,\n",
      "       0.01994724, 0.01954808, 0.01914878, 0.02094421, 0.02114353,\n",
      "       0.04926853, 0.02134314, 0.01934824, 0.02074471, 0.02373643,\n",
      "       0.0207449 , 0.01954803, 0.01974697, 0.02234073, 0.0193481 ,\n",
      "       0.01715412]),\n",
      " 'mean_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.32666667, 0.3       , 0.31333333, 0.31      ,\n",
      "       0.29666667, 0.28333333, 0.30333333, 0.28333333, 0.30666667,\n",
      "       0.29      , 0.29333333, 0.38333333, 0.37      , 0.40666667,\n",
      "       0.39      , 0.36      , 0.39      , 0.40666667, 0.37666667,\n",
      "       0.37      , 0.37      , 0.35      , 0.38      , 0.39333333,\n",
      "       0.39333333, 0.38333333, 0.38      , 0.38333333, 0.38333333,\n",
      "       0.35333333, 0.36666667, 0.37666667, 0.37      , 0.4       ,\n",
      "       0.37666667, 0.35333333, 0.36666667, 0.38666667, 0.35      ,\n",
      "       0.35666667, 0.38      , 0.34      , 0.39333333, 0.36666667,\n",
      "       0.37666667, 0.38666667, 0.39333333, 0.39333333, 0.38      ,\n",
      "       0.36333333, 0.36      , 0.37333333, 0.34      , 0.37333333,\n",
      "       0.33666667, 0.37666667, 0.38333333, 0.38      , 0.39      ,\n",
      "       0.38      , 0.40333333, 0.36666667, 0.37333333, 0.36333333,\n",
      "       0.37666667, 0.36      , 0.38      , 0.38666667, 0.37      ,\n",
      "       0.38333333, 0.39333333, 0.38333333, 0.35666667, 0.38666667,\n",
      "       0.36333333, 0.37      , 0.38333333, 0.37666667, 0.38      ,\n",
      "       0.37666667, 0.36666667, 0.37333333, 0.36333333, 0.37      ,\n",
      "       0.39666667, 0.38      , 0.39333333, 0.37666667, 0.36666667,\n",
      "       0.35      , 0.37      , 0.39      , 0.37333333, 0.39      ,\n",
      "       0.36666667, 0.38      , 0.35      , 0.39333333, 0.38333333,\n",
      "       0.35      , 0.40666667, 0.39666667, 0.39333333, 0.37333333,\n",
      "       0.37666667, 0.38333333, 0.38      , 0.35333333, 0.39333333,\n",
      "       0.38333333]),\n",
      " 'mean_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.49916667, 0.49416667, 0.48833333, 0.4925    ,\n",
      "       0.4875    , 0.46666667, 0.48416667, 0.48416667, 0.4775    ,\n",
      "       0.46833333, 0.4675    , 0.95583333, 0.94666667, 0.9375    ,\n",
      "       0.915     , 0.89083333, 0.87416667, 0.86      , 0.84833333,\n",
      "       0.84083333, 0.8275    , 0.80833333, 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.9975    , 0.9925    , 0.98583333,\n",
      "       0.97833333, 0.97      , 0.9575    , 0.94      , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.995     , 0.99      , 0.98      , 0.97166667, 0.95666667,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99666667, 0.99416667, 0.98666667, 0.97416667,\n",
      "       0.96      , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.995     , 0.99333333, 0.98583333,\n",
      "       0.97583333, 0.9625    , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.98916667,\n",
      "       0.9875    , 0.9725    , 0.96416667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99916667,\n",
      "       0.99166667, 0.98583333, 0.97833333, 0.96083333, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.9975    , 0.99083333, 0.98666667, 0.97333333, 0.96083333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99833333, 0.99333333, 0.98583333, 0.97333333,\n",
      "       0.96083333]),\n",
      " 'param_max_depth': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
      "                   3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "                   4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "                   6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8,\n",
      "                   8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "                   9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_min_child_weight': masked_array(data=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6,\n",
      "                   7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2,\n",
      "                   3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
      "                   10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5,\n",
      "                   6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1,\n",
      "                   2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
      "                   9, 10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'max_depth': 0, 'min_child_weight': 0},\n",
      "            {'max_depth': 0, 'min_child_weight': 1},\n",
      "            {'max_depth': 0, 'min_child_weight': 2},\n",
      "            {'max_depth': 0, 'min_child_weight': 3},\n",
      "            {'max_depth': 0, 'min_child_weight': 4},\n",
      "            {'max_depth': 0, 'min_child_weight': 5},\n",
      "            {'max_depth': 0, 'min_child_weight': 6},\n",
      "            {'max_depth': 0, 'min_child_weight': 7},\n",
      "            {'max_depth': 0, 'min_child_weight': 8},\n",
      "            {'max_depth': 0, 'min_child_weight': 9},\n",
      "            {'max_depth': 0, 'min_child_weight': 10},\n",
      "            {'max_depth': 1, 'min_child_weight': 0},\n",
      "            {'max_depth': 1, 'min_child_weight': 1},\n",
      "            {'max_depth': 1, 'min_child_weight': 2},\n",
      "            {'max_depth': 1, 'min_child_weight': 3},\n",
      "            {'max_depth': 1, 'min_child_weight': 4},\n",
      "            {'max_depth': 1, 'min_child_weight': 5},\n",
      "            {'max_depth': 1, 'min_child_weight': 6},\n",
      "            {'max_depth': 1, 'min_child_weight': 7},\n",
      "            {'max_depth': 1, 'min_child_weight': 8},\n",
      "            {'max_depth': 1, 'min_child_weight': 9},\n",
      "            {'max_depth': 1, 'min_child_weight': 10},\n",
      "            {'max_depth': 2, 'min_child_weight': 0},\n",
      "            {'max_depth': 2, 'min_child_weight': 1},\n",
      "            {'max_depth': 2, 'min_child_weight': 2},\n",
      "            {'max_depth': 2, 'min_child_weight': 3},\n",
      "            {'max_depth': 2, 'min_child_weight': 4},\n",
      "            {'max_depth': 2, 'min_child_weight': 5},\n",
      "            {'max_depth': 2, 'min_child_weight': 6},\n",
      "            {'max_depth': 2, 'min_child_weight': 7},\n",
      "            {'max_depth': 2, 'min_child_weight': 8},\n",
      "            {'max_depth': 2, 'min_child_weight': 9},\n",
      "            {'max_depth': 2, 'min_child_weight': 10},\n",
      "            {'max_depth': 3, 'min_child_weight': 0},\n",
      "            {'max_depth': 3, 'min_child_weight': 1},\n",
      "            {'max_depth': 3, 'min_child_weight': 2},\n",
      "            {'max_depth': 3, 'min_child_weight': 3},\n",
      "            {'max_depth': 3, 'min_child_weight': 4},\n",
      "            {'max_depth': 3, 'min_child_weight': 5},\n",
      "            {'max_depth': 3, 'min_child_weight': 6},\n",
      "            {'max_depth': 3, 'min_child_weight': 7},\n",
      "            {'max_depth': 3, 'min_child_weight': 8},\n",
      "            {'max_depth': 3, 'min_child_weight': 9},\n",
      "            {'max_depth': 3, 'min_child_weight': 10},\n",
      "            {'max_depth': 4, 'min_child_weight': 0},\n",
      "            {'max_depth': 4, 'min_child_weight': 1},\n",
      "            {'max_depth': 4, 'min_child_weight': 2},\n",
      "            {'max_depth': 4, 'min_child_weight': 3},\n",
      "            {'max_depth': 4, 'min_child_weight': 4},\n",
      "            {'max_depth': 4, 'min_child_weight': 5},\n",
      "            {'max_depth': 4, 'min_child_weight': 6},\n",
      "            {'max_depth': 4, 'min_child_weight': 7},\n",
      "            {'max_depth': 4, 'min_child_weight': 8},\n",
      "            {'max_depth': 4, 'min_child_weight': 9},\n",
      "            {'max_depth': 4, 'min_child_weight': 10},\n",
      "            {'max_depth': 5, 'min_child_weight': 0},\n",
      "            {'max_depth': 5, 'min_child_weight': 1},\n",
      "            {'max_depth': 5, 'min_child_weight': 2},\n",
      "            {'max_depth': 5, 'min_child_weight': 3},\n",
      "            {'max_depth': 5, 'min_child_weight': 4},\n",
      "            {'max_depth': 5, 'min_child_weight': 5},\n",
      "            {'max_depth': 5, 'min_child_weight': 6},\n",
      "            {'max_depth': 5, 'min_child_weight': 7},\n",
      "            {'max_depth': 5, 'min_child_weight': 8},\n",
      "            {'max_depth': 5, 'min_child_weight': 9},\n",
      "            {'max_depth': 5, 'min_child_weight': 10},\n",
      "            {'max_depth': 6, 'min_child_weight': 0},\n",
      "            {'max_depth': 6, 'min_child_weight': 1},\n",
      "            {'max_depth': 6, 'min_child_weight': 2},\n",
      "            {'max_depth': 6, 'min_child_weight': 3},\n",
      "            {'max_depth': 6, 'min_child_weight': 4},\n",
      "            {'max_depth': 6, 'min_child_weight': 5},\n",
      "            {'max_depth': 6, 'min_child_weight': 6},\n",
      "            {'max_depth': 6, 'min_child_weight': 7},\n",
      "            {'max_depth': 6, 'min_child_weight': 8},\n",
      "            {'max_depth': 6, 'min_child_weight': 9},\n",
      "            {'max_depth': 6, 'min_child_weight': 10},\n",
      "            {'max_depth': 7, 'min_child_weight': 0},\n",
      "            {'max_depth': 7, 'min_child_weight': 1},\n",
      "            {'max_depth': 7, 'min_child_weight': 2},\n",
      "            {'max_depth': 7, 'min_child_weight': 3},\n",
      "            {'max_depth': 7, 'min_child_weight': 4},\n",
      "            {'max_depth': 7, 'min_child_weight': 5},\n",
      "            {'max_depth': 7, 'min_child_weight': 6},\n",
      "            {'max_depth': 7, 'min_child_weight': 7},\n",
      "            {'max_depth': 7, 'min_child_weight': 8},\n",
      "            {'max_depth': 7, 'min_child_weight': 9},\n",
      "            {'max_depth': 7, 'min_child_weight': 10},\n",
      "            {'max_depth': 8, 'min_child_weight': 0},\n",
      "            {'max_depth': 8, 'min_child_weight': 1},\n",
      "            {'max_depth': 8, 'min_child_weight': 2},\n",
      "            {'max_depth': 8, 'min_child_weight': 3},\n",
      "            {'max_depth': 8, 'min_child_weight': 4},\n",
      "            {'max_depth': 8, 'min_child_weight': 5},\n",
      "            {'max_depth': 8, 'min_child_weight': 6},\n",
      "            {'max_depth': 8, 'min_child_weight': 7},\n",
      "            {'max_depth': 8, 'min_child_weight': 8},\n",
      "            {'max_depth': 8, 'min_child_weight': 9},\n",
      "            {'max_depth': 8, 'min_child_weight': 10},\n",
      "            {'max_depth': 9, 'min_child_weight': 0},\n",
      "            {'max_depth': 9, 'min_child_weight': 1},\n",
      "            {'max_depth': 9, 'min_child_weight': 2},\n",
      "            {'max_depth': 9, 'min_child_weight': 3},\n",
      "            {'max_depth': 9, 'min_child_weight': 4},\n",
      "            {'max_depth': 9, 'min_child_weight': 5},\n",
      "            {'max_depth': 9, 'min_child_weight': 6},\n",
      "            {'max_depth': 9, 'min_child_weight': 7},\n",
      "            {'max_depth': 9, 'min_child_weight': 8},\n",
      "            {'max_depth': 9, 'min_child_weight': 9},\n",
      "            {'max_depth': 9, 'min_child_weight': 10},\n",
      "            {'max_depth': 10, 'min_child_weight': 0},\n",
      "            {'max_depth': 10, 'min_child_weight': 1},\n",
      "            {'max_depth': 10, 'min_child_weight': 2},\n",
      "            {'max_depth': 10, 'min_child_weight': 3},\n",
      "            {'max_depth': 10, 'min_child_weight': 4},\n",
      "            {'max_depth': 10, 'min_child_weight': 5},\n",
      "            {'max_depth': 10, 'min_child_weight': 6},\n",
      "            {'max_depth': 10, 'min_child_weight': 7},\n",
      "            {'max_depth': 10, 'min_child_weight': 8},\n",
      "            {'max_depth': 10, 'min_child_weight': 9},\n",
      "            {'max_depth': 10, 'min_child_weight': 10}],\n",
      " 'rank_test_score': array([111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 100, 105,\n",
      "       101, 102, 106, 109, 104, 109, 103, 108, 107,  28,  65,   2,  18,\n",
      "        84,  18,   1,  49,  65,  65,  92,  38,  16,   8,  28,  38,  34,\n",
      "        28,  89,  73,  51,  65,   5,  49,  89,  79,  24,  92,  87,  38,\n",
      "        98,   8,  76,  51,  25,   8,   8,  38,  82,  84,  59,  97,  59,\n",
      "        99,  51,  28,  38,  22,  38,   4,  76,  59,  80,  51,  84,  48,\n",
      "        23,  65,  28,   8,  27,  87,  25,  82,  65,  28,  51,  38,  51,\n",
      "        73,  59,  80,  65,   6,  38,   8,  51,  73,  92,  65,  18,  59,\n",
      "        18,  76,  38,  92,   8,  34,  92,   2,   7,  16,  59,  51,  34,\n",
      "        38,  89,   8,  34]),\n",
      " 'split0_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.36666667, 0.35      , 0.31666667, 0.35      ,\n",
      "       0.33333333, 0.33333333, 0.31666667, 0.3       , 0.31666667,\n",
      "       0.3       , 0.28333333, 0.36666667, 0.31666667, 0.46666667,\n",
      "       0.48333333, 0.35      , 0.4       , 0.41666667, 0.43333333,\n",
      "       0.38333333, 0.38333333, 0.4       , 0.45      , 0.36666667,\n",
      "       0.45      , 0.33333333, 0.36666667, 0.38333333, 0.35      ,\n",
      "       0.36666667, 0.35      , 0.33333333, 0.4       , 0.36666667,\n",
      "       0.36666667, 0.31666667, 0.3       , 0.33333333, 0.31666667,\n",
      "       0.31666667, 0.4       , 0.36666667, 0.41666667, 0.41666667,\n",
      "       0.38333333, 0.36666667, 0.36666667, 0.35      , 0.36666667,\n",
      "       0.4       , 0.33333333, 0.41666667, 0.33333333, 0.38333333,\n",
      "       0.4       , 0.35      , 0.36666667, 0.35      , 0.38333333,\n",
      "       0.36666667, 0.4       , 0.31666667, 0.36666667, 0.38333333,\n",
      "       0.36666667, 0.36666667, 0.35      , 0.35      , 0.33333333,\n",
      "       0.4       , 0.38333333, 0.41666667, 0.28333333, 0.41666667,\n",
      "       0.35      , 0.36666667, 0.41666667, 0.36666667, 0.26666667,\n",
      "       0.35      , 0.31666667, 0.38333333, 0.35      , 0.36666667,\n",
      "       0.36666667, 0.4       , 0.38333333, 0.4       , 0.38333333,\n",
      "       0.33333333, 0.4       , 0.38333333, 0.38333333, 0.4       ,\n",
      "       0.35      , 0.35      , 0.3       , 0.4       , 0.41666667,\n",
      "       0.36666667, 0.36666667, 0.31666667, 0.41666667, 0.33333333,\n",
      "       0.38333333, 0.35      , 0.4       , 0.3       , 0.4       ,\n",
      "       0.41666667]),\n",
      " 'split0_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.475     , 0.46666667, 0.4375    , 0.45      ,\n",
      "       0.42916667, 0.39583333, 0.4375    , 0.43333333, 0.4375    ,\n",
      "       0.42916667, 0.43333333, 0.95      , 0.91666667, 0.92083333,\n",
      "       0.89583333, 0.86666667, 0.84583333, 0.82083333, 0.8125    ,\n",
      "       0.79166667, 0.80833333, 0.79166667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.9875    , 0.98333333,\n",
      "       0.975     , 0.96666667, 0.95833333, 0.92916667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.99583333, 0.97916667, 0.97083333, 0.94583333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99583333, 0.9875    , 0.98333333, 0.97083333,\n",
      "       0.9625    , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.99583333, 0.98333333,\n",
      "       0.975     , 0.9625    , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99166667,\n",
      "       0.98333333, 0.975     , 0.96666667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99166667, 0.98333333, 0.975     , 0.96666667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.9875    , 0.9875    , 0.97916667, 0.96666667,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99166667, 0.9875    , 0.97916667,\n",
      "       0.96666667]),\n",
      " 'split1_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.25      , 0.18333333, 0.26666667, 0.26666667,\n",
      "       0.21666667, 0.2       , 0.28333333, 0.21666667, 0.21666667,\n",
      "       0.23333333, 0.23333333, 0.36666667, 0.38333333, 0.35      ,\n",
      "       0.36666667, 0.35      , 0.33333333, 0.38333333, 0.36666667,\n",
      "       0.33333333, 0.35      , 0.3       , 0.35      , 0.33333333,\n",
      "       0.35      , 0.4       , 0.33333333, 0.31666667, 0.45      ,\n",
      "       0.31666667, 0.31666667, 0.35      , 0.33333333, 0.4       ,\n",
      "       0.31666667, 0.35      , 0.38333333, 0.33333333, 0.36666667,\n",
      "       0.36666667, 0.35      , 0.3       , 0.33333333, 0.31666667,\n",
      "       0.33333333, 0.35      , 0.36666667, 0.38333333, 0.36666667,\n",
      "       0.28333333, 0.36666667, 0.36666667, 0.3       , 0.3       ,\n",
      "       0.3       , 0.33333333, 0.38333333, 0.38333333, 0.31666667,\n",
      "       0.38333333, 0.36666667, 0.36666667, 0.38333333, 0.33333333,\n",
      "       0.4       , 0.36666667, 0.36666667, 0.36666667, 0.31666667,\n",
      "       0.35      , 0.38333333, 0.31666667, 0.3       , 0.36666667,\n",
      "       0.36666667, 0.33333333, 0.4       , 0.33333333, 0.36666667,\n",
      "       0.38333333, 0.36666667, 0.3       , 0.35      , 0.3       ,\n",
      "       0.41666667, 0.31666667, 0.4       , 0.31666667, 0.35      ,\n",
      "       0.35      , 0.35      , 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.33333333, 0.36666667, 0.31666667, 0.4       , 0.33333333,\n",
      "       0.33333333, 0.36666667, 0.4       , 0.38333333, 0.33333333,\n",
      "       0.28333333, 0.36666667, 0.35      , 0.31666667, 0.4       ,\n",
      "       0.33333333]),\n",
      " 'split1_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.50833333, 0.51666667, 0.51666667, 0.525     ,\n",
      "       0.525     , 0.4875    , 0.50833333, 0.50833333, 0.5125    ,\n",
      "       0.5       , 0.5       , 0.95833333, 0.95      , 0.95833333,\n",
      "       0.95      , 0.92083333, 0.88333333, 0.88333333, 0.8875    ,\n",
      "       0.8625    , 0.83333333, 0.81666667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.9875    , 0.9875    ,\n",
      "       0.97916667, 0.96666667, 0.96666667, 0.9625    , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.9875    , 0.9875    , 0.9875    , 0.975     , 0.95833333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99166667, 0.98333333, 0.975     ,\n",
      "       0.97083333, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.9875    , 0.98333333,\n",
      "       0.97083333, 0.96666667, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.98333333,\n",
      "       0.98333333, 0.975     , 0.9625    , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.9875    , 0.97916667, 0.97916667, 0.97083333, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.9875    , 0.98333333, 0.97916667, 0.97083333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99583333, 0.9875    , 0.98333333, 0.97916667,\n",
      "       0.97083333]),\n",
      " 'split2_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.31666667, 0.3       , 0.3       , 0.3       ,\n",
      "       0.3       , 0.25      , 0.28333333, 0.31666667, 0.33333333,\n",
      "       0.28333333, 0.33333333, 0.36666667, 0.36666667, 0.38333333,\n",
      "       0.38333333, 0.35      , 0.35      , 0.4       , 0.36666667,\n",
      "       0.36666667, 0.35      , 0.28333333, 0.35      , 0.36666667,\n",
      "       0.38333333, 0.35      , 0.38333333, 0.35      , 0.33333333,\n",
      "       0.35      , 0.31666667, 0.33333333, 0.3       , 0.41666667,\n",
      "       0.31666667, 0.35      , 0.35      , 0.38333333, 0.31666667,\n",
      "       0.31666667, 0.33333333, 0.33333333, 0.35      , 0.3       ,\n",
      "       0.36666667, 0.36666667, 0.38333333, 0.43333333, 0.35      ,\n",
      "       0.35      , 0.31666667, 0.31666667, 0.3       , 0.33333333,\n",
      "       0.28333333, 0.35      , 0.35      , 0.31666667, 0.38333333,\n",
      "       0.3       , 0.35      , 0.3       , 0.31666667, 0.35      ,\n",
      "       0.3       , 0.26666667, 0.35      , 0.4       , 0.38333333,\n",
      "       0.36666667, 0.36666667, 0.3       , 0.31666667, 0.35      ,\n",
      "       0.35      , 0.3       , 0.28333333, 0.31666667, 0.35      ,\n",
      "       0.33333333, 0.36666667, 0.38333333, 0.33333333, 0.35      ,\n",
      "       0.31666667, 0.36666667, 0.33333333, 0.33333333, 0.31666667,\n",
      "       0.31666667, 0.33333333, 0.38333333, 0.33333333, 0.36666667,\n",
      "       0.38333333, 0.33333333, 0.36666667, 0.35      , 0.33333333,\n",
      "       0.28333333, 0.38333333, 0.36666667, 0.35      , 0.35      ,\n",
      "       0.35      , 0.36666667, 0.3       , 0.36666667, 0.35      ,\n",
      "       0.33333333]),\n",
      " 'split2_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.51666667, 0.49166667, 0.4625    , 0.49583333,\n",
      "       0.5       , 0.475     , 0.49583333, 0.48333333, 0.49166667,\n",
      "       0.46666667, 0.475     , 0.94166667, 0.95      , 0.92916667,\n",
      "       0.9       , 0.87916667, 0.86666667, 0.84583333, 0.825     ,\n",
      "       0.8375    , 0.8       , 0.7875    , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.99583333, 0.97916667,\n",
      "       0.975     , 0.9625    , 0.95      , 0.94166667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.97916667, 0.97916667, 0.96666667, 0.95      ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99166667, 0.99583333, 0.9875    , 0.975     ,\n",
      "       0.95416667, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99166667, 0.99583333, 0.98333333,\n",
      "       0.97083333, 0.95      , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99166667,\n",
      "       0.98333333, 0.9625    , 0.95833333, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.9875    , 0.9875    , 0.97083333, 0.95416667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99166667, 0.9875    , 0.95833333, 0.95416667,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99583333, 0.99166667, 0.9875    , 0.95833333,\n",
      "       0.95416667]),\n",
      " 'split3_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.38333333, 0.35      , 0.35      , 0.33333333,\n",
      "       0.31666667, 0.33333333, 0.33333333, 0.31666667, 0.35      ,\n",
      "       0.35      , 0.35      , 0.4       , 0.41666667, 0.43333333,\n",
      "       0.41666667, 0.36666667, 0.45      , 0.46666667, 0.4       ,\n",
      "       0.41666667, 0.43333333, 0.46666667, 0.35      , 0.45      ,\n",
      "       0.38333333, 0.45      , 0.41666667, 0.43333333, 0.41666667,\n",
      "       0.38333333, 0.45      , 0.5       , 0.45      , 0.4       ,\n",
      "       0.46666667, 0.43333333, 0.4       , 0.43333333, 0.43333333,\n",
      "       0.45      , 0.45      , 0.33333333, 0.48333333, 0.46666667,\n",
      "       0.41666667, 0.46666667, 0.43333333, 0.45      , 0.43333333,\n",
      "       0.43333333, 0.46666667, 0.4       , 0.41666667, 0.5       ,\n",
      "       0.43333333, 0.48333333, 0.4       , 0.48333333, 0.46666667,\n",
      "       0.45      , 0.48333333, 0.51666667, 0.41666667, 0.45      ,\n",
      "       0.48333333, 0.51666667, 0.4       , 0.46666667, 0.45      ,\n",
      "       0.41666667, 0.43333333, 0.48333333, 0.53333333, 0.45      ,\n",
      "       0.45      , 0.5       , 0.45      , 0.45      , 0.5       ,\n",
      "       0.43333333, 0.4       , 0.4       , 0.41666667, 0.46666667,\n",
      "       0.46666667, 0.45      , 0.5       , 0.5       , 0.43333333,\n",
      "       0.35      , 0.4       , 0.45      , 0.45      , 0.46666667,\n",
      "       0.43333333, 0.41666667, 0.45      , 0.46666667, 0.5       ,\n",
      "       0.4       , 0.48333333, 0.5       , 0.43333333, 0.43333333,\n",
      "       0.46666667, 0.46666667, 0.45      , 0.45      , 0.46666667,\n",
      "       0.5       ]),\n",
      " 'split3_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.46666667, 0.46666667, 0.49583333, 0.475     ,\n",
      "       0.47083333, 0.4625    , 0.46666667, 0.47083333, 0.45      ,\n",
      "       0.45833333, 0.43333333, 0.95416667, 0.96666667, 0.93333333,\n",
      "       0.90416667, 0.89583333, 0.87916667, 0.86666667, 0.84166667,\n",
      "       0.83333333, 0.8375    , 0.81666667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.99166667, 0.9875    ,\n",
      "       0.975     , 0.97916667, 0.95833333, 0.92916667, 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.9875    , 0.975     , 0.97083333, 0.95833333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.9875    , 0.975     ,\n",
      "       0.95833333, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99166667, 0.99166667, 0.9875    ,\n",
      "       0.975     , 0.9625    , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.9875    ,\n",
      "       0.99166667, 0.97083333, 0.9625    , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.98333333, 0.98333333, 0.9625    , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99166667, 0.98333333, 0.97916667, 0.9625    ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.98333333, 0.97916667,\n",
      "       0.9625    ]),\n",
      " 'split4_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.31666667, 0.31666667, 0.33333333, 0.3       ,\n",
      "       0.31666667, 0.3       , 0.3       , 0.26666667, 0.31666667,\n",
      "       0.28333333, 0.26666667, 0.41666667, 0.36666667, 0.4       ,\n",
      "       0.3       , 0.38333333, 0.41666667, 0.36666667, 0.31666667,\n",
      "       0.35      , 0.33333333, 0.3       , 0.4       , 0.45      ,\n",
      "       0.4       , 0.38333333, 0.4       , 0.43333333, 0.36666667,\n",
      "       0.35      , 0.4       , 0.36666667, 0.36666667, 0.41666667,\n",
      "       0.41666667, 0.31666667, 0.4       , 0.45      , 0.31666667,\n",
      "       0.33333333, 0.36666667, 0.36666667, 0.38333333, 0.33333333,\n",
      "       0.38333333, 0.38333333, 0.41666667, 0.35      , 0.38333333,\n",
      "       0.35      , 0.31666667, 0.36666667, 0.35      , 0.35      ,\n",
      "       0.26666667, 0.36666667, 0.41666667, 0.36666667, 0.4       ,\n",
      "       0.4       , 0.41666667, 0.33333333, 0.38333333, 0.3       ,\n",
      "       0.33333333, 0.28333333, 0.43333333, 0.35      , 0.36666667,\n",
      "       0.38333333, 0.4       , 0.4       , 0.35      , 0.35      ,\n",
      "       0.3       , 0.35      , 0.36666667, 0.41666667, 0.41666667,\n",
      "       0.38333333, 0.38333333, 0.4       , 0.36666667, 0.36666667,\n",
      "       0.41666667, 0.36666667, 0.35      , 0.33333333, 0.35      ,\n",
      "       0.4       , 0.36666667, 0.4       , 0.36666667, 0.38333333,\n",
      "       0.33333333, 0.43333333, 0.31666667, 0.35      , 0.33333333,\n",
      "       0.36666667, 0.43333333, 0.4       , 0.38333333, 0.41666667,\n",
      "       0.4       , 0.36666667, 0.4       , 0.33333333, 0.35      ,\n",
      "       0.33333333]),\n",
      " 'split4_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.52916667, 0.52916667, 0.52916667, 0.51666667,\n",
      "       0.5125    , 0.5125    , 0.5125    , 0.525     , 0.49583333,\n",
      "       0.4875    , 0.49583333, 0.975     , 0.95      , 0.94583333,\n",
      "       0.925     , 0.89166667, 0.89583333, 0.88333333, 0.875     ,\n",
      "       0.87916667, 0.85833333, 0.82916667, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99166667,\n",
      "       0.9875    , 0.975     , 0.95416667, 0.9375    , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.97916667, 0.975     , 0.97083333,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 0.99583333, 0.99583333, 0.99166667, 0.975     ,\n",
      "       0.95416667, 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.99583333, 0.99166667,\n",
      "       0.9875    , 0.97083333, 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99166667,\n",
      "       0.99583333, 0.97916667, 0.97083333, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.99583333,\n",
      "       0.99583333, 0.99583333, 0.98333333, 0.95      , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99583333, 0.99583333, 0.99166667, 0.97083333, 0.95      ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 0.99583333, 0.9875    , 0.97083333,\n",
      "       0.95      ]),\n",
      " 'std_fit_time': array([0.03977791, 0.00506196, 0.00696712, 0.00279239, 0.00453117,\n",
      "       0.02340992, 0.00996533, 0.00587041, 0.0059709 , 0.00525472,\n",
      "       0.01695625, 0.05359461, 0.04958474, 0.02289433, 0.011312  ,\n",
      "       0.013345  , 0.01560946, 0.02131189, 0.01763491, 0.00411693,\n",
      "       0.14926638, 0.0531813 , 0.02982011, 0.00391868, 0.01041418,\n",
      "       0.03559831, 0.01531397, 0.0247012 , 0.02884757, 0.01707252,\n",
      "       0.06458914, 0.0766568 , 0.0215237 , 0.01820959, 0.02712585,\n",
      "       0.3010222 , 0.25717268, 0.01606154, 0.01281916, 0.01671247,\n",
      "       0.00834395, 0.01440307, 0.01500139, 0.00747961, 0.02214532,\n",
      "       0.0226814 , 0.03440668, 0.01613056, 0.0287258 , 0.01739341,\n",
      "       0.02456043, 0.02911387, 0.03833492, 0.13394448, 0.06351031,\n",
      "       0.3188381 , 0.33789267, 0.06715073, 0.05892736, 0.06545615,\n",
      "       0.04295543, 0.03718337, 0.02656421, 0.01930165, 0.33041908,\n",
      "       0.04800766, 0.33773397, 0.07316586, 0.04866383, 0.06313837,\n",
      "       0.06537908, 0.06400492, 0.20807344, 0.20633261, 0.01623665,\n",
      "       0.13304081, 0.16362016, 0.22792364, 0.14943564, 0.06672584,\n",
      "       0.05496719, 0.06464878, 0.04121588, 0.06143321, 0.02944184,\n",
      "       0.21855145, 0.21071593, 0.04250679, 0.17937313, 0.10408506,\n",
      "       0.12399761, 0.145618  , 0.06253468, 0.10863157, 0.08552046,\n",
      "       0.06831684, 0.05174427, 0.02855504, 0.06484138, 0.20528315,\n",
      "       0.10510869, 0.02370554, 0.05911237, 0.25560964, 0.25522806,\n",
      "       0.02566516, 0.04578814, 0.08602776, 0.05286622, 0.02315571,\n",
      "       0.40786108, 0.06022849, 0.07238336, 0.0837433 , 0.06141194,\n",
      "       0.05462779, 0.12465748, 0.03164874, 0.05209612, 0.17470307,\n",
      "       0.26175809]),\n",
      " 'std_score_time': array([7.46149376e-04, 6.30525029e-04, 8.92336610e-04, 4.88266242e-04,\n",
      "       4.88324718e-04, 4.89336913e-04, 3.98755198e-04, 3.99112872e-04,\n",
      "       3.98540554e-04, 3.98993845e-04, 3.23406696e-07, 4.88830808e-04,\n",
      "       4.88772774e-04, 7.97224979e-04, 6.30298727e-04, 7.98082373e-04,\n",
      "       4.88636202e-04, 4.89044929e-04, 3.99017362e-04, 3.98922252e-04,\n",
      "       2.03401271e-03, 2.41055797e-03, 1.93351155e-03, 3.98850594e-04,\n",
      "       6.30675674e-04, 7.46416646e-04, 7.46276559e-04, 3.98779044e-04,\n",
      "       7.97700960e-04, 1.78392666e-03, 1.71580611e-03, 6.30600248e-04,\n",
      "       8.91910086e-04, 1.01732670e-03, 7.46391189e-04, 1.49281413e-03,\n",
      "       1.16283478e-03, 1.16313737e-03, 7.98142100e-04, 7.46556871e-04,\n",
      "       1.26187902e-03, 4.88713937e-04, 8.92016648e-04, 7.98368632e-04,\n",
      "       7.97653369e-04, 7.46403995e-04, 7.46327549e-04, 7.45843237e-04,\n",
      "       1.19713152e-03, 7.46251015e-04, 8.92496841e-04, 7.97677159e-04,\n",
      "       8.92443177e-04, 1.66900993e-03, 2.40961481e-03, 9.77242925e-04,\n",
      "       8.92283390e-04, 7.46544195e-04, 7.46467903e-04, 9.76960613e-04,\n",
      "       1.78411333e-03, 1.19698859e-03, 1.78408661e-03, 1.54489505e-03,\n",
      "       2.79292726e-03, 3.11626022e-03, 1.71600576e-03, 1.32294535e-03,\n",
      "       1.02368940e-02, 2.41023834e-03, 7.45957966e-04, 2.05359971e-03,\n",
      "       8.97715624e-04, 7.46302000e-04, 2.77830358e-03, 4.57484193e-03,\n",
      "       1.66895298e-03, 1.35341489e-03, 2.40967005e-03, 2.13039297e-03,\n",
      "       7.45868671e-04, 3.53422891e-03, 1.71613323e-03, 3.39648818e-03,\n",
      "       1.01687780e-03, 4.06899568e-03, 7.46659075e-04, 1.21879599e-02,\n",
      "       1.93410173e-03, 2.86302303e-03, 1.04405593e-02, 1.46546063e-03,\n",
      "       1.16314578e-03, 1.16343995e-03, 6.31052673e-04, 4.88305129e-04,\n",
      "       7.46263979e-04, 1.16293300e-03, 1.73885509e-03, 1.16268760e-03,\n",
      "       3.56862638e-03, 2.49088893e-03, 1.35281027e-03, 5.33723356e-03,\n",
      "       1.62070460e-03, 1.09244930e-03, 7.97760588e-04, 7.45855971e-04,\n",
      "       4.13613399e-03, 2.70588760e-03, 1.09901436e-02, 2.32652824e-03,\n",
      "       1.01684976e-03, 1.71575067e-03, 5.79508170e-03, 3.53467292e-03,\n",
      "       1.35281729e-03, 9.77174832e-04, 6.81100423e-03, 7.98070436e-04,\n",
      "       2.31004002e-03]),\n",
      " 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.04666667, 0.06146363, 0.02867442, 0.02905933,\n",
      "       0.04136558, 0.05163978, 0.01943651, 0.03800585, 0.04666667,\n",
      "       0.03741657, 0.042947  , 0.02108185, 0.03231787, 0.04027682,\n",
      "       0.0601849 , 0.01333333, 0.042947  , 0.03431877, 0.03887301,\n",
      "       0.02867442, 0.03559026, 0.07149204, 0.04      , 0.04784233,\n",
      "       0.03265986, 0.04082483, 0.02867442, 0.04594683, 0.04346135,\n",
      "       0.02211083, 0.05163978, 0.06289321, 0.05206833, 0.01825742,\n",
      "       0.05830952, 0.04268749, 0.03800585, 0.04876246, 0.04594683,\n",
      "       0.05011099, 0.04136558, 0.02494438, 0.05333333, 0.06411795,\n",
      "       0.02708013, 0.04136558, 0.02708013, 0.04163332, 0.02867442,\n",
      "       0.0509902 , 0.05637178, 0.03431877, 0.042947  , 0.06879922,\n",
      "       0.06699917, 0.05436502, 0.02357023, 0.05617433, 0.04784233,\n",
      "       0.04876246, 0.04642796, 0.0781736 , 0.03265986, 0.0509902 ,\n",
      "       0.06289321, 0.08856887, 0.03231787, 0.04396969, 0.04642796,\n",
      "       0.02357023, 0.02260777, 0.06749486, 0.09104334, 0.04      ,\n",
      "       0.04876246, 0.06863753, 0.05676462, 0.05011099, 0.07702813,\n",
      "       0.03431877, 0.02788867, 0.03741657, 0.02867442, 0.05416026,\n",
      "       0.0509902 , 0.04396969, 0.05830952, 0.06798693, 0.03944053,\n",
      "       0.02788867, 0.02666667, 0.03741657, 0.042947  , 0.04422166,\n",
      "       0.03800585, 0.03858612, 0.05477226, 0.042947  , 0.06666667,\n",
      "       0.03944053, 0.04546061, 0.06      , 0.02905933, 0.042947  ,\n",
      "       0.0601849 , 0.0421637 , 0.0509902 , 0.05312459, 0.042947  ,\n",
      "       0.06666667]),\n",
      " 'std_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.02420973, 0.0254951 , 0.03399346, 0.0274368 ,\n",
      "       0.03425801, 0.0390868 , 0.02830881, 0.03166667, 0.02869863,\n",
      "       0.02452323, 0.02915476, 0.01105542, 0.01632993, 0.01317616,\n",
      "       0.02017286, 0.01814295, 0.01695582, 0.02395018, 0.02869863,\n",
      "       0.02974428, 0.02101587, 0.01602949, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00204124, 0.00485913, 0.00424918,\n",
      "       0.00485913, 0.00612372, 0.00552771, 0.01224745, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00408248, 0.00726483, 0.00408248, 0.00311805, 0.00857969,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00311805, 0.00424918, 0.00311805, 0.00166667,\n",
      "       0.0062361 , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00311805, 0.00333333, 0.00333333,\n",
      "       0.00612372, 0.00697217, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00333333,\n",
      "       0.00527046, 0.00565194, 0.00424918, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00166667,\n",
      "       0.00372678, 0.00565194, 0.00485913, 0.00772802, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00204124, 0.00311805, 0.00311805, 0.00816497, 0.00772802,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00204124, 0.00424918, 0.00204124, 0.00816497,\n",
      "       0.00772802])}\n"
     ]
    }
   ],
   "source": [
    "# Trying to tune the shit, test_run 2\n",
    "param_t2 = {'max_depth':range(0,11,1), 'min_child_weight':range(0,11,1)}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265,\n",
    "                                                gamma=0, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27),\n",
    "                        param_grid = param_t2, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)\n",
    "pp.pprint(gsearch2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9741\n",
      "AUC Score : 0.970719\n",
      "[[3300   24]\n",
      " [  65   41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3324\n",
      "           1       0.63      0.39      0.48       106\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3430\n",
      "   macro avg       0.81      0.69      0.73      3430\n",
      "weighted avg       0.97      0.97      0.97      3430\n",
      "\n",
      "AUC Score 0.9707189564743546\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9728862973760933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.876922       0.033077       0.861648      0.037370\n",
      "1         0.916519       0.014174       0.899056      0.015528\n",
      "2         0.939076       0.004438       0.923620      0.007963\n",
      "3         0.956173       0.004832       0.946382      0.011214\n",
      "4         0.961853       0.005289       0.952300      0.010970\n",
      "5         0.968366       0.004062       0.960885      0.009181\n",
      "6         0.973036       0.001594       0.964545      0.005538\n",
      "7         0.975396       0.001011       0.968303      0.002825\n",
      "8         0.976246       0.000887       0.968786      0.002969\n",
      "9         0.977222       0.000496       0.969492      0.003307\n",
      "10        0.978143       0.000793       0.969828      0.003251\n",
      "11        0.978737       0.000958       0.970039      0.003721\n",
      "12        0.979239       0.000859       0.970199      0.004377\n",
      "13        0.979631       0.000810       0.970164      0.004423\n",
      "14        0.979922       0.000939       0.970199      0.003759\n",
      "15        0.980510       0.000900       0.970409      0.004223\n",
      "16        0.980891       0.000675       0.969786      0.004303\n",
      "17        0.981417       0.000773       0.969658      0.004273\n",
      "18        0.981791       0.000877       0.970270      0.003927\n",
      "19        0.982083       0.000780       0.970349      0.003644\n",
      "20        0.982276       0.000760       0.970160      0.003796\n",
      "21        0.982641       0.000847       0.970332      0.004016\n",
      "22        0.982881       0.000868       0.970137      0.004084\n",
      "23        0.983318       0.000887       0.970148      0.003899\n",
      "24        0.983554       0.000836       0.970116      0.003623\n",
      "25        0.983715       0.000886       0.970429      0.003612\n",
      "26        0.983989       0.000946       0.970246      0.003364\n",
      "27        0.984195       0.000888       0.970020      0.003491\n",
      "28        0.984460       0.000854       0.969888      0.003602\n",
      "29        0.984739       0.000811       0.970100      0.003475\n",
      "30        0.984933       0.000837       0.970153      0.003412\n",
      "31        0.985111       0.000778       0.970266      0.003813\n",
      "32        0.985453       0.000832       0.970196      0.003882\n",
      "33        0.985703       0.000777       0.970682      0.003506\n",
      "34        0.985842       0.000800       0.970813      0.003960\n",
      "35        0.986067       0.000685       0.970902      0.003838\n",
      "36        0.986221       0.000599       0.971091      0.003809\n",
      "37        0.986379       0.000746       0.971042      0.003925\n",
      "38        0.986661       0.000619       0.971385      0.003916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ad1dc1470>"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune test 3\n",
    "# Test run 3\n",
    "xgb_classt3 = XGBClassifier(learning_rate=0.5, max_depth=2, scale_post_weight=1, min_child_weight=6, gamma=0, subsample=0.8,\n",
    "                    nthread=4, objective='binary:logistic', n_estimators=265, seed=27, colsample_bytree=0.8)\n",
    "\n",
    "xgb_classt3.fit(X_train, y_train)\n",
    "\n",
    "predictionst3 = xgb_classt3.predict(X_test)\n",
    "predict_probat3 = xgb_classt3.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictionst3))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_probat3[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictionst3))\n",
    "print(classification_report(y_test, predictionst3))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_probat3[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3297 + 40) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':6, 'gamma':0, 'subsample':0.8, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':265, 'seed':27, 'colsample_bytree':0.8,\n",
    "          'max_depth':2}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_classt3.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.40666666666666673\n",
      "{'mean_fit_time': array([2.10935822, 1.73775034, 1.73017082, 1.63941336, 1.63741927,\n",
      "       1.65098305, 1.64819007, 1.66953321, 1.75949259, 2.08462234,\n",
      "       1.9605546 ]),\n",
      " 'mean_score_time': array([0.0109694 , 0.0093751 , 0.0091753 , 0.00937505, 0.00977693,\n",
      "       0.0095746 , 0.0095768 , 0.00957432, 0.01296558, 0.01236711,\n",
      "       0.01176815]),\n",
      " 'mean_test_score': array([0.40666667, 0.39      , 0.39      , 0.39      , 0.37666667,\n",
      "       0.37666667, 0.37666667, 0.35333333, 0.35666667, 0.38666667,\n",
      "       0.36666667]),\n",
      " 'mean_train_score': array([0.86      , 0.86083333, 0.85833333, 0.85833333, 0.8625    ,\n",
      "       0.86166667, 0.86583333, 0.8575    , 0.855     , 0.8525    ,\n",
      "       0.84583333]),\n",
      " 'param_gamma': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'gamma': 0.0},\n",
      "            {'gamma': 0.1},\n",
      "            {'gamma': 0.2},\n",
      "            {'gamma': 0.3},\n",
      "            {'gamma': 0.4},\n",
      "            {'gamma': 0.5},\n",
      "            {'gamma': 0.6},\n",
      "            {'gamma': 0.7},\n",
      "            {'gamma': 0.8},\n",
      "            {'gamma': 0.9},\n",
      "            {'gamma': 1.0}],\n",
      " 'rank_test_score': array([ 1,  2,  2,  2,  6,  6,  6, 11, 10,  5,  9]),\n",
      " 'split0_test_score': array([0.41666667, 0.41666667, 0.41666667, 0.41666667, 0.41666667,\n",
      "       0.4       , 0.38333333, 0.38333333, 0.36666667, 0.41666667,\n",
      "       0.41666667]),\n",
      " 'split0_train_score': array([0.82083333, 0.82083333, 0.82083333, 0.82083333, 0.825     ,\n",
      "       0.81666667, 0.8375    , 0.82083333, 0.82916667, 0.81666667,\n",
      "       0.825     ]),\n",
      " 'split1_test_score': array([0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.38333333, 0.31666667, 0.28333333, 0.31666667,\n",
      "       0.31666667]),\n",
      " 'split1_train_score': array([0.88333333, 0.88333333, 0.88333333, 0.88333333, 0.88333333,\n",
      "       0.88333333, 0.8875    , 0.87916667, 0.87083333, 0.87083333,\n",
      "       0.87083333]),\n",
      " 'split2_test_score': array([0.4       , 0.31666667, 0.31666667, 0.31666667, 0.31666667,\n",
      "       0.31666667, 0.36666667, 0.33333333, 0.36666667, 0.35      ,\n",
      "       0.35      ]),\n",
      " 'split2_train_score': array([0.84583333, 0.85      , 0.8375    , 0.8375    , 0.83333333,\n",
      "       0.83333333, 0.8625    , 0.84583333, 0.85      , 0.83333333,\n",
      "       0.825     ]),\n",
      " 'split3_test_score': array([0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.41666667,\n",
      "       0.38333333, 0.38333333, 0.4       , 0.38333333, 0.43333333,\n",
      "       0.35      ]),\n",
      " 'split3_train_score': array([0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
      "       0.875     , 0.8625    , 0.85833333, 0.875     , 0.84166667,\n",
      "       0.85      ]),\n",
      " 'split4_test_score': array([0.36666667, 0.36666667, 0.36666667, 0.36666667, 0.35      ,\n",
      "       0.4       , 0.36666667, 0.33333333, 0.38333333, 0.41666667,\n",
      "       0.4       ]),\n",
      " 'split4_train_score': array([0.88333333, 0.88333333, 0.88333333, 0.88333333, 0.90416667,\n",
      "       0.9       , 0.87916667, 0.88333333, 0.85      , 0.9       ,\n",
      "       0.85833333]),\n",
      " 'std_fit_time': array([0.24813279, 0.12250353, 0.08920751, 0.03373574, 0.04950811,\n",
      "       0.03774914, 0.03882499, 0.0432756 , 0.11532121, 0.03690609,\n",
      "       0.14980346]),\n",
      " 'std_score_time': array([0.00199533, 0.00101731, 0.00039899, 0.00079789, 0.00116343,\n",
      "       0.00048858, 0.00048619, 0.00079776, 0.00209226, 0.00048834,\n",
      "       0.00193438]),\n",
      " 'std_test_score': array([0.03431877, 0.05011099, 0.05011099, 0.05011099, 0.03887301,\n",
      "       0.03091206, 0.00816497, 0.03231787, 0.03741657, 0.04521553,\n",
      "       0.03651484]),\n",
      " 'std_train_score': array([0.02395018, 0.02351123, 0.02513851, 0.02513851, 0.02981424,\n",
      "       0.0314466 , 0.01715938, 0.02288255, 0.01654119, 0.02953341,\n",
      "       0.01825742])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 3 \n",
    "paramt3 = {'gamma':[i/10.0 for i in range (0, 11)]}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265, max_depth=2, min_child_weight=6,\n",
    "                                                subsample=0.8, colsample_bytree=0.8, objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27),\n",
    "                        param_grid = paramt3, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch3.best_params_)\n",
    "print(gsearch3.best_score_)\n",
    "pp.pprint(gsearch3.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'subsample': 0.8}\n",
      "0.40666666666666673\n",
      "{'mean_fit_time': array([0.91076236, 0.97399349, 1.05238409, 1.09048157, 1.10584087,\n",
      "       1.18522873, 1.26401792, 1.25224943, 1.23090625, 1.22691703,\n",
      "       1.07053537, 0.94726348, 1.08569484, 1.19121265, 1.22332654,\n",
      "       1.25065355, 1.28815341, 1.27020106, 1.25923028, 1.24048085,\n",
      "       1.50198154, 1.39825864, 1.24227614, 1.4367557 , 1.55783162,\n",
      "       1.63223238, 1.68090281, 1.72378802, 1.85862641, 1.6934689 ,\n",
      "       1.70982547, 1.70723228, 1.50417552, 1.2855598 , 1.67392144,\n",
      "       1.84785647, 1.76447921, 1.85763021, 1.88016949, 1.94060783,\n",
      "       1.92445149, 1.8400764 , 1.81873484, 1.65796423, 1.42738042,\n",
      "       1.64499841, 1.81933222, 1.92405243, 2.04213614, 2.08562002,\n",
      "       2.09758835, 2.07205572, 2.09300013, 2.11354499, 1.90550184,\n",
      "       1.47625017, 1.80237813, 2.0431334 , 2.18036647, 2.23881054,\n",
      "       2.38063116, 2.39858222, 2.37664165, 2.53561625, 2.42531114,\n",
      "       2.2086906 , 1.67132859, 2.05131245, 2.30423508, 2.68741026,\n",
      "       2.66646624, 2.64651966, 2.71313853, 2.67105403, 2.66008358,\n",
      "       2.62218451, 2.39539089, 1.74313602, 2.12331901, 2.35749245,\n",
      "       2.50569611, 2.63794246, 2.72650547, 2.7352819 , 2.71493716,\n",
      "       2.69339423, 2.67504272, 2.44445992, 1.76148734, 2.12730832,\n",
      "       2.4257102 , 2.56713138, 2.71752977, 2.8122757 , 2.82404461,\n",
      "       2.83321991, 2.83581333, 3.23733935, 2.57909999, 1.77923961,\n",
      "       2.2130794 , 2.48255773, 2.65848722, 2.81486931, 2.91460214,\n",
      "       2.95768714, 2.9706521 , 2.93993487, 2.88807302, 2.6660676 ,\n",
      "       1.76806974, 2.2358181 , 2.57411284, 2.83202357, 2.95389705,\n",
      "       3.07218099, 3.12683434, 3.09811106, 3.08514585, 3.07098379,\n",
      "       2.67065511]),\n",
      " 'mean_score_time': array([0.00618362, 0.00738053, 0.0093749 , 0.00817842, 0.00897589,\n",
      "       0.0101728 , 0.00917521, 0.009375  , 0.00917544, 0.00917563,\n",
      "       0.00977392, 0.0065825 , 0.00797873, 0.00957427, 0.00977387,\n",
      "       0.00977397, 0.0095746 , 0.00957465, 0.00937543, 0.00957446,\n",
      "       0.01196771, 0.01236701, 0.00857749, 0.00997324, 0.01176877,\n",
      "       0.01176906, 0.01196775, 0.01276617, 0.01196837, 0.01256595,\n",
      "       0.01316466, 0.01256685, 0.01156912, 0.00837817, 0.01136975,\n",
      "       0.01236682, 0.01256633, 0.01296515, 0.01256652, 0.01376324,\n",
      "       0.01296487, 0.01336455, 0.01316438, 0.01356335, 0.00877638,\n",
      "       0.01196828, 0.01356378, 0.01376328, 0.01316514, 0.0135632 ,\n",
      "       0.01336474, 0.01296573, 0.01396255, 0.01396322, 0.01476026,\n",
      "       0.01037235, 0.01236672, 0.01496005, 0.01495986, 0.01456137,\n",
      "       0.01535878, 0.01515927, 0.01456127, 0.01555858, 0.01615691,\n",
      "       0.0157578 , 0.01097069, 0.01336365, 0.01615667, 0.01655574,\n",
      "       0.01615663, 0.01495991, 0.01615658, 0.01635633, 0.01635594,\n",
      "       0.01655579, 0.01615634, 0.01117058, 0.01296554, 0.01575775,\n",
      "       0.01615691, 0.01555805, 0.01635594, 0.0159574 , 0.01635618,\n",
      "       0.01635656, 0.01535931, 0.01615705, 0.01136942, 0.0133646 ,\n",
      "       0.01575813, 0.01575832, 0.01635633, 0.01715422, 0.01655536,\n",
      "       0.01595707, 0.01675491, 0.01795206, 0.01635642, 0.01236672,\n",
      "       0.01316504, 0.0159575 , 0.01555872, 0.01735349, 0.01615672,\n",
      "       0.01615696, 0.01715441, 0.01575751, 0.01655622, 0.01675487,\n",
      "       0.01136956, 0.01456165, 0.01595716, 0.01715388, 0.01575832,\n",
      "       0.01735353, 0.01655569, 0.01695437, 0.01695471, 0.01695518,\n",
      "       0.01655588]),\n",
      " 'mean_test_score': array([0.        , 0.34333333, 0.27666667, 0.25666667, 0.28      ,\n",
      "       0.31      , 0.28666667, 0.26333333, 0.28666667, 0.31      ,\n",
      "       0.30666667, 0.        , 0.34333333, 0.27666667, 0.25666667,\n",
      "       0.28      , 0.31      , 0.28666667, 0.26333333, 0.28666667,\n",
      "       0.31      , 0.30666667, 0.        , 0.36      , 0.3       ,\n",
      "       0.30666667, 0.34      , 0.34333333, 0.35666667, 0.35      ,\n",
      "       0.37      , 0.33      , 0.37333333, 0.        , 0.34333333,\n",
      "       0.30666667, 0.34      , 0.32666667, 0.33333333, 0.34666667,\n",
      "       0.36333333, 0.36333333, 0.37666667, 0.35666667, 0.        ,\n",
      "       0.33333333, 0.38      , 0.33      , 0.36333333, 0.37      ,\n",
      "       0.36666667, 0.34666667, 0.37      , 0.36666667, 0.35333333,\n",
      "       0.        , 0.3       , 0.33666667, 0.31666667, 0.35333333,\n",
      "       0.36333333, 0.34666667, 0.32333333, 0.39666667, 0.38      ,\n",
      "       0.37      , 0.        , 0.37666667, 0.34      , 0.34666667,\n",
      "       0.35333333, 0.33333333, 0.39      , 0.38666667, 0.38333333,\n",
      "       0.38      , 0.38666667, 0.        , 0.31666667, 0.33      ,\n",
      "       0.31666667, 0.34333333, 0.35      , 0.38666667, 0.38333333,\n",
      "       0.37      , 0.37      , 0.36666667, 0.        , 0.33      ,\n",
      "       0.33333333, 0.35      , 0.35333333, 0.35666667, 0.39666667,\n",
      "       0.39333333, 0.40666667, 0.37333333, 0.4       , 0.        ,\n",
      "       0.31333333, 0.37      , 0.34333333, 0.35      , 0.38      ,\n",
      "       0.38      , 0.38666667, 0.37666667, 0.37666667, 0.38666667,\n",
      "       0.        , 0.29333333, 0.30666667, 0.35      , 0.33      ,\n",
      "       0.36      , 0.35666667, 0.36      , 0.39333333, 0.36      ,\n",
      "       0.39666667]),\n",
      " 'mean_train_score': array([0.        , 0.41333333, 0.48083333, 0.52      , 0.56166667,\n",
      "       0.6025    , 0.61583333, 0.62666667, 0.63083333, 0.63916667,\n",
      "       0.64916667, 0.        , 0.41333333, 0.48083333, 0.52      ,\n",
      "       0.56166667, 0.6025    , 0.61583333, 0.62666667, 0.63083333,\n",
      "       0.63916667, 0.64916667, 0.        , 0.45333333, 0.51      ,\n",
      "       0.6175    , 0.66416667, 0.72416667, 0.72333333, 0.74333333,\n",
      "       0.76583333, 0.76666667, 0.7775    , 0.        , 0.425     ,\n",
      "       0.53166667, 0.6325    , 0.68583333, 0.74416667, 0.76666667,\n",
      "       0.78083333, 0.7975    , 0.79583333, 0.81166667, 0.        ,\n",
      "       0.41083333, 0.5525    , 0.64083333, 0.7       , 0.76333333,\n",
      "       0.78666667, 0.8025    , 0.82333333, 0.8325    , 0.8375    ,\n",
      "       0.        , 0.42416667, 0.54083333, 0.655     , 0.7075    ,\n",
      "       0.77083333, 0.80583333, 0.81416667, 0.84166667, 0.8425    ,\n",
      "       0.85083333, 0.        , 0.425     , 0.55833333, 0.66166667,\n",
      "       0.73416667, 0.78583333, 0.81333333, 0.8275    , 0.8475    ,\n",
      "       0.84583333, 0.85083333, 0.        , 0.42916667, 0.5625    ,\n",
      "       0.65      , 0.7275    , 0.77916667, 0.80583333, 0.85083333,\n",
      "       0.86      , 0.8625    , 0.86833333, 0.        , 0.40333333,\n",
      "       0.56583333, 0.65416667, 0.73416667, 0.7925    , 0.84333333,\n",
      "       0.84      , 0.86      , 0.8675    , 0.86416667, 0.        ,\n",
      "       0.41416667, 0.5775    , 0.66416667, 0.73833333, 0.8025    ,\n",
      "       0.83833333, 0.84583333, 0.86166667, 0.8775    , 0.87583333,\n",
      "       0.        , 0.38833333, 0.55583333, 0.66916667, 0.765     ,\n",
      "       0.80166667, 0.85583333, 0.87333333, 0.87666667, 0.88083333,\n",
      "       0.8775    ]),\n",
      " 'param_colsample_bytree': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
      "                   0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_subsample': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'colsample_bytree': 0.0, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.0, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.1, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.2, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.3, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.4, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.5, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.6, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.7, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 0.9, 'subsample': 1.0},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.0},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.1},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.2},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.3},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.4},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.5},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.6},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.7},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 0.9},\n",
      "            {'colsample_bytree': 1.0, 'subsample': 1.0}],\n",
      " 'rank_test_score': array([111,  65, 105, 109, 103,  89,  99, 107,  99,  87,  91, 111,  65,\n",
      "       105, 109, 103,  89,  99, 107,  99,  87,  91, 111,  41,  96,  91,\n",
      "        68,  62,  45,  53,  27,  77,  25, 111,  62,  91,  68,  81,  73,\n",
      "        61,  38,  38,  21,  45, 111,  73,  16,  77,  37,  27,  34,  58,\n",
      "        27,  34,  50, 111,  96,  71,  83,  50,  38,  58,  82,   3,  16,\n",
      "        27, 111,  21,  68,  58,  49,  73,   8,  11,  14,  16,   9, 111,\n",
      "        85,  77,  83,  62,  53,  11,  14,  27,  27,  34, 111,  77,  72,\n",
      "        53,  52,  45,   5,   7,   1,  26,   2, 111,  86,  27,  65,  53,\n",
      "        16,  16,   9,  21,  21,  11, 111,  98,  91,  53,  76,  41,  45,\n",
      "        41,   6,  41,   3]),\n",
      " 'split0_test_score': array([0.        , 0.35      , 0.38333333, 0.31666667, 0.35      ,\n",
      "       0.33333333, 0.26666667, 0.3       , 0.33333333, 0.38333333,\n",
      "       0.33333333, 0.        , 0.35      , 0.38333333, 0.31666667,\n",
      "       0.35      , 0.33333333, 0.26666667, 0.3       , 0.33333333,\n",
      "       0.38333333, 0.33333333, 0.        , 0.36666667, 0.35      ,\n",
      "       0.33333333, 0.33333333, 0.4       , 0.46666667, 0.38333333,\n",
      "       0.46666667, 0.36666667, 0.51666667, 0.        , 0.35      ,\n",
      "       0.26666667, 0.35      , 0.38333333, 0.45      , 0.33333333,\n",
      "       0.38333333, 0.43333333, 0.45      , 0.4       , 0.        ,\n",
      "       0.43333333, 0.5       , 0.35      , 0.38333333, 0.36666667,\n",
      "       0.41666667, 0.31666667, 0.4       , 0.41666667, 0.4       ,\n",
      "       0.        , 0.28333333, 0.46666667, 0.3       , 0.43333333,\n",
      "       0.48333333, 0.4       , 0.36666667, 0.4       , 0.41666667,\n",
      "       0.41666667, 0.        , 0.38333333, 0.38333333, 0.45      ,\n",
      "       0.4       , 0.43333333, 0.45      , 0.4       , 0.38333333,\n",
      "       0.41666667, 0.43333333, 0.        , 0.3       , 0.38333333,\n",
      "       0.36666667, 0.38333333, 0.28333333, 0.4       , 0.45      ,\n",
      "       0.35      , 0.41666667, 0.43333333, 0.        , 0.33333333,\n",
      "       0.43333333, 0.4       , 0.33333333, 0.4       , 0.43333333,\n",
      "       0.48333333, 0.41666667, 0.43333333, 0.45      , 0.        ,\n",
      "       0.23333333, 0.43333333, 0.4       , 0.33333333, 0.41666667,\n",
      "       0.43333333, 0.45      , 0.35      , 0.43333333, 0.43333333,\n",
      "       0.        , 0.31666667, 0.4       , 0.41666667, 0.33333333,\n",
      "       0.41666667, 0.43333333, 0.38333333, 0.41666667, 0.41666667,\n",
      "       0.45      ]),\n",
      " 'split0_train_score': array([0.        , 0.39583333, 0.49166667, 0.50833333, 0.52083333,\n",
      "       0.57083333, 0.575     , 0.57916667, 0.59583333, 0.6       ,\n",
      "       0.6125    , 0.        , 0.39583333, 0.49166667, 0.50833333,\n",
      "       0.52083333, 0.57083333, 0.575     , 0.57916667, 0.59583333,\n",
      "       0.6       , 0.6125    , 0.        , 0.45      , 0.47916667,\n",
      "       0.5875    , 0.63333333, 0.71666667, 0.72083333, 0.725     ,\n",
      "       0.7375    , 0.71666667, 0.74583333, 0.        , 0.36666667,\n",
      "       0.4875    , 0.61666667, 0.675     , 0.74583333, 0.76666667,\n",
      "       0.75833333, 0.77083333, 0.77083333, 0.78333333, 0.        ,\n",
      "       0.425     , 0.54583333, 0.59583333, 0.68333333, 0.75      ,\n",
      "       0.74583333, 0.7875    , 0.79583333, 0.80833333, 0.8       ,\n",
      "       0.        , 0.4       , 0.52916667, 0.6375    , 0.67916667,\n",
      "       0.74166667, 0.77083333, 0.80833333, 0.83333333, 0.81666667,\n",
      "       0.80833333, 0.        , 0.4       , 0.5375    , 0.67083333,\n",
      "       0.71666667, 0.7875    , 0.78333333, 0.7875    , 0.825     ,\n",
      "       0.82916667, 0.79583333, 0.        , 0.35      , 0.5375    ,\n",
      "       0.61666667, 0.70833333, 0.74583333, 0.7875    , 0.825     ,\n",
      "       0.8375    , 0.84166667, 0.82916667, 0.        , 0.40416667,\n",
      "       0.6       , 0.63333333, 0.67083333, 0.75833333, 0.8125    ,\n",
      "       0.80416667, 0.82083333, 0.8625    , 0.84166667, 0.        ,\n",
      "       0.33333333, 0.56666667, 0.65      , 0.72916667, 0.80833333,\n",
      "       0.79166667, 0.82916667, 0.85      , 0.85      , 0.8375    ,\n",
      "       0.        , 0.35416667, 0.5375    , 0.65416667, 0.75833333,\n",
      "       0.77916667, 0.85      , 0.84166667, 0.86666667, 0.83333333,\n",
      "       0.85833333]),\n",
      " 'split1_test_score': array([0.        , 0.35      , 0.28333333, 0.26666667, 0.26666667,\n",
      "       0.3       , 0.23333333, 0.2       , 0.25      , 0.33333333,\n",
      "       0.28333333, 0.        , 0.35      , 0.28333333, 0.26666667,\n",
      "       0.26666667, 0.3       , 0.23333333, 0.2       , 0.25      ,\n",
      "       0.33333333, 0.28333333, 0.        , 0.5       , 0.35      ,\n",
      "       0.26666667, 0.3       , 0.31666667, 0.31666667, 0.3       ,\n",
      "       0.28333333, 0.31666667, 0.35      , 0.        , 0.33333333,\n",
      "       0.33333333, 0.36666667, 0.28333333, 0.26666667, 0.3       ,\n",
      "       0.33333333, 0.31666667, 0.33333333, 0.3       , 0.        ,\n",
      "       0.31666667, 0.35      , 0.3       , 0.33333333, 0.31666667,\n",
      "       0.3       , 0.3       , 0.31666667, 0.4       , 0.35      ,\n",
      "       0.        , 0.28333333, 0.31666667, 0.25      , 0.31666667,\n",
      "       0.28333333, 0.26666667, 0.25      , 0.38333333, 0.36666667,\n",
      "       0.38333333, 0.        , 0.36666667, 0.35      , 0.31666667,\n",
      "       0.33333333, 0.25      , 0.26666667, 0.36666667, 0.33333333,\n",
      "       0.33333333, 0.33333333, 0.        , 0.3       , 0.3       ,\n",
      "       0.28333333, 0.21666667, 0.4       , 0.28333333, 0.31666667,\n",
      "       0.36666667, 0.35      , 0.36666667, 0.        , 0.31666667,\n",
      "       0.28333333, 0.3       , 0.31666667, 0.3       , 0.36666667,\n",
      "       0.35      , 0.38333333, 0.36666667, 0.38333333, 0.        ,\n",
      "       0.31666667, 0.4       , 0.31666667, 0.31666667, 0.28333333,\n",
      "       0.31666667, 0.3       , 0.35      , 0.31666667, 0.43333333,\n",
      "       0.        , 0.26666667, 0.23333333, 0.26666667, 0.3       ,\n",
      "       0.36666667, 0.26666667, 0.26666667, 0.36666667, 0.31666667,\n",
      "       0.35      ]),\n",
      " 'split1_train_score': array([0.        , 0.475     , 0.5       , 0.54583333, 0.575     ,\n",
      "       0.63333333, 0.65833333, 0.6375    , 0.64166667, 0.67916667,\n",
      "       0.67083333, 0.        , 0.475     , 0.5       , 0.54583333,\n",
      "       0.575     , 0.63333333, 0.65833333, 0.6375    , 0.64166667,\n",
      "       0.67916667, 0.67083333, 0.        , 0.50416667, 0.55      ,\n",
      "       0.6375    , 0.67083333, 0.70833333, 0.72916667, 0.77916667,\n",
      "       0.77916667, 0.78333333, 0.82083333, 0.        , 0.45      ,\n",
      "       0.575     , 0.65833333, 0.69166667, 0.75833333, 0.77916667,\n",
      "       0.7625    , 0.81666667, 0.83333333, 0.85      , 0.        ,\n",
      "       0.43333333, 0.56666667, 0.64583333, 0.7       , 0.78333333,\n",
      "       0.79583333, 0.77083333, 0.85416667, 0.84583333, 0.8875    ,\n",
      "       0.        , 0.4125    , 0.5375    , 0.6625    , 0.72916667,\n",
      "       0.775     , 0.81666667, 0.79583333, 0.85416667, 0.875     ,\n",
      "       0.89166667, 0.        , 0.4375    , 0.54583333, 0.71666667,\n",
      "       0.75      , 0.78333333, 0.83333333, 0.82083333, 0.85416667,\n",
      "       0.8875    , 0.89583333, 0.        , 0.45833333, 0.55833333,\n",
      "       0.62083333, 0.70416667, 0.80416667, 0.8125    , 0.85833333,\n",
      "       0.87083333, 0.89166667, 0.91666667, 0.        , 0.42916667,\n",
      "       0.5125    , 0.62916667, 0.74583333, 0.80833333, 0.84166667,\n",
      "       0.87083333, 0.88333333, 0.89583333, 0.89583333, 0.        ,\n",
      "       0.44583333, 0.5875    , 0.67083333, 0.74583333, 0.79583333,\n",
      "       0.8875    , 0.87083333, 0.875     , 0.89583333, 0.9       ,\n",
      "       0.        , 0.41666667, 0.58333333, 0.65      , 0.79166667,\n",
      "       0.80416667, 0.87083333, 0.88333333, 0.89583333, 0.9125    ,\n",
      "       0.91666667]),\n",
      " 'split2_test_score': array([0.        , 0.33333333, 0.25      , 0.2       , 0.3       ,\n",
      "       0.31666667, 0.28333333, 0.3       , 0.3       , 0.3       ,\n",
      "       0.3       , 0.        , 0.33333333, 0.25      , 0.2       ,\n",
      "       0.3       , 0.31666667, 0.28333333, 0.3       , 0.3       ,\n",
      "       0.3       , 0.3       , 0.        , 0.3       , 0.25      ,\n",
      "       0.25      , 0.21666667, 0.35      , 0.3       , 0.35      ,\n",
      "       0.28333333, 0.28333333, 0.35      , 0.        , 0.36666667,\n",
      "       0.28333333, 0.28333333, 0.25      , 0.25      , 0.33333333,\n",
      "       0.35      , 0.33333333, 0.33333333, 0.38333333, 0.        ,\n",
      "       0.38333333, 0.3       , 0.26666667, 0.33333333, 0.36666667,\n",
      "       0.35      , 0.33333333, 0.4       , 0.31666667, 0.33333333,\n",
      "       0.        , 0.3       , 0.28333333, 0.26666667, 0.31666667,\n",
      "       0.3       , 0.33333333, 0.3       , 0.38333333, 0.33333333,\n",
      "       0.35      , 0.        , 0.36666667, 0.28333333, 0.3       ,\n",
      "       0.35      , 0.28333333, 0.35      , 0.4       , 0.38333333,\n",
      "       0.35      , 0.41666667, 0.        , 0.31666667, 0.25      ,\n",
      "       0.23333333, 0.26666667, 0.4       , 0.35      , 0.36666667,\n",
      "       0.38333333, 0.33333333, 0.35      , 0.        , 0.3       ,\n",
      "       0.18333333, 0.36666667, 0.35      , 0.35      , 0.35      ,\n",
      "       0.33333333, 0.4       , 0.35      , 0.38333333, 0.        ,\n",
      "       0.28333333, 0.35      , 0.31666667, 0.3       , 0.38333333,\n",
      "       0.4       , 0.4       , 0.38333333, 0.36666667, 0.4       ,\n",
      "       0.        , 0.25      , 0.2       , 0.31666667, 0.3       ,\n",
      "       0.25      , 0.36666667, 0.35      , 0.36666667, 0.33333333,\n",
      "       0.38333333]),\n",
      " 'split2_train_score': array([0.        , 0.35416667, 0.5       , 0.5125    , 0.54166667,\n",
      "       0.59166667, 0.59166667, 0.62916667, 0.6125    , 0.65833333,\n",
      "       0.65833333, 0.        , 0.35416667, 0.5       , 0.5125    ,\n",
      "       0.54166667, 0.59166667, 0.59166667, 0.62916667, 0.6125    ,\n",
      "       0.65833333, 0.65833333, 0.        , 0.45      , 0.52083333,\n",
      "       0.59583333, 0.67916667, 0.74166667, 0.75      , 0.70833333,\n",
      "       0.75416667, 0.775     , 0.77083333, 0.        , 0.42083333,\n",
      "       0.57916667, 0.60833333, 0.69583333, 0.73333333, 0.77083333,\n",
      "       0.775     , 0.775     , 0.77916667, 0.80416667, 0.        ,\n",
      "       0.3875    , 0.56666667, 0.64166667, 0.7       , 0.75833333,\n",
      "       0.775     , 0.80416667, 0.82083333, 0.8125    , 0.82916667,\n",
      "       0.        , 0.40833333, 0.54166667, 0.67083333, 0.72916667,\n",
      "       0.79166667, 0.80833333, 0.8       , 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.        , 0.37916667, 0.59583333, 0.67083333,\n",
      "       0.74583333, 0.80416667, 0.81666667, 0.82916667, 0.81666667,\n",
      "       0.825     , 0.84583333, 0.        , 0.3625    , 0.575     ,\n",
      "       0.65833333, 0.7375    , 0.74583333, 0.79583333, 0.85      ,\n",
      "       0.85416667, 0.85      , 0.85833333, 0.        , 0.325     ,\n",
      "       0.60416667, 0.68333333, 0.74583333, 0.8       , 0.85      ,\n",
      "       0.84166667, 0.84583333, 0.82916667, 0.85833333, 0.        ,\n",
      "       0.37916667, 0.6       , 0.65833333, 0.7       , 0.8       ,\n",
      "       0.82083333, 0.83333333, 0.84166667, 0.87083333, 0.86666667,\n",
      "       0.        , 0.30833333, 0.54166667, 0.675     , 0.7625    ,\n",
      "       0.82083333, 0.82916667, 0.88333333, 0.85833333, 0.88333333,\n",
      "       0.85833333]),\n",
      " 'split3_test_score': array([0.        , 0.36666667, 0.3       , 0.26666667, 0.26666667,\n",
      "       0.31666667, 0.38333333, 0.28333333, 0.3       , 0.3       ,\n",
      "       0.35      , 0.        , 0.36666667, 0.3       , 0.26666667,\n",
      "       0.26666667, 0.31666667, 0.38333333, 0.28333333, 0.3       ,\n",
      "       0.3       , 0.35      , 0.        , 0.33333333, 0.25      ,\n",
      "       0.31666667, 0.43333333, 0.36666667, 0.36666667, 0.36666667,\n",
      "       0.43333333, 0.33333333, 0.33333333, 0.        , 0.41666667,\n",
      "       0.33333333, 0.35      , 0.4       , 0.43333333, 0.45      ,\n",
      "       0.36666667, 0.4       , 0.41666667, 0.38333333, 0.        ,\n",
      "       0.31666667, 0.45      , 0.36666667, 0.4       , 0.5       ,\n",
      "       0.43333333, 0.43333333, 0.31666667, 0.38333333, 0.33333333,\n",
      "       0.        , 0.28333333, 0.33333333, 0.41666667, 0.36666667,\n",
      "       0.41666667, 0.35      , 0.35      , 0.41666667, 0.4       ,\n",
      "       0.33333333, 0.        , 0.38333333, 0.4       , 0.38333333,\n",
      "       0.36666667, 0.35      , 0.51666667, 0.36666667, 0.45      ,\n",
      "       0.41666667, 0.38333333, 0.        , 0.33333333, 0.38333333,\n",
      "       0.35      , 0.45      , 0.38333333, 0.45      , 0.41666667,\n",
      "       0.4       , 0.36666667, 0.35      , 0.        , 0.35      ,\n",
      "       0.43333333, 0.3       , 0.43333333, 0.43333333, 0.45      ,\n",
      "       0.4       , 0.46666667, 0.4       , 0.38333333, 0.        ,\n",
      "       0.35      , 0.4       , 0.35      , 0.43333333, 0.45      ,\n",
      "       0.41666667, 0.36666667, 0.43333333, 0.4       , 0.33333333,\n",
      "       0.        , 0.3       , 0.35      , 0.41666667, 0.4       ,\n",
      "       0.38333333, 0.36666667, 0.43333333, 0.38333333, 0.4       ,\n",
      "       0.41666667]),\n",
      " 'split3_train_score': array([0.        , 0.4125    , 0.44166667, 0.4875    , 0.56666667,\n",
      "       0.5875    , 0.62083333, 0.625     , 0.63333333, 0.59583333,\n",
      "       0.63333333, 0.        , 0.4125    , 0.44166667, 0.4875    ,\n",
      "       0.56666667, 0.5875    , 0.62083333, 0.625     , 0.63333333,\n",
      "       0.59583333, 0.63333333, 0.        , 0.35833333, 0.475     ,\n",
      "       0.63333333, 0.64583333, 0.70833333, 0.7125    , 0.75833333,\n",
      "       0.76666667, 0.75833333, 0.75416667, 0.        , 0.42083333,\n",
      "       0.49166667, 0.6375    , 0.68333333, 0.74166667, 0.74166667,\n",
      "       0.8       , 0.79583333, 0.775     , 0.80416667, 0.        ,\n",
      "       0.38333333, 0.54166667, 0.62083333, 0.7       , 0.74583333,\n",
      "       0.8125    , 0.8125    , 0.825     , 0.83333333, 0.82083333,\n",
      "       0.        , 0.42916667, 0.55833333, 0.62916667, 0.67916667,\n",
      "       0.76666667, 0.825     , 0.82083333, 0.82916667, 0.83333333,\n",
      "       0.85833333, 0.        , 0.4375    , 0.55      , 0.575     ,\n",
      "       0.7125    , 0.75416667, 0.8       , 0.82916667, 0.85833333,\n",
      "       0.81666667, 0.85      , 0.        , 0.4625    , 0.52083333,\n",
      "       0.6625    , 0.72916667, 0.79166667, 0.80833333, 0.82916667,\n",
      "       0.84583333, 0.85      , 0.85416667, 0.        , 0.4125    ,\n",
      "       0.56666667, 0.64166667, 0.74583333, 0.79166667, 0.85416667,\n",
      "       0.80833333, 0.86666667, 0.8625    , 0.8625    , 0.        ,\n",
      "       0.41666667, 0.55416667, 0.65      , 0.75416667, 0.78333333,\n",
      "       0.8375    , 0.83333333, 0.85      , 0.875     , 0.87916667,\n",
      "       0.        , 0.38333333, 0.54166667, 0.67916667, 0.74166667,\n",
      "       0.77916667, 0.85      , 0.875     , 0.88333333, 0.8875    ,\n",
      "       0.8625    ]),\n",
      " 'split4_test_score': array([0.        , 0.31666667, 0.16666667, 0.23333333, 0.21666667,\n",
      "       0.28333333, 0.26666667, 0.23333333, 0.25      , 0.23333333,\n",
      "       0.26666667, 0.        , 0.31666667, 0.16666667, 0.23333333,\n",
      "       0.21666667, 0.28333333, 0.26666667, 0.23333333, 0.25      ,\n",
      "       0.23333333, 0.26666667, 0.        , 0.3       , 0.3       ,\n",
      "       0.36666667, 0.41666667, 0.28333333, 0.33333333, 0.35      ,\n",
      "       0.38333333, 0.35      , 0.31666667, 0.        , 0.25      ,\n",
      "       0.31666667, 0.35      , 0.31666667, 0.26666667, 0.31666667,\n",
      "       0.38333333, 0.33333333, 0.35      , 0.31666667, 0.        ,\n",
      "       0.21666667, 0.3       , 0.36666667, 0.36666667, 0.3       ,\n",
      "       0.33333333, 0.35      , 0.41666667, 0.31666667, 0.35      ,\n",
      "       0.        , 0.35      , 0.28333333, 0.35      , 0.33333333,\n",
      "       0.33333333, 0.38333333, 0.35      , 0.4       , 0.38333333,\n",
      "       0.36666667, 0.        , 0.38333333, 0.28333333, 0.28333333,\n",
      "       0.31666667, 0.35      , 0.36666667, 0.4       , 0.36666667,\n",
      "       0.38333333, 0.36666667, 0.        , 0.33333333, 0.33333333,\n",
      "       0.35      , 0.4       , 0.28333333, 0.45      , 0.36666667,\n",
      "       0.35      , 0.38333333, 0.33333333, 0.        , 0.35      ,\n",
      "       0.33333333, 0.38333333, 0.33333333, 0.3       , 0.38333333,\n",
      "       0.4       , 0.36666667, 0.31666667, 0.4       , 0.        ,\n",
      "       0.38333333, 0.26666667, 0.33333333, 0.36666667, 0.36666667,\n",
      "       0.33333333, 0.41666667, 0.36666667, 0.36666667, 0.33333333,\n",
      "       0.        , 0.33333333, 0.35      , 0.33333333, 0.31666667,\n",
      "       0.38333333, 0.35      , 0.36666667, 0.43333333, 0.33333333,\n",
      "       0.38333333]),\n",
      " 'split4_train_score': array([0.        , 0.42916667, 0.47083333, 0.54583333, 0.60416667,\n",
      "       0.62916667, 0.63333333, 0.6625    , 0.67083333, 0.6625    ,\n",
      "       0.67083333, 0.        , 0.42916667, 0.47083333, 0.54583333,\n",
      "       0.60416667, 0.62916667, 0.63333333, 0.6625    , 0.67083333,\n",
      "       0.6625    , 0.67083333, 0.        , 0.50416667, 0.525     ,\n",
      "       0.63333333, 0.69166667, 0.74583333, 0.70416667, 0.74583333,\n",
      "       0.79166667, 0.8       , 0.79583333, 0.        , 0.46666667,\n",
      "       0.525     , 0.64166667, 0.68333333, 0.74166667, 0.775     ,\n",
      "       0.80833333, 0.82916667, 0.82083333, 0.81666667, 0.        ,\n",
      "       0.425     , 0.54166667, 0.7       , 0.71666667, 0.77916667,\n",
      "       0.80416667, 0.8375    , 0.82083333, 0.8625    , 0.85      ,\n",
      "       0.        , 0.47083333, 0.5375    , 0.675     , 0.72083333,\n",
      "       0.77916667, 0.80833333, 0.84583333, 0.85833333, 0.85416667,\n",
      "       0.8625    , 0.        , 0.47083333, 0.5625    , 0.675     ,\n",
      "       0.74583333, 0.8       , 0.83333333, 0.87083333, 0.88333333,\n",
      "       0.87083333, 0.86666667, 0.        , 0.5125    , 0.62083333,\n",
      "       0.69166667, 0.75833333, 0.80833333, 0.825     , 0.89166667,\n",
      "       0.89166667, 0.87916667, 0.88333333, 0.        , 0.44583333,\n",
      "       0.54583333, 0.68333333, 0.7625    , 0.80416667, 0.85833333,\n",
      "       0.875     , 0.88333333, 0.8875    , 0.8625    , 0.        ,\n",
      "       0.49583333, 0.57916667, 0.69166667, 0.7625    , 0.825     ,\n",
      "       0.85416667, 0.8625    , 0.89166667, 0.89583333, 0.89583333,\n",
      "       0.        , 0.47916667, 0.575     , 0.6875    , 0.77083333,\n",
      "       0.825     , 0.87916667, 0.88333333, 0.87916667, 0.8875    ,\n",
      "       0.89166667]),\n",
      " 'std_fit_time': array([0.03982507, 0.01999225, 0.01724472, 0.01102671, 0.00395922,\n",
      "       0.06129673, 0.00421251, 0.00325318, 0.00486126, 0.01440328,\n",
      "       0.00886721, 0.00806287, 0.00430582, 0.00654283, 0.00632633,\n",
      "       0.00935605, 0.00272029, 0.00715294, 0.00831091, 0.0072029 ,\n",
      "       0.0521135 , 0.02280385, 0.01643086, 0.01771354, 0.02267294,\n",
      "       0.02091673, 0.0105669 , 0.01971181, 0.07268785, 0.0092491 ,\n",
      "       0.03120613, 0.02563338, 0.02685289, 0.01154488, 0.16626897,\n",
      "       0.12075088, 0.01459489, 0.02314654, 0.01151737, 0.04568813,\n",
      "       0.07911914, 0.01269421, 0.01717727, 0.03131446, 0.03186077,\n",
      "       0.01658834, 0.0146083 , 0.03005504, 0.02300003, 0.01998045,\n",
      "       0.01149947, 0.01201122, 0.02295678, 0.03010205, 0.01694394,\n",
      "       0.03419779, 0.02272826, 0.05034153, 0.0035349 , 0.0256329 ,\n",
      "       0.0569228 , 0.02548954, 0.01779606, 0.07672197, 0.01977044,\n",
      "       0.0323023 , 0.01136118, 0.04011841, 0.00831094, 0.15205403,\n",
      "       0.09351883, 0.00986519, 0.02319528, 0.0161851 , 0.01220539,\n",
      "       0.0095747 , 0.01215557, 0.01195849, 0.01178361, 0.02083848,\n",
      "       0.03695567, 0.01950327, 0.00603049, 0.01387142, 0.03496906,\n",
      "       0.02757165, 0.02441687, 0.02704208, 0.02479683, 0.02625827,\n",
      "       0.02108534, 0.05278888, 0.02254351, 0.0292227 , 0.01233771,\n",
      "       0.01302544, 0.03293631, 0.13278682, 0.03102341, 0.03308997,\n",
      "       0.05684657, 0.01173947, 0.03929299, 0.01779206, 0.00660309,\n",
      "       0.0198125 , 0.02133989, 0.02150518, 0.0153391 , 0.02062754,\n",
      "       0.02567915, 0.0309035 , 0.05520183, 0.02340299, 0.02638225,\n",
      "       0.01176008, 0.01160362, 0.02901913, 0.02770083, 0.02629926,\n",
      "       0.16217608]),\n",
      " 'std_score_time': array([0.00039887, 0.00135281, 0.0010171 , 0.00039866, 0.0006306 ,\n",
      "       0.00039914, 0.00039904, 0.0004886 , 0.000746  , 0.00039847,\n",
      "       0.00074647, 0.00048871, 0.00063083, 0.0010165 , 0.00074639,\n",
      "       0.00039887, 0.0010171 , 0.00079805, 0.00079782, 0.00079825,\n",
      "       0.00063113, 0.00048842, 0.00048834, 0.00109284, 0.00116306,\n",
      "       0.00132313, 0.0008917 , 0.00074643, 0.00109249, 0.0004884 ,\n",
      "       0.00074638, 0.00048856, 0.0004886 , 0.00048889, 0.00135292,\n",
      "       0.00048848, 0.00048891, 0.00063105, 0.00048877, 0.00074688,\n",
      "       0.00089202, 0.00101717, 0.00039895, 0.00119617, 0.00039861,\n",
      "       0.00109258, 0.00119711, 0.00074631, 0.00074625, 0.00079831,\n",
      "       0.00048856, 0.00089218, 0.00063098, 0.00109258, 0.00039899,\n",
      "       0.00048875, 0.00101695, 0.00109249, 0.00063113, 0.00079749,\n",
      "       0.000798  , 0.00039868, 0.00101678, 0.00101735, 0.00074648,\n",
      "       0.00097772, 0.00109245, 0.00079761, 0.00116319, 0.00149276,\n",
      "       0.00039926, 0.00089244, 0.00132318, 0.00101694, 0.00184954,\n",
      "       0.00135251, 0.00074606, 0.0007463 , 0.00063075, 0.00074628,\n",
      "       0.00097748, 0.00149278, 0.00135326, 0.0014101 , 0.00101775,\n",
      "       0.00101699, 0.00101702, 0.0009772 , 0.00079765, 0.00048838,\n",
      "       0.0003994 , 0.00116312, 0.00119711, 0.00074603, 0.0013528 ,\n",
      "       0.00063052, 0.00116361, 0.00373119, 0.00101658, 0.00337299,\n",
      "       0.00074653, 0.00126146, 0.00162032, 0.00249143, 0.00074653,\n",
      "       0.0011627 , 0.00116296, 0.00097747, 0.00135288, 0.0009768 ,\n",
      "       0.0007977 , 0.00079787, 0.00089186, 0.00097686, 0.00074624,\n",
      "       0.00149197, 0.00048844, 0.00109258, 0.00199435, 0.00063075,\n",
      "       0.00048811]),\n",
      " 'std_test_score': array([0.        , 0.01699673, 0.07039571, 0.03887301, 0.04396969,\n",
      "       0.01699673, 0.0509902 , 0.04      , 0.03231787, 0.04898979,\n",
      "       0.03091206, 0.        , 0.01699673, 0.07039571, 0.03887301,\n",
      "       0.04396969, 0.01699673, 0.0509902 , 0.04      , 0.03231787,\n",
      "       0.04898979, 0.03091206, 0.        , 0.07423686, 0.04472136,\n",
      "       0.042947  , 0.07930252, 0.04027682, 0.05925463, 0.02788867,\n",
      "       0.07557189, 0.02867442, 0.07272475, 0.        , 0.05436502,\n",
      "       0.02708013, 0.02905933, 0.05734884, 0.08881942, 0.05312459,\n",
      "       0.01943651, 0.04521553, 0.04784233, 0.04027682, 0.        ,\n",
      "       0.07302967, 0.08124038, 0.04      , 0.02666667, 0.07023769,\n",
      "       0.0505525 , 0.04642796, 0.04396969, 0.0421637 , 0.0244949 ,\n",
      "       0.        , 0.02581989, 0.0678233 , 0.06055301, 0.04396969,\n",
      "       0.07557189, 0.04642796, 0.042947  , 0.01247219, 0.02867442,\n",
      "       0.02867442, 0.        , 0.00816497, 0.04898979, 0.06182412,\n",
      "       0.02867442, 0.06324555, 0.08602325, 0.01632993, 0.03800585,\n",
      "       0.03399346, 0.03559026, 0.        , 0.01490712, 0.0509902 ,\n",
      "       0.0505525 , 0.08730534, 0.05477226, 0.06359595, 0.04594683,\n",
      "       0.01943651, 0.02867442, 0.03496029, 0.        , 0.01943651,\n",
      "       0.09486833, 0.0421637 , 0.04136558, 0.05333333, 0.03858612,\n",
      "       0.05228129, 0.03431877, 0.04027682, 0.02581989, 0.        ,\n",
      "       0.05206833, 0.05811865, 0.03091206, 0.04714045, 0.05617433,\n",
      "       0.04642796, 0.0509902 , 0.03091206, 0.03887301, 0.04521553,\n",
      "       0.        , 0.03091206, 0.07644897, 0.05868939, 0.03711843,\n",
      "       0.05734884, 0.05333333, 0.05436502, 0.02708013, 0.04027682,\n",
      "       0.03399346]),\n",
      " 'std_train_score': array([0.        , 0.03965126, 0.02229848, 0.0227303 , 0.02855307,\n",
      "       0.02452323, 0.02962731, 0.02708013, 0.02563093, 0.03441979,\n",
      "       0.02288255, 0.        , 0.03965126, 0.02229848, 0.0227303 ,\n",
      "       0.02855307, 0.02452323, 0.02962731, 0.02708013, 0.02563093,\n",
      "       0.03441979, 0.02288255, 0.        , 0.05332031, 0.02869863,\n",
      "       0.02131119, 0.02150581, 0.01632993, 0.0157233 , 0.02480479,\n",
      "       0.01889297, 0.02838231, 0.02758824, 0.        , 0.03405469,\n",
      "       0.03931709, 0.01795055, 0.00726483, 0.00816497, 0.01317616,\n",
      "       0.02      , 0.02276083, 0.02595402, 0.02195323, 0.        ,\n",
      "       0.02101587, 0.01166667, 0.0345004 , 0.01054093, 0.01522972,\n",
      "       0.02392117, 0.02260777, 0.01855921, 0.0203101 , 0.02969755,\n",
      "       0.        , 0.02519369, 0.00964653, 0.01833333, 0.02333333,\n",
      "       0.01666667, 0.01855921, 0.01798919, 0.01207615, 0.02013841,\n",
      "       0.02818589, 0.        , 0.03205897, 0.02041241, 0.04665178,\n",
      "       0.0161159 , 0.01759893, 0.01943651, 0.0265623 , 0.02409472,\n",
      "       0.02801289, 0.03263859, 0.        , 0.06263873, 0.03446012,\n",
      "       0.02801289, 0.01982563, 0.02776389, 0.01307032, 0.02392117,\n",
      "       0.01929306, 0.01936492, 0.02965074, 0.        , 0.04169999,\n",
      "       0.03429853, 0.02415229, 0.03231787, 0.01795055, 0.0163724 ,\n",
      "       0.02988404, 0.02395018, 0.02333333, 0.01759893, 0.        ,\n",
      "       0.05556528, 0.01594261, 0.0157233 , 0.02211083, 0.01384437,\n",
      "       0.03210227, 0.01728037, 0.01870829, 0.01719981, 0.02257703,\n",
      "       0.        , 0.05769893, 0.01929306, 0.01457738, 0.0163724 ,\n",
      "       0.01964971, 0.01759893, 0.01615893, 0.01307032, 0.02590045,\n",
      "       0.02321398])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 5 \n",
    "paramt5 = {'subsample':[i/10.0 for i in range (0, 11)], 'colsample_bytree':[i/10.0 for i in range (0, 11)]}\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0),\n",
    "                        param_grid = paramt5, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch5.best_params_)\n",
    "print(gsearch5.best_score_)\n",
    "pp.pprint(gsearch5.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'subsample': 0.8}\n",
      "0.40666666666666673\n",
      "{'mean_fit_time': array([2.22830453, 1.557832  , 1.59393096, 1.59912105, 1.60370908,\n",
      "       1.61388183, 1.6555707 , 1.68170066, 1.49340477]),\n",
      " 'mean_score_time': array([0.00837789, 0.00917492, 0.00977335, 0.00857735, 0.00917592,\n",
      "       0.00977378, 0.00917506, 0.0095737 , 0.00937486]),\n",
      " 'mean_test_score': array([0.38666667, 0.40666667, 0.4       , 0.38666667, 0.40666667,\n",
      "       0.4       , 0.39      , 0.37666667, 0.37333333]),\n",
      " 'mean_train_score': array([0.855     , 0.86      , 0.86      , 0.855     , 0.86      ,\n",
      "       0.86      , 0.855     , 0.86166667, 0.87583333]),\n",
      " 'param_colsample_bytree': masked_array(data=[0.75, 0.75, 0.75, 0.8, 0.8, 0.8, 0.85, 0.85, 0.85],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_subsample': masked_array(data=[0.75, 0.8, 0.85, 0.75, 0.8, 0.85, 0.75, 0.8, 0.85],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'colsample_bytree': 0.75, 'subsample': 0.75},\n",
      "            {'colsample_bytree': 0.75, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.75, 'subsample': 0.85},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.75},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.8, 'subsample': 0.85},\n",
      "            {'colsample_bytree': 0.85, 'subsample': 0.75},\n",
      "            {'colsample_bytree': 0.85, 'subsample': 0.8},\n",
      "            {'colsample_bytree': 0.85, 'subsample': 0.85}],\n",
      " 'rank_test_score': array([6, 1, 3, 6, 1, 3, 5, 8, 9]),\n",
      " 'split0_test_score': array([0.41666667, 0.41666667, 0.46666667, 0.41666667, 0.41666667,\n",
      "       0.46666667, 0.45      , 0.35      , 0.45      ]),\n",
      " 'split0_train_score': array([0.84583333, 0.82083333, 0.82916667, 0.84583333, 0.82083333,\n",
      "       0.82916667, 0.81666667, 0.85      , 0.84166667]),\n",
      " 'split1_test_score': array([0.38333333, 0.38333333, 0.36666667, 0.38333333, 0.38333333,\n",
      "       0.36666667, 0.36666667, 0.35      , 0.36666667]),\n",
      " 'split1_train_score': array([0.87083333, 0.88333333, 0.89583333, 0.87083333, 0.88333333,\n",
      "       0.89583333, 0.875     , 0.875     , 0.89166667]),\n",
      " 'split2_test_score': array([0.33333333, 0.4       , 0.38333333, 0.33333333, 0.4       ,\n",
      "       0.38333333, 0.36666667, 0.38333333, 0.31666667]),\n",
      " 'split2_train_score': array([0.83333333, 0.84583333, 0.83333333, 0.83333333, 0.84583333,\n",
      "       0.83333333, 0.82083333, 0.84166667, 0.8625    ]),\n",
      " 'split3_test_score': array([0.43333333, 0.46666667, 0.38333333, 0.43333333, 0.46666667,\n",
      "       0.38333333, 0.43333333, 0.43333333, 0.36666667]),\n",
      " 'split3_train_score': array([0.84166667, 0.86666667, 0.85833333, 0.84166667, 0.86666667,\n",
      "       0.85833333, 0.875     , 0.85      , 0.875     ]),\n",
      " 'split4_test_score': array([0.36666667, 0.36666667, 0.4       , 0.36666667, 0.36666667,\n",
      "       0.4       , 0.33333333, 0.36666667, 0.36666667]),\n",
      " 'split4_train_score': array([0.88333333, 0.88333333, 0.88333333, 0.88333333, 0.88333333,\n",
      "       0.88333333, 0.8875    , 0.89166667, 0.90833333]),\n",
      " 'std_fit_time': array([0.35897547, 0.03083022, 0.00540564, 0.01225665, 0.0136311 ,\n",
      "       0.01823111, 0.02430654, 0.01260609, 0.34992781]),\n",
      " 'std_score_time': array([0.00079794, 0.00074646, 0.00074593, 0.00079781, 0.00039892,\n",
      "       0.00039866, 0.00097684, 0.00048832, 0.00135346]),\n",
      " 'std_test_score': array([0.03559026, 0.03431877, 0.03496029, 0.03559026, 0.03431877,\n",
      "       0.03496029, 0.04422166, 0.03091206, 0.042947  ]),\n",
      " 'std_train_score': array([0.01889297, 0.02395018, 0.02643125, 0.01889297, 0.02395018,\n",
      "       0.02643125, 0.02997684, 0.01870829, 0.02303379])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 6\n",
    "paramt6 = {'subsample':[i/100.0 for i in range (75,90,5)], 'colsample_bytree':[i/100.0 for i in range (75,90,5)]}\n",
    "\n",
    "gsearch6 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic',\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0),\n",
    "                        param_grid = paramt6, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch6.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch6.best_params_)\n",
    "print(gsearch6.best_score_)\n",
    "pp.pprint(gsearch6.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.01}\n",
      "0.4133333333333333\n",
      "{'mean_fit_time': array([2.14199753, 1.54347034, 1.55583744, 1.53828411, 1.07073469]),\n",
      " 'mean_score_time': array([0.008178  , 0.00877662, 0.00857716, 0.00757995, 0.00578489]),\n",
      " 'mean_test_score': array([0.39333333, 0.41333333, 0.38333333, 0.38333333, 0.        ]),\n",
      " 'mean_train_score': array([0.87666667, 0.87833333, 0.8775    , 0.84      , 0.        ]),\n",
      " 'param_reg_alpha': masked_array(data=[1e-05, 0.01, 0.1, 1, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'reg_alpha': 1e-05},\n",
      "            {'reg_alpha': 0.01},\n",
      "            {'reg_alpha': 0.1},\n",
      "            {'reg_alpha': 1},\n",
      "            {'reg_alpha': 100}],\n",
      " 'rank_test_score': array([2, 1, 3, 4, 5]),\n",
      " 'split0_test_score': array([0.41666667, 0.36666667, 0.43333333, 0.41666667, 0.        ]),\n",
      " 'split0_train_score': array([0.86666667, 0.8625    , 0.86666667, 0.81666667, 0.        ]),\n",
      " 'split1_test_score': array([0.36666667, 0.43333333, 0.41666667, 0.33333333, 0.        ]),\n",
      " 'split1_train_score': array([0.89583333, 0.9       , 0.8875    , 0.8625    , 0.        ]),\n",
      " 'split2_test_score': array([0.36666667, 0.38333333, 0.33333333, 0.38333333, 0.        ]),\n",
      " 'split2_train_score': array([0.85833333, 0.8625    , 0.85833333, 0.82916667, 0.        ]),\n",
      " 'split3_test_score': array([0.38333333, 0.45      , 0.4       , 0.43333333, 0.        ]),\n",
      " 'split3_train_score': array([0.88333333, 0.87083333, 0.89166667, 0.825     , 0.        ]),\n",
      " 'split4_test_score': array([0.43333333, 0.43333333, 0.33333333, 0.35      , 0.        ]),\n",
      " 'split4_train_score': array([0.87916667, 0.89583333, 0.88333333, 0.86666667, 0.        ]),\n",
      " 'std_fit_time': array([0.31549287, 0.01002537, 0.02802479, 0.01257775, 0.1198767 ]),\n",
      " 'std_score_time': array([0.00116307, 0.00039873, 0.00048827, 0.00048844, 0.00039871]),\n",
      " 'std_test_score': array([0.02708013, 0.03231787, 0.0421637 , 0.03800585, 0.        ]),\n",
      " 'std_train_score': array([0.01307032, 0.01632993, 0.01280191, 0.02051422, 0.        ])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 7\n",
    "paramt7 = {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "\n",
    "gsearch7 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.8, colsample_by_tree = 0.8,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0),\n",
    "                        param_grid = paramt7, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch7.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch7.best_params_)\n",
    "print(gsearch7.best_score_)\n",
    "pp.pprint(gsearch7.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.02}\n",
      "0.43000000000000005\n",
      "{'mean_fit_time': array([1.85423083, 1.69606233, 1.63861542, 1.54466691, 1.75450592,\n",
      "       1.86002326, 2.13149748, 2.33475423]),\n",
      " 'mean_score_time': array([0.00977459, 0.01037235, 0.01077213, 0.00897627, 0.00997357,\n",
      "       0.00997396, 0.01037269, 0.01376281]),\n",
      " 'mean_test_score': array([0.39333333, 0.38666667, 0.39      , 0.41333333, 0.43      ,\n",
      "       0.37333333, 0.40666667, 0.39      ]),\n",
      " 'mean_train_score': array([0.87666667, 0.87416667, 0.875     , 0.87833333, 0.875     ,\n",
      "       0.8875    , 0.87583333, 0.88      ]),\n",
      " 'param_reg_alpha': masked_array(data=[0, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'reg_alpha': 0},\n",
      "            {'reg_alpha': 0.001},\n",
      "            {'reg_alpha': 0.005},\n",
      "            {'reg_alpha': 0.01},\n",
      "            {'reg_alpha': 0.02},\n",
      "            {'reg_alpha': 0.03},\n",
      "            {'reg_alpha': 0.04},\n",
      "            {'reg_alpha': 0.05}],\n",
      " 'rank_test_score': array([4, 7, 6, 2, 1, 8, 3, 5]),\n",
      " 'split0_test_score': array([0.41666667, 0.38333333, 0.38333333, 0.36666667, 0.43333333,\n",
      "       0.41666667, 0.4       , 0.45      ]),\n",
      " 'split0_train_score': array([0.86666667, 0.85416667, 0.875     , 0.8625    , 0.86666667,\n",
      "       0.87916667, 0.84166667, 0.85833333]),\n",
      " 'split1_test_score': array([0.36666667, 0.36666667, 0.36666667, 0.43333333, 0.48333333,\n",
      "       0.33333333, 0.38333333, 0.38333333]),\n",
      " 'split1_train_score': array([0.89583333, 0.89583333, 0.89583333, 0.9       , 0.89583333,\n",
      "       0.91666667, 0.9       , 0.89583333]),\n",
      " 'split2_test_score': array([0.36666667, 0.36666667, 0.4       , 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.36666667, 0.31666667]),\n",
      " 'split2_train_score': array([0.85833333, 0.85833333, 0.85      , 0.8625    , 0.84583333,\n",
      "       0.84583333, 0.85833333, 0.86666667]),\n",
      " 'split3_test_score': array([0.38333333, 0.38333333, 0.45      , 0.45      , 0.41666667,\n",
      "       0.4       , 0.43333333, 0.43333333]),\n",
      " 'split3_train_score': array([0.88333333, 0.88333333, 0.87916667, 0.87083333, 0.89166667,\n",
      "       0.89166667, 0.88333333, 0.875     ]),\n",
      " 'split4_test_score': array([0.43333333, 0.43333333, 0.35      , 0.43333333, 0.43333333,\n",
      "       0.33333333, 0.45      , 0.36666667]),\n",
      " 'split4_train_score': array([0.87916667, 0.87916667, 0.875     , 0.89583333, 0.875     ,\n",
      "       0.90416667, 0.89583333, 0.90416667]),\n",
      " 'std_fit_time': array([0.05769022, 0.05454434, 0.02544335, 0.04527632, 0.04000017,\n",
      "       0.04041377, 0.15793068, 0.02268159]),\n",
      " 'std_score_time': array([0.00074626, 0.00195414, 0.00222124, 0.00109267, 0.00141047,\n",
      "       0.00089244, 0.00162069, 0.00324039]),\n",
      " 'std_test_score': array([0.02708013, 0.0244949 , 0.03431877, 0.03231787, 0.03231787,\n",
      "       0.03431877, 0.03091206, 0.04784233]),\n",
      " 'std_train_score': array([0.01307032, 0.01567907, 0.01467235, 0.01632993, 0.01806624,\n",
      "       0.02429563, 0.02242271, 0.01736056])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 8\n",
    "paramt8 = {'reg_alpha':[0, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05]}\n",
    "\n",
    "gsearch8 = GridSearchCV(estimator=XGBClassifier(learning_rate=0.5, n_estimators=265, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.8, colsample_by_tree = 0.75,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0),\n",
    "                        param_grid = paramt8, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch8.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch8.best_params_)\n",
    "print(gsearch8.best_score_)\n",
    "pp.pprint(gsearch8.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9711\n",
      "AUC Score : 0.954025\n",
      "[[3285   39]\n",
      " [  60   46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3324\n",
      "           1       0.54      0.43      0.48       106\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3430\n",
      "   macro avg       0.76      0.71      0.73      3430\n",
      "weighted avg       0.97      0.97      0.97      3430\n",
      "\n",
      "AUC Score 0.9540250437072861\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9728862973760933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.876922       0.033077       0.861648      0.037370\n",
      "1         0.916519       0.014174       0.899056      0.015528\n",
      "2         0.939077       0.004438       0.923607      0.007962\n",
      "3         0.956174       0.004832       0.946381      0.011212\n",
      "4         0.961855       0.005287       0.952300      0.010970\n",
      "5         0.968370       0.004061       0.960895      0.009170\n",
      "6         0.973040       0.001596       0.964539      0.005535\n",
      "7         0.975424       0.001034       0.968315      0.002812\n",
      "8         0.976255       0.000899       0.968791      0.002961\n",
      "9         0.977245       0.000488       0.969502      0.003298\n",
      "10        0.978151       0.000800       0.969839      0.003239\n",
      "11        0.978739       0.000965       0.970038      0.003720\n",
      "12        0.979237       0.000863       0.970202      0.004363\n",
      "13        0.979626       0.000812       0.970183      0.004409\n",
      "14        0.979919       0.000945       0.970225      0.003738\n",
      "15        0.980508       0.000908       0.970424      0.004205\n",
      "16        0.980891       0.000685       0.969797      0.004297\n",
      "17        0.981417       0.000780       0.969673      0.004265\n",
      "18        0.981794       0.000885       0.970288      0.003924\n",
      "19        0.982086       0.000789       0.970359      0.003649\n",
      "20        0.982344       0.000778       0.970192      0.003813\n",
      "21        0.982621       0.000842       0.970437      0.004072\n",
      "22        0.982867       0.000863       0.970220      0.004127\n",
      "23        0.983200       0.000833       0.970442      0.004020\n",
      "24        0.983442       0.000800       0.970387      0.003732\n",
      "25        0.983582       0.000815       0.970724      0.003774\n",
      "26        0.983894       0.000904       0.970878      0.003674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21aee71e160>"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test run 8\n",
    "xgb_classt8 = XGBClassifier(learning_rate=1.3, n_estimators=500, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.8, colsample_by_tree = 0.75,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0, reg_alpha=0.01)\n",
    "\n",
    "\n",
    "\n",
    "xgb_classt8.fit(X_train, y_train)\n",
    "\n",
    "predictionst8 = xgb_classt8.predict(X_test)\n",
    "predict_probat8 = xgb_classt8.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictionst8))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_probat8[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictionst8))\n",
    "print(classification_report(y_test, predictionst8))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_probat8[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3297 + 40) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':6, 'gamma':0, 'subsample':0.8, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':265, 'seed':27, 'colsample_bytree':0.75,\n",
    "          'max_depth':2, 'reg_alpha':0.02}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_classt8.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning rate': 0.0}\n",
      "0.32333333333333336\n",
      "{'mean_fit_time': array([4.68267131, 3.84591064, 3.55548787, 3.45954156, 3.51499658,\n",
      "       3.46891942, 3.74717464, 4.22090764, 4.38247561, 4.45548024,\n",
      "       4.39145098, 4.37848597, 4.48819232, 4.52090554, 5.2363914 ,\n",
      "       5.27030039, 5.11730971, 4.80474567, 4.86079593, 4.97868099,\n",
      "       5.12748256, 5.15361257, 5.26371808, 5.42348475, 5.19789443]),\n",
      " 'mean_score_time': array([0.01535816, 0.01316504, 0.0133646 , 0.01376343, 0.01336441,\n",
      "       0.01296563, 0.01516004, 0.01715436, 0.01675529, 0.01635594,\n",
      "       0.01795249, 0.01795187, 0.01735396, 0.01795211, 0.02134414,\n",
      "       0.01835093, 0.0199472 , 0.01974721, 0.02014666, 0.0195477 ,\n",
      "       0.02094383, 0.02154312, 0.02114358, 0.02114353, 0.02094417]),\n",
      " 'mean_test_score': array([0.32333333, 0.32333333, 0.32333333, 0.32333333, 0.32333333,\n",
      "       0.32333333, 0.32333333, 0.32333333, 0.32333333, 0.32333333,\n",
      "       0.32333333, 0.32333333, 0.32333333, 0.32333333, 0.32333333,\n",
      "       0.32333333, 0.32333333, 0.32333333, 0.32333333, 0.32333333,\n",
      "       0.32333333, 0.32333333, 0.32333333, 0.32333333, 0.32333333]),\n",
      " 'mean_train_score': array([0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375,\n",
      "       0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375,\n",
      "       0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375, 0.6375,\n",
      "       0.6375]),\n",
      " 'param_learning rate': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
      "                   1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1,\n",
      "                   2.2, 2.3, 2.4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'learning rate': 0.0},\n",
      "            {'learning rate': 0.1},\n",
      "            {'learning rate': 0.2},\n",
      "            {'learning rate': 0.3},\n",
      "            {'learning rate': 0.4},\n",
      "            {'learning rate': 0.5},\n",
      "            {'learning rate': 0.6},\n",
      "            {'learning rate': 0.7},\n",
      "            {'learning rate': 0.8},\n",
      "            {'learning rate': 0.9},\n",
      "            {'learning rate': 1.0},\n",
      "            {'learning rate': 1.1},\n",
      "            {'learning rate': 1.2},\n",
      "            {'learning rate': 1.3},\n",
      "            {'learning rate': 1.4},\n",
      "            {'learning rate': 1.5},\n",
      "            {'learning rate': 1.6},\n",
      "            {'learning rate': 1.7},\n",
      "            {'learning rate': 1.8},\n",
      "            {'learning rate': 1.9},\n",
      "            {'learning rate': 2.0},\n",
      "            {'learning rate': 2.1},\n",
      "            {'learning rate': 2.2},\n",
      "            {'learning rate': 2.3},\n",
      "            {'learning rate': 2.4}],\n",
      " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1]),\n",
      " 'split0_test_score': array([0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
      "       0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333]),\n",
      " 'split0_train_score': array([0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667]),\n",
      " 'split1_test_score': array([0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
      "       0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
      "       0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
      "       0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
      "       0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333]),\n",
      " 'split1_train_score': array([0.67916667, 0.67916667, 0.67916667, 0.67916667, 0.67916667,\n",
      "       0.67916667, 0.67916667, 0.67916667, 0.67916667, 0.67916667,\n",
      "       0.67916667, 0.67916667, 0.67916667, 0.67916667, 0.67916667,\n",
      "       0.67916667, 0.67916667, 0.67916667, 0.67916667, 0.67916667,\n",
      "       0.67916667, 0.67916667, 0.67916667, 0.67916667, 0.67916667]),\n",
      " 'split2_test_score': array([0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333]),\n",
      " 'split2_train_score': array([0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
      "       0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
      "       0.65, 0.65, 0.65]),\n",
      " 'split3_test_score': array([0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35,\n",
      "       0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35,\n",
      "       0.35, 0.35, 0.35]),\n",
      " 'split3_train_score': array([0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667,\n",
      "       0.61666667, 0.61666667, 0.61666667, 0.61666667, 0.61666667]),\n",
      " 'split4_test_score': array([0.26666667, 0.26666667, 0.26666667, 0.26666667, 0.26666667,\n",
      "       0.26666667, 0.26666667, 0.26666667, 0.26666667, 0.26666667,\n",
      "       0.26666667, 0.26666667, 0.26666667, 0.26666667, 0.26666667,\n",
      "       0.26666667, 0.26666667, 0.26666667, 0.26666667, 0.26666667,\n",
      "       0.26666667, 0.26666667, 0.26666667, 0.26666667, 0.26666667]),\n",
      " 'split4_train_score': array([0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625,\n",
      "       0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625,\n",
      "       0.625, 0.625, 0.625, 0.625, 0.625, 0.625, 0.625]),\n",
      " 'std_fit_time': array([0.43762172, 0.19338814, 0.12107628, 0.02430432, 0.04202337,\n",
      "       0.04531651, 0.25843914, 0.07124131, 0.12791579, 0.07118661,\n",
      "       0.03170433, 0.03470028, 0.03191712, 0.05319857, 0.51853033,\n",
      "       0.35279032, 0.16151233, 0.04209905, 0.06368694, 0.05510805,\n",
      "       0.0423759 , 0.11615105, 0.02139407, 0.04761146, 0.63948509]),\n",
      " 'std_score_time': array([0.0017379 , 0.00146594, 0.00185014, 0.00171573, 0.00048834,\n",
      "       0.00063075, 0.00203404, 0.00097725, 0.00039849, 0.00048856,\n",
      "       0.00089255, 0.00141054, 0.00101695, 0.00126139, 0.00286425,\n",
      "       0.00162053, 0.00302499, 0.00132316, 0.00097688, 0.00048862,\n",
      "       0.0012618 , 0.00079768, 0.00074631, 0.00074633, 0.00141047]),\n",
      " 'std_test_score': array([0.042947, 0.042947, 0.042947, 0.042947, 0.042947, 0.042947,\n",
      "       0.042947, 0.042947, 0.042947, 0.042947, 0.042947, 0.042947,\n",
      "       0.042947, 0.042947, 0.042947, 0.042947, 0.042947, 0.042947,\n",
      "       0.042947, 0.042947, 0.042947, 0.042947, 0.042947, 0.042947,\n",
      "       0.042947]),\n",
      " 'std_train_score': array([0.02415229, 0.02415229, 0.02415229, 0.02415229, 0.02415229,\n",
      "       0.02415229, 0.02415229, 0.02415229, 0.02415229, 0.02415229,\n",
      "       0.02415229, 0.02415229, 0.02415229, 0.02415229, 0.02415229,\n",
      "       0.02415229, 0.02415229, 0.02415229, 0.02415229, 0.02415229,\n",
      "       0.02415229, 0.02415229, 0.02415229, 0.02415229, 0.02415229])}\n"
     ]
    }
   ],
   "source": [
    "# Tune test 9\n",
    "paramt9 = {'learning rate':[i/10.0 for i in range (0,25,1)]}\n",
    "\n",
    "gsearch9 = GridSearchCV(estimator=XGBClassifier(n_estimators=500, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.8, colsample_by_tree = 0.75,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0, reg_alpha=0.01),\n",
    "                        param_grid = paramt9, scoring='recall', n_jobs=4, iid=False, cv=5)\n",
    "\n",
    "gsearch9.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(gsearch9.best_params_)\n",
    "print(gsearch9.best_score_)\n",
    "pp.pprint(gsearch9.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8962\n",
      "AUC Score : 0.802935\n",
      "[[3004  320]\n",
      " [  36   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      3324\n",
      "           1       0.18      0.66      0.28       106\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      3430\n",
      "   macro avg       0.58      0.78      0.61      3430\n",
      "weighted avg       0.96      0.90      0.92      3430\n",
      "\n",
      "AUC Score 0.8029354835047566\n",
      "Accuracy (I.e. Total Correct Predictions / Total Predictions) 0.9728862973760933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kengw\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0         0.876922       0.033077       0.861648      0.037370\n",
      "1         0.916519       0.014174       0.899056      0.015528\n",
      "2         0.939076       0.004438       0.923620      0.007963\n",
      "3         0.956173       0.004832       0.946382      0.011214\n",
      "4         0.961855       0.005287       0.952301      0.010971\n",
      "5         0.968369       0.004062       0.960887      0.009177\n",
      "6         0.973040       0.001595       0.964539      0.005538\n",
      "7         0.975423       0.001036       0.968312      0.002815\n",
      "8         0.976256       0.000899       0.968788      0.002965\n",
      "9         0.977246       0.000488       0.969507      0.003298\n",
      "10        0.978152       0.000799       0.969842      0.003239\n",
      "11        0.978743       0.000964       0.970043      0.003715\n",
      "12        0.979241       0.000865       0.970206      0.004358\n",
      "13        0.979632       0.000812       0.970185      0.004402\n",
      "14        0.979924       0.000945       0.970226      0.003732\n",
      "15        0.980513       0.000908       0.970430      0.004203\n",
      "16        0.980893       0.000687       0.969798      0.004293\n",
      "17        0.981419       0.000781       0.969674      0.004265\n",
      "18        0.981795       0.000885       0.970291      0.003922\n",
      "19        0.982088       0.000787       0.970366      0.003643\n",
      "20        0.982346       0.000778       0.970196      0.003802\n",
      "21        0.982624       0.000841       0.970442      0.004060\n",
      "22        0.982868       0.000864       0.970226      0.004118\n",
      "23        0.983203       0.000833       0.970441      0.004018\n",
      "24        0.983445       0.000799       0.970390      0.003729\n",
      "25        0.983585       0.000814       0.970730      0.003772\n",
      "26        0.983897       0.000905       0.970876      0.003667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ae19b1fd0>"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 9\n",
    "# Test run 9\n",
    "xgb_classt9 = XGBClassifier(learning_rate=2.5, n_estimators=500, max_depth=2, min_child_weight=6,\n",
    "                                                objective='binary:logistic', subsample=0.8, colsample_by_tree = 0.75,\n",
    "                                                nthread=4, scale_post_weight=1, seed=27, gamma=0, reg_alpha=0.01)\n",
    "\n",
    "\n",
    "\n",
    "xgb_classt9.fit(X_train, y_train)\n",
    "\n",
    "predictionst9 = xgb_classt9.predict(X_test)\n",
    "predict_probat9 = xgb_classt9.predict_proba(X_test)\n",
    "\n",
    "print(\"Accuracy : %.4g\" % accuracy_score(y_test, predictionst9))\n",
    "print(\"AUC Score : %f\" % roc_auc_score(y_test, predict_probat9[:,1]))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, predictionst9))\n",
    "print(classification_report(y_test, predictionst9))\n",
    "print('AUC Score', roc_auc_score(y_test, predict_probat9[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy (I.e. Total Correct Predictions / Total Predictions)', (3297 + 40) / 3430)\n",
    "\n",
    "params = {'learning_rate':0.5, 'scale_post_weight':1, 'min_child_weight':6, 'gamma':0, 'subsample':0.8, \n",
    "          'nthread':4, 'objective':'binary:logistic', 'n_estimators':265, 'seed':27, 'colsample_bytree':0.75,\n",
    "          'max_depth':2, 'reg_alpha':0.01}\n",
    "\n",
    "train = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(dtrain=train, params=params, nfold=5, num_boost_round=50, early_stopping_rounds=10, metrics='auc',\n",
    "                    as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results)\n",
    "\n",
    "\n",
    "feat_imp = pd.Series(xgb_classt9.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
